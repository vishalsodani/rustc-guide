<!DOCTYPE HTML>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>Guide to Rustc Development</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="A guide to developing rustc ">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <base href="">

        <link rel="stylesheet" href="book.css">
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css">
        <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro:500" rel="stylesheet" type="text/css">

        <link rel="shortcut icon" href="favicon.png">

        <!-- Font Awesome -->
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">

        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme -->
        

        

        <!-- Fetch Clipboard.js from CDN but have a local fallback -->
        <script src="https://cdn.jsdelivr.net/clipboard.js/1.6.1/clipboard.min.js"></script>
        <script>
            if (typeof Clipboard == 'undefined') {
                document.write(unescape("%3Cscript src='clipboard.min.js'%3E%3C/script%3E"));
            }
        </script>

    </head>
    <body class="light">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { } 
            if (theme === null || theme === undefined) { theme = 'light'; }
            document.body.className = theme;
            document.querySelector('html').className = theme;
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            document.querySelector('html').classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <ol class="chapter"><li><a href="about-this-guide.html"><strong aria-hidden="true">1.</strong> About this guide</a></li><li><a href="how-to-build-and-run.html"><strong aria-hidden="true">2.</strong> How to build the compiler and run what you built</a></li><li><a href="conventions.html"><strong aria-hidden="true">3.</strong> Coding conventions</a></li><li><a href="tests/intro.html"><strong aria-hidden="true">4.</strong> The compiler testing framework</a></li><li><ol class="section"><li><a href="tests/running.html"><strong aria-hidden="true">4.1.</strong> Running tests</a></li><li><a href="tests/adding.html"><strong aria-hidden="true">4.2.</strong> Adding new tests</a></li><li><a href="compiletest.html"><strong aria-hidden="true">4.3.</strong> Using compiletest + commands to control test execution</a></li></ol></li><li><a href="walkthrough.html"><strong aria-hidden="true">5.</strong> Walkthrough: a typical contribution</a></li><li><a href="high-level-overview.html"><strong aria-hidden="true">6.</strong> High-level overview of the compiler source</a></li><li><a href="query.html"><strong aria-hidden="true">7.</strong> Queries: demand-driven compilation</a></li><li><ol class="section"><li><a href="incremental-compilation.html"><strong aria-hidden="true">7.1.</strong> Incremental compilation</a></li></ol></li><li><a href="the-parser.html"><strong aria-hidden="true">8.</strong> The parser</a></li><li><a href="macro-expansion.html"><strong aria-hidden="true">9.</strong> Macro expansion</a></li><li><a href="name-resolution.html"><strong aria-hidden="true">10.</strong> Name resolution</a></li><li><a href="hir.html"><strong aria-hidden="true">11.</strong> The HIR (High-level IR)</a></li><li><a href="ty.html"><strong aria-hidden="true">12.</strong> The ty module: representing types</a></li><li><a href="type-inference.html"><strong aria-hidden="true">13.</strong> Type inference</a></li><li><a href="trait-resolution.html"><strong aria-hidden="true">14.</strong> Trait resolution</a></li><li><ol class="section"><li><a href="trait-hrtb.html"><strong aria-hidden="true">14.1.</strong> Higher-ranked trait bounds</a></li><li><a href="trait-caching.html"><strong aria-hidden="true">14.2.</strong> Caching subtleties</a></li><li><a href="trait-specialization.html"><strong aria-hidden="true">14.3.</strong> Speciailization</a></li></ol></li><li><a href="type-checking.html"><strong aria-hidden="true">15.</strong> Type checking</a></li><li><a href="mir.html"><strong aria-hidden="true">16.</strong> The MIR (Mid-level IR)</a></li><li><ol class="section"><li><a href="mir-construction.html"><strong aria-hidden="true">16.1.</strong> MIR construction</a></li><li><a href="mir-visitor.html"><strong aria-hidden="true">16.2.</strong> MIR visitor and traversal</a></li><li><a href="mir-passes.html"><strong aria-hidden="true">16.3.</strong> MIR passes: getting the MIR for a function</a></li><li><a href="mir-borrowck.html"><strong aria-hidden="true">16.4.</strong> MIR borrowck</a></li><li><ol class="section"><li><a href="mir-regionck.html"><strong aria-hidden="true">16.4.1.</strong> MIR-based region checking (NLL)</a></li></ol></li><li><a href="mir-optimizations.html"><strong aria-hidden="true">16.5.</strong> MIR optimizations</a></li></ol></li><li><a href="const-eval.html"><strong aria-hidden="true">17.</strong> Constant evaluation</a></li><li><ol class="section"><li><a href="miri.html"><strong aria-hidden="true">17.1.</strong> miri const evaluator</a></li></ol></li><li><a href="param_env.html"><strong aria-hidden="true">18.</strong> Parameter Environments</a></li><li><a href="trans.html"><strong aria-hidden="true">19.</strong> Generating LLVM IR</a></li><li><a href="background.html"><strong aria-hidden="true">20.</strong> Background material</a></li><li><a href="glossary.html"><strong aria-hidden="true">21.</strong> Glossary</a></li><li><a href="code-index.html"><strong aria-hidden="true">22.</strong> Code Index</a></li></ol>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar" class="menu-bar">
                    <div id="menu-bar-sticky-container">
                        <div class="left-buttons">
                            <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-controls="sidebar">
                                <i class="fa fa-bars"></i>
                            </button>
                            <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                                <i class="fa fa-paint-brush"></i>
                            </button>
                            <ul id="theme-list" class="theme-popup" aria-label="submenu">
                                <li><button class="theme" id="light">Light <span class="default">(default)</span></button></li>
                                <li><button class="theme" id="rust">Rust</button></li>
                                <li><button class="theme" id="coal">Coal</button></li>
                                <li><button class="theme" id="navy">Navy</button></li>
                                <li><button class="theme" id="ayu">Ayu</button></li>
                            </ul>
                        </div>

                        <h1 class="menu-title">Guide to Rustc Development</h1>

                        <div class="right-buttons">
                            <a href="print.html" title="Print this book">
                                <i id="print-button" class="fa fa-print"></i>
                            </a>
                        </div>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <a class="header" href="print.html#about-this-guide" id="about-this-guide"><h1>About this guide</h1></a>
<p>This guide is meant to help document how rustc – the Rust compiler –
works, as well as to help new contributors get involved in rustc
development. It is not meant to replace code documentation – each
chapter gives only high-level details – the kinds of things that
(ideally) don't change frequently.</p>
<p>The guide itself is of course open-source as well, and the sources can
be found at the <a href="https://github.com/rust-lang-nursery/rustc-guide/">GitHub repository</a>. If you find any mistakes in the
guide, please file an issue about it, or even better, open a PR
with a correction!</p>
<a class="header" href="print.html#how-to-build-the-compiler-and-run-what-you-built" id="how-to-build-the-compiler-and-run-what-you-built"><h1>How to build the compiler and run what you built</h1></a>
<p>The compiler is built using a tool called <code>x.py</code>. You will need to
have Python installed to run it. But before we get to that, if you're going to
be hacking on rustc, you'll want to tweak the configuration of the compiler. The default
configuration is oriented towards running the compiler as a user, not a developer.</p>
<a class="header" href="print.html#create-a-configtoml" id="create-a-configtoml"><h3>Create a config.toml</h3></a>
<p>To start, copy <a href="https://github.com/rust-lang/rust/blob/master/config.toml.example"><code>config.toml.example</code></a> to <code>config.toml</code>:</p>
<pre><code class="language-bash">&gt; cd $RUST_CHECKOUT
&gt; cp config.toml.example config.toml
</code></pre>
<p>Then you will want to open up the file and change the following
settings (and possibly others, such as <code>llvm.ccache</code>):</p>
<pre><code class="language-toml">[llvm]
# Enables LLVM assertions, which will check that the LLVM bitcode generated
# by the compiler is internally consistent. These are particularly helpful
# if you edit `trans`.
assertions = true

[rust]
# This enables some assertions, but more importantly it enables the `debug!` logging
# macros that are essential for debugging rustc.
debug-assertions = true

# This will make your build more parallel; it costs a bit of runtime
# performance perhaps (less inlining) but it's worth it.
codegen-units = 0

# I always enable full debuginfo, though debuginfo-lines is more important.
debuginfo = true

# Gives you line numbers for backtraces.
debuginfo-lines = true

# Using the system allocator (instead of jemalloc) means that tools
# like valgrind and memcache work better.
use-jemalloc = false
</code></pre>
<a class="header" href="print.html#running-xpy-and-building-a-stage1-compiler" id="running-xpy-and-building-a-stage1-compiler"><h3>Running x.py and building a stage1 compiler</h3></a>
<p>One thing to keep in mind is that <code>rustc</code> is a <em>bootstrapping</em> compiler. That
is, since <code>rustc</code> is written in Rust, we need to use an older version of the
compiler to compile the newer version. In particular, the newer version of the
compiler, <code>libstd</code>, and other tooling may use some unstable features
internally. The result is the compiling <code>rustc</code> is done in stages.</p>
<ul>
<li><strong>Stage 0:</strong> the stage0 compiler is the current <em>beta</em> compiler; we
download this binary from the internet.</li>
<li><strong>Stage 1:</strong> the code in your clone is then compiled with the stage
0 compiler to produce the stage 1 compiler.</li>
<li><strong>Stage 2:</strong> the code in your clone is then compiled with the stage
1 compiler <em>again</em> to produce the stage 2 compiler (i.e. it builds
itself).</li>
</ul>
<p>For hacking, often building the stage 1 compiler is enough, but for
final testing and release, the stage 2 compiler is used.</p>
<p>Once you've created a config.toml, you are now ready to run
<code>x.py</code>. There are a lot of options here, but let's start with what is
probably the best &quot;go to&quot; command for building a local rust:</p>
<pre><code>./x.py build -i --stage 1 src/libstd
</code></pre>
<p>What this command will do is the following:</p>
<ul>
<li>Using the beta compiler (also called stage 0), it will build the
standard library and rustc from the <code>src</code> directory. The resulting
compiler is called the &quot;stage 1&quot; compiler.
<ul>
<li>During this build, the <code>-i</code> (or <code>--incremental</code>) switch enables incremental
compilation, so that if you later rebuild after editing things in
<code>src</code>, you can save a bit of time.</li>
</ul>
</li>
<li>Using this stage 1 compiler, it will build the standard library.
(this is what the <code>src/libstd</code>) means.</li>
</ul>
<p>This is just a subset of the full rustc build. The <strong>full</strong> rustc build (what you
get if you just say <code>./x.py build</code>) has quite a few more steps:</p>
<ul>
<li>Build stage1 rustc with stage0 compiler</li>
<li>Build libstd with stage1 compiler (up to here is the same)</li>
<li>Build rustc from <code>src</code> again, this time with the stage1 compiler (this part is new)
<ul>
<li>The resulting compiler here is called the &quot;stage2&quot; compiler</li>
</ul>
</li>
<li>Build libstd with stage2 compiler</li>
<li>Build librustdoc and a bunch of other things</li>
</ul>
<a class="header" href="print.html#creating-a-rustup-toolchain" id="creating-a-rustup-toolchain"><h3>Creating a rustup toolchain</h3></a>
<p>Once you have successfully built rustc, you will have created a bunch
of files in your <code>build</code> directory. In order to actually run the
resulting rustc, we recommend creating rustup toolchains. The first
one will run the stage1 compiler (which we built above). The second
will execute the stage2 compiler (which we did not build, but which
you will likely need to build at some point; for example, if you want
to run the entire test suite).</p>
<pre><code>&gt; rustup toolchain link stage1 build/&lt;host-triple&gt;/stage1
&gt; rustup toolchain link stage2 build/&lt;host-triple&gt;/stage2
</code></pre>
<p>Now you can run the rustc you built with. If you run with <code>-vV</code>, you
should see a version number ending in <code>-dev</code>, indicating a build from
your local environment:</p>
<pre><code>&gt; rustc +stage1 -vV
rustc 1.25.0-dev
binary: rustc
commit-hash: unknown
commit-date: unknown
host: x86_64-unknown-linux-gnu
release: 1.25.0-dev
LLVM version: 4.0
</code></pre>
<a class="header" href="print.html#other-xpy-commands" id="other-xpy-commands"><h3>Other x.py commands</h3></a>
<p>Here are a few other useful x.py commands. We'll cover some of them in detail in other sections:</p>
<ul>
<li>Building things:
<ul>
<li><code>./x.py clean</code> – clean up the build directory (<code>rm -rf build</code> works too, but then you have to rebuild LLVM)</li>
<li><code>./x.py build --stage 1</code> – builds everything using the stage 1 compiler, not just up to libstd</li>
<li><code>./x.py build</code> – builds the stage2 compiler</li>
</ul>
</li>
<li>Running tests (see the <a href="./tests/running.html">section on running tests</a> for more details):
<ul>
<li><code>./x.py test --stage 1 src/libstd</code> – runs the <code>#[test]</code> tests from libstd</li>
<li><code>./x.py test --stage 1 src/test/run-pass</code> – runs the <code>run-pass</code> test suite</li>
</ul>
</li>
</ul>
<p>This file offers some tips on the coding conventions for rustc.  This
chapter covers <a href="print.html#formatting">formatting</a>, <a href="print.html#cc">coding for correctness</a>,
<a href="print.html#cio">using crates from crates.io</a>, and some tips on
<a href="print.html#er">structuring your PR for easy review</a>.</p>
<p><a name=formatting></p>
<a class="header" href="print.html#formatting-and-the-tidy-script" id="formatting-and-the-tidy-script"><h1>Formatting and the tidy script</h1></a>
<p>rustc is slowly moving towards the <a href="https://github.com/rust-lang-nursery/fmt-rfcs">Rust standard coding style</a>;
at the moment, however, it follows a rather more <em>chaotic</em> style.  We
do have some mandatory formatting conventions, which are automatically
enforced by a script we affectionately call the &quot;tidy&quot; script.  The
tidy script runs automatically when you do <code>./x.py test</code>.</p>
<p><a name=copyright></p>
<a class="header" href="print.html#copyright-notice" id="copyright-notice"><h3>Copyright notice</h3></a>
<p>All files must begin with the following copyright notice:</p>
<pre><code>// Copyright 2012-2013 The Rust Project Developers. See the COPYRIGHT
// file at the top-level directory of this distribution and at
// http://rust-lang.org/COPYRIGHT.
//
// Licensed under the Apache License, Version 2.0 &lt;LICENSE-APACHE or
// http://www.apache.org/licenses/LICENSE-2.0&gt; or the MIT license
// &lt;LICENSE-MIT or http://opensource.org/licenses/MIT&gt;, at your
// option. This file may not be copied, modified, or distributed
// except according to those terms.
</code></pre>
<p>The year at the top is not meaningful: copyright protections are in
fact automatic from the moment of authorship. We do not typically edit
the years on existing files. When creating a new file, you can use the
current year if you like, but you don't have to.</p>
<a class="header" href="print.html#line-length" id="line-length"><h2>Line length</h2></a>
<p>Lines should be at most 100 characters. It's even better if you can
keep things to 80.</p>
<p><strong>Ignoring the line length limit.</strong> Sometimes -- in particular for
tests -- it can be necessary to exempt yourself from this limit. In
that case, you can add a comment towards the top of the file (after
the copyright notice) like so:</p>
<pre><code>// ignore-tidy-linelength
</code></pre>
<a class="header" href="print.html#tabs-vs-spaces" id="tabs-vs-spaces"><h2>Tabs vs spaces</h2></a>
<p>Prefer 4-space indent.</p>
<p><a name=cc></p>
<a class="header" href="print.html#coding-for-correctness" id="coding-for-correctness"><h1>Coding for correctness</h1></a>
<p>Beyond formatting, there are a few other tips that are worth
following.</p>
<a class="header" href="print.html#prefer-exhaustive-matches" id="prefer-exhaustive-matches"><h2>Prefer exhaustive matches</h2></a>
<p>Using <code>_</code> in a match is convenient, but it means that when new
variants are added to the enum, they may not get handled correctly.
Ask yourself: if a new variant were added to this enum, what's the
chance that it would want to use the <code>_</code> code, versus having some
other treatment?  Unless the answer is &quot;low&quot;, then prefer an
exhaustive match. (The same advice applies to <code>if let</code> and <code>while let</code>, which are effectively tests for a single variant.)</p>
<a class="header" href="print.html#use-todo-comments-for-things-you-dont-want-to-forget" id="use-todo-comments-for-things-you-dont-want-to-forget"><h2>Use &quot;TODO&quot; comments for things you don't want to forget</h2></a>
<p>As a useful tool to yourself, you can insert a <code>// TODO</code> comment
for something that you want to get back to before you land your PR:</p>
<pre><code class="language-rust ignore">fn do_something() {
    if something_else {
        unimplemented!(): // TODO write this
    }
}
</code></pre>
<p>The tidy script will report an error for a <code>// TODO</code> comment, so this
code would not be able to land until the TODO is fixed (or removed).</p>
<p>This can also be useful in a PR as a way to signal from one commit that you are
leaving a bug that a later commit will fix:</p>
<pre><code class="language-rust ignore">if foo {
    return true; // TODO wrong, but will be fixed in a later commit
}
</code></pre>
<p><a name=cio></p>
<a class="header" href="print.html#using-crates-from-cratesio" id="using-crates-from-cratesio"><h1>Using crates from crates.io</h1></a>
<p>It is allowed to use crates from crates.io, though external
dependencies should not be added gratuitously. All such crates must
have a suitably permissive license. There is an automatic check which
inspects the Cargo metadata to ensure this.</p>
<p><a name=er></p>
<a class="header" href="print.html#how-to-structure-your-pr" id="how-to-structure-your-pr"><h1>How to structure your PR</h1></a>
<p>How you prepare the commits in your PR can make a big difference for the reviewer.
Here are some tips.</p>
<p><strong>Isolate &quot;pure refactorings&quot; into their own commit.</strong> For example, if
you rename a method, then put that rename into its own commit, along
with the renames of all the uses.</p>
<p><strong>More commits is usually better.</strong> If you are doing a large change,
it's almost always better to break it up into smaller steps that can
be independently understood. The one thing to be aware of is that if
you introduce some code following one strategy, then change it
dramatically (versus adding to it) in a later commit, that
'back-and-forth' can be confusing.</p>
<p><strong>If you run rustfmt and the file was not already formatted, isolate
that into its own commit.</strong> This is really the same as the previous
rule, but it's worth highlighting. It's ok to rustfmt files, but since
we do not currently run rustfmt all the time, that can introduce a lot
of noise into your commit. Please isolate that into its own
commit. This also makes rebases a lot less painful, since rustfmt
tends to cause a lot of merge conflicts, and having those isolated
into their own commit makes htem easier to resolve.</p>
<p><strong>No merges.</strong> We do not allow merge commits into our history, other
than those by bors. If you get a merge conflict, rebase instead via a
command like <code>git rebase -i rust-lang/master</code> (presuming you use the
name <code>rust-lang</code> for your remote).</p>
<p><strong>Individual commits do not have to build (but it's nice).</strong> We do not
require that every intermediate commit successfully builds -- we only
expect to be able to bisect at a PR level. However, if you <em>can</em> make
individual commits build, that is always helpful.</p>
<a class="header" href="print.html#the-compiler-testing-framework" id="the-compiler-testing-framework"><h1>The compiler testing framework</h1></a>
<p>The Rust project runs a wide variety of different tests, orchestrated by the
build system (<code>x.py test</code>).  The main test harness for testing the compiler
itself is a tool called compiletest (sources in the
<a href="https://github.com/rust-lang/rust/tree/master/src/tools/compiletest"><code>src/tools/compiletest</code></a>). This section gives a brief overview of how the
testing framework is setup, and then gets into some of the details on <a href="./tests/running.html#ui">how to
run tests</a> as well as <a href="./tests/adding.html">how to add new
tests</a>.</p>
<a class="header" href="print.html#compiletest-test-suites" id="compiletest-test-suites"><h2>Compiletest test suites</h2></a>
<p>The compiletest tests are located in the tree in the <a href="https://github.com/rust-lang/rust/tree/master/src/test"><code>src/test</code></a>
directory. Immediately within you will see a series of subdirectories
(e.g. <code>ui</code>, <code>run-make</code>, and so forth). Each of those directories is
called a <strong>test suite</strong> -- they house a group of tests that are run in
a distinct mode.</p>
<p>Here is a brief summary of the test suites as of this writing and what
they mean. In some cases, the test suites are linked to parts of the manual
that give more details.</p>
<ul>
<li><a href="./tests/adding.html#ui"><code>ui</code></a> -- tests that check the exact stdout/stderr from compilation
and/or running the test</li>
<li><code>run-pass</code> -- tests that are expected to compile and execute successfully (no panics)
<ul>
<li><code>run-pass-valgrind</code> -- tests that ought to run with valrind</li>
</ul>
</li>
<li><code>run-fail</code> -- tests that are expected to compile but then panic during execution</li>
<li><code>compile-fail</code> -- tests that are expected to fail compilation.</li>
<li><code>parse-fail</code> -- tests that are expected to fail to parse</li>
<li><code>pretty</code> -- tests targeting the Rust &quot;pretty printer&quot;, which
generates valid Rust code from the AST</li>
<li><code>debuginfo</code> -- tests that run in gdb or lldb and query the debug info</li>
<li><code>codegen</code> -- tests that compile and then test the generated LLVM
code to make sure that the optimizations we want are taking effect.</li>
<li><code>mir-opt</code> -- tests that check parts of the generated MIR to make
sure we are building things correctly or doing the optimizations we
expect.</li>
<li><code>incremental</code> -- tests for incremental compilation, checking that
when certain modifications are performed, we are able to reuse the
results from previous compilations.</li>
<li><code>run-make</code> -- tests that basically just execute a <code>Makefile</code>; the
ultimate in flexibility but quite annoying to write.</li>
<li><code>rustdoc</code> -- tests for rustdoc, making sure that the generated files contain
the expected documentation.</li>
<li><code>*-fulldeps</code> -- same as above, but indicates that the test depends on things other
than <code>libstd</code> (and hence those things must be built)</li>
</ul>
<a class="header" href="print.html#other-tests" id="other-tests"><h2>Other Tests</h2></a>
<p>The Rust build system handles running tests for various other things,
including:</p>
<ul>
<li>
<p><strong>Tidy</strong> -- This is a custom tool used for validating source code style and
formatting conventions, such as rejecting long lines.  There is more
information in the <a href="./conventions.html#formatting">section on coding conventions</a>.</p>
<p>Example: <code>./x.py test src/tools/tidy</code></p>
</li>
<li>
<p><strong>Unittests</strong> -- The Rust standard library and many of the Rust packages
include typical Rust <code>#[test]</code> unittests.  Under the hood, <code>x.py</code> will run
<code>cargo test</code> on each package to run all the tests.</p>
<p>Example: <code>./x.py test src/libstd</code></p>
</li>
<li>
<p><strong>Doctests</strong> -- Example code embedded within Rust documentation is executed
via <code>rustdoc --test</code>.  Examples:</p>
<p><code>./x.py test src/doc</code> -- Runs <code>rustdoc --test</code> for all documentation in
<code>src/doc</code>.</p>
<p><code>./x.py test --doc src/libstd</code> -- Runs <code>rustdoc --test</code> on the standard
library.</p>
</li>
<li>
<p><strong>Linkchecker</strong> -- A small tool for verifying <code>href</code> links within
documentation.</p>
<p>Example: <code>./x.py test src/tools/linkchecker</code></p>
</li>
<li>
<p><strong>Distcheck</strong> -- This verifies that the source distribution tarball created
by the build system will unpack, build, and run all tests.</p>
<p>Example: <code>./x.py test distcheck</code></p>
</li>
<li>
<p><strong>Tool tests</strong> -- Packages that are included with Rust have all of their
tests run as well (typically by running <code>cargo test</code> within their
directory).  This includes things such as cargo, clippy, rustfmt, rls, miri,
bootstrap (testing the Rust build system itself), etc.</p>
</li>
<li>
<p><strong>Cargotest</strong> -- This is a small tool which runs <code>cargo test</code> on a few
significant projects (such as <code>servo</code>, <code>ripgrep</code>, <code>tokei</code>, etc.) just to
ensure there aren't any significant regressions.</p>
<p>Example: <code>./x.py test src/tools/cargotest</code></p>
</li>
</ul>
<a class="header" href="print.html#testing-infrastructure" id="testing-infrastructure"><h2>Testing infrastructure</h2></a>
<p>When a Pull Request is opened on Github, <a href="https://travis-ci.org/rust-lang/rust">Travis</a> will automatically launch a
build that will run all tests on a single configuration (x86-64 linux). In
essence, it runs <code>./x.py test</code> after building.</p>
<p>The integration bot <a href="https://github.com/servo/homu">bors</a> is used for coordinating merges to the master
branch. When a PR is approved, it goes into a <a href="https://buildbot2.rust-lang.org/homu/queue/rust">queue</a> where merges are tested
one at a time on a wide set of platforms using Travis and <a href="https://ci.appveyor.com/project/rust-lang/rust">Appveyor</a>
(currently over 50 different configurations).  Most platforms only run the
build steps, some run a restricted set of tests, only a subset run the full
suite of tests (see Rust's <a href="https://forge.rust-lang.org/platform-support.html">platform tiers</a>).</p>
<a class="header" href="print.html#testing-with-docker-images" id="testing-with-docker-images"><h2>Testing with Docker images</h2></a>
<p>The Rust tree includes <a href="https://www.docker.com/">Docker</a> image definitions for the platforms used on
Travis in <a href="https://github.com/rust-lang/rust/tree/master/src/ci/docker">src/ci/docker</a>.  The script <a href="https://github.com/rust-lang/rust/blob/master/src/ci/docker/run.sh">src/ci/docker/run.sh</a> is used to build
the Docker image, run it, build Rust within the image, and run the tests.</p>
<blockquote>
<p>TODO: What is a typical workflow for testing/debugging on a platform that
you don't have easy access to?  Do people build Docker images and enter them
to test things out?</p>
</blockquote>
<a class="header" href="print.html#testing-on-emulators" id="testing-on-emulators"><h2>Testing on emulators</h2></a>
<p>Some platforms are tested via an emulator for architectures that aren't
readily available.  There is a set of tools for orchestrating running the
tests within the emulator.  Platforms such as <code>arm-android</code> and
<code>arm-unknown-linux-gnueabihf</code> are set up to automatically run the tests under
emulation on Travis.  The following will take a look at how a target's tests
are run under emulation.</p>
<p>The Docker image for <a href="https://github.com/rust-lang/rust/tree/master/src/ci/docker/armhf-gnu">armhf-gnu</a> includes <a href="https://www.qemu.org/">QEMU</a> to emulate the ARM CPU
architecture.  Included in the Rust tree are the tools <a href="https://github.com/rust-lang/rust/tree/master/src/tools/remote-test-client">remote-test-client</a>
and <a href="https://github.com/rust-lang/rust/tree/master/src/tools/remote-test-server">remote-test-server</a> which are programs for sending test programs and
libraries to the emulator, and running the tests within the emulator, and
reading the results.  The Docker image is set up to launch
<code>remote-test-server</code> and the build tools use <code>remote-test-client</code> to
communicate with the server to coordinate running tests (see
<a href="https://github.com/rust-lang/rust/tree/master/src/bootstrap/test.rs">src/bootstrap/test.rs</a>).</p>
<blockquote>
<p>TODO: What are the steps for manually running tests within an emulator?
<code>./src/ci/docker/run.sh armhf-gnu</code> will do everything, but takes hours to
run and doesn't offer much help with interacting within the emulator.</p>
<p>Is there any support for emulating other (non-Android) platforms, such as
running on an iOS emulator?</p>
<p>Is there anything else interesting that can be said here about running tests
remotely on real hardware?</p>
<p>It's also unclear to me how the wasm or asm.js tests are run.</p>
</blockquote>
<a class="header" href="print.html#crater" id="crater"><h2>Crater</h2></a>
<p>TODO</p>
<a class="header" href="print.html#further-reading" id="further-reading"><h2>Further reading</h2></a>
<p>The following blog posts may also be of interest:</p>
<ul>
<li>brson's classic <a href="https://brson.github.io/2017/07/10/how-rust-is-tested">&quot;How Rust is tested&quot;</a></li>
</ul>
<a class="header" href="print.html#running-tests" id="running-tests"><h1>Running tests</h1></a>
<p>You can run the tests using <code>x.py</code>. The most basic command -- which
you will almost never want to use! -- is as follows:</p>
<pre><code>./x.py test
</code></pre>
<p>This will build the full stage 2 compiler and then run the whole test
suite. You probably don't want to do this very often, because it takes
a very long time, and anyway bors / travis will do it for you. (Often,
I will run this command in the background after opening a PR that I
think is done, but rarely otherwise. -nmatsakis)</p>
<a class="header" href="print.html#running-a-subset-of-the-test-suites" id="running-a-subset-of-the-test-suites"><h2>Running a subset of the test suites</h2></a>
<p>When working on a specific PR, you will usually want to run a smaller
set of tests, and with a stage 1 build. For example, a good &quot;smoke
test&quot; that can be used after modifying rustc to see if things are
generally working correctly would be the following:</p>
<pre><code class="language-bash">./x.py test --stage 1 src/test/{ui,compile-fail,run-pass}
</code></pre>
<p>This will run the <code>ui</code>, <code>compile-fail</code>, and <code>run-pass</code> test suites, and
only with the stage 1 build. Of course, the choice of test suites is somewhat
arbitrary, and may not suit the task you are doing. For example, if you are hacking
on debuginfo, you may be better off with the debuginfo test suite:</p>
<pre><code class="language-bash">./x.py test --stage 1 src/test/debuginfo
</code></pre>
<p><strong>Warning:</strong> Note that bors only runs the tests with the full stage 2
build; therefore, while the tests <strong>usually</strong> work fine with stage 1,
there are some limitations. In particular, the stage1 compiler doesn't
work well with procedural macros or custom derive tests.</p>
<a class="header" href="print.html#running-an-individual-test" id="running-an-individual-test"><h2>Running an individual test</h2></a>
<p>Another common thing that people want to do is to run an <strong>individual
test</strong>, often the test they are trying to fix. One way to do this is
to invoke <code>x.py</code> with the <code>--test-args</code> option:</p>
<pre><code>./x.py test --stage 1 src/test/ui --test-args issue-1234
</code></pre>
<p>Under the hood, the test runner invokes the standard rust test runner
(the same one you get with <code>#[test]</code>), so this command would wind up
filtering for tests that include &quot;issue-1234&quot; in the name.</p>
<p>Often, though, it's easier to just run the test by hand. Most tests are
just <code>rs</code> files, so you can do something like</p>
<pre><code>rustc +stage1 src/test/ui/issue-1234.rs
</code></pre>
<p>This is much faster, but doesn't always work. For example, some tests
include directives that specify specific compiler flags, or which rely
on other crates, and they may not run the same without those options.</p>
<a class="header" href="print.html#adding-new-tests" id="adding-new-tests"><h1>Adding new tests</h1></a>
<p><strong>In general, we expect every PR that fixes a bug in rustc to come
accompanied by a regression test of some kind.</strong> This test should fail
in master but pass after the PR. These tests are really useful for
preventing us from repeating the mistakes of the past.</p>
<p>To add a new test, the first thing you generally do is to create a
file, typically a Rust source file. Test files have a particular
structure:</p>
<ul>
<li>They always begin with the <a href="./conventions.html#copyright">copyright notice</a>;</li>
<li>then they should have some kind of
<a href="print.html#explanatory_comment">comment explaining what the test is about</a>;</li>
<li>next, they can have one or more <a href="print.html#header_commands">header commands</a>, which are special
comments that the test interpreter knows how to interpret.</li>
<li>finally, they have the Rust source. This may have various <a href="print.html#error_annotations">error
annotations</a> which indicate expected compilation errors or
warnings.</li>
</ul>
<p>Depending on the test suite, there may be some other details to be aware of:</p>
<ul>
<li>For <a href="print.html#ui">the <code>ui</code> test suite</a>, you need to generate reference output files.</li>
</ul>
<a class="header" href="print.html#what-kind-of-test-should-i-add" id="what-kind-of-test-should-i-add"><h2>What kind of test should I add?</h2></a>
<p>It can be difficult to know what kind of test to use. Here are some
rough heuristics:</p>
<ul>
<li>Some tests have specialized needs:
<ul>
<li>need to run gdb or lldb? use the <code>debuginfo</code> test suite</li>
<li>need to inspect LLVM IR or MIR IR? use the <code>codegen</code> or <code>mir-opt</code> test suites</li>
<li>need to run rustdoc? Prefer a <code>rustdoc</code> test</li>
<li>need to inspect the resulting binary in some way? Then use <code>run-make</code></li>
</ul>
</li>
<li>For most other things, <a href="print.html#ui">a <code>ui</code> (or <code>ui-fulldeps</code>) test</a> is to be preferred:
<ul>
<li><code>ui</code> tests subsume both run-pass, compile-fail, and parse-fail tests</li>
<li>in the case of warnings or errors, <code>ui</code> tests capture the full output,
which makes it easier to review but also helps prevent &quot;hidden&quot; regressions
in the output</li>
</ul>
</li>
</ul>
<a class="header" href="print.html#naming-your-test" id="naming-your-test"><h2>Naming your test</h2></a>
<p>We have not traditionally had a lot of structure in the names of
tests.  Moreover, for a long time, the rustc test runner did not
support subdirectories (it now does), so test suites like
<a href="https://github.com/rust-lang/rust/tree/master/src/test/run-pass/"><code>src/test/run-pass</code></a> have a huge mess of files in them. This is not
considered an ideal setup.</p>
<p>For regression tests -- basically, some random snippet of code that
came in from the internet -- we often just name the test after the
issue. For example, <code>src/test/run-pass/issue-12345.rs</code>. If possible,
though, it is better if you can put the test into a directory that
helps identify what piece of code is being tested here (e.g.,
<code>borrowck/issue-12345.rs</code> is much better), or perhaps give it a more
meaningful name. Still, <strong>do include the issue number somewhere</strong>.</p>
<p>When writing a new feature, <strong>create a subdirectory to store your
tests</strong>. For example, if you are implementing RFC 1234 (&quot;Widgets&quot;),
then it might make sense to put the tests in directories like:</p>
<ul>
<li><code>src/test/ui/rfc1234-widgets/</code></li>
<li><code>src/test/run-pass/rfc1234-widgets/</code></li>
<li>etc</li>
</ul>
<p>In other cases, there may already be a suitable directory. (The proper
directory structure to use is actually an area of active debate.)</p>
<p><a name=explanatory_comment></p>
<a class="header" href="print.html#comment-explaining-what-the-test-is-about" id="comment-explaining-what-the-test-is-about"><h2>Comment explaining what the test is about</h2></a>
<p>When you create a test file, <strong>include a comment summarizing the point
of the test immediately after the copyright notice</strong>. This should
highlight which parts of the test are more important, and what the bug
was that the test is fixing.  Citing an issue number is often very
helpful.</p>
<p>This comment doesn't have to be super extensive. Just something like
&quot;Regression test for #18060: match arms were matching in the wrong
order.&quot;  might already be enough.</p>
<p>These comments are very useful to others later on when your test
breaks, since they often can highlight what the problem is. They are
also useful if for some reason the tests need to be refactored, since
they let others know which parts of the test were important (often a
test must be rewritten because it no longer tests what is was meant to
test, and then it's useful to know what it <em>was</em> meant to test
exactly).</p>
<p><a name=header_commands></p>
<a class="header" href="print.html#header-commands-configuring-rustc" id="header-commands-configuring-rustc"><h2>Header commands: configuring rustc</h2></a>
<p>Header commands are special comments that the test runner knows how to
interpret.  They must appear before the Rust source in the test. They
are normally put after the short comment that explains the point of
this test. For example, this test uses the <code>// compile-flags</code> command
to specify a custom flag to give to rustc when the test is compiled:</p>
<pre><pre class="playpen"><code class="language-rust">// Copyright 2017 The Rust Project Developers. blah blah blah.
// ...
// except according to those terms.

// Test the behavior of `0 - 1` when overflow checks are disabled.

// compile-flags: -Coverflow-checks=off

fn main() {
    let x = 0 - 1;
    ...
}
</code></pre></pre>
<a class="header" href="print.html#ignoring-tests" id="ignoring-tests"><h3>Ignoring tests</h3></a>
<p>These are used to ignore the test in some situations, which means the test won't
be compiled or run.</p>
<ul>
<li><code>ignore-X</code> where <code>X</code> is a target detail or stage will ignore the test accordingly (see below)</li>
<li><code>ignore-pretty</code> will not compile the pretty-printed test (this is done to test the pretty-printer, but might not always work)</li>
<li><code>ignore-test</code> always ignores the test</li>
<li><code>ignore-lldb</code> and <code>ignore-gdb</code> will skip a debuginfo test on that debugger.</li>
</ul>
<p>Some examples of <code>X</code> in <code>ignore-X</code>:</p>
<ul>
<li>Architecture: <code>aarch64</code>, <code>arm</code>, <code>asmjs</code>, <code>mips</code>, <code>wasm32</code>, <code>x86_64</code>, <code>x86</code>, ...</li>
<li>OS: <code>android</code>, <code>emscripten</code>, <code>freebsd</code>, <code>ios</code>, <code>linux</code>, <code>macos</code>, <code>windows</code>, ...</li>
<li>Environment (fourth word of the target triple): <code>gnu</code>, <code>msvc</code>, <code>musl</code>.</li>
<li>Pointer width: <code>32bit</code>, <code>64bit</code>.</li>
<li>Stage: <code>stage0</code>, <code>stage1</code>, <code>stage2</code>.</li>
</ul>
<a class="header" href="print.html#other-header-commands" id="other-header-commands"><h3>Other Header Commands</h3></a>
<p>Here is a list of other header commands. This list is not
exhaustive. Header commands can generally be found by browsing the
<code>TestProps</code> structure found in <a href="https://github.com/rust-lang/rust/tree/master/src/tools/compiletest/src/header.rs"><code>header.rs</code></a> from the compiletest
source.</p>
<ul>
<li><code>min-{gdb,lldb}-version</code></li>
<li><code>min-llvm-version</code></li>
<li><code>must-compile-successfully</code> for UI tests, indicates that the test is supposed
to compile, as opposed to the default where the test is supposed to error out.</li>
<li><code>compile-flags</code> passes extra command-line args to the compiler,
e.g. <code>compile-flags -g</code> which forces debuginfo to be enabled.</li>
<li><code>should-fail</code> indicates that the test should fail; used for &quot;meta testing&quot;,
where we test the compiletest program itself to check that it will generate
errors in appropriate scenarios. This header is ignored for pretty-printer tests.</li>
<li><code>gate-test-X</code> where <code>X</code> is a feature marks the test as &quot;gate test&quot; for feature X.
Such tests are supposed to ensure that the compiler errors when usage of a gated
feature is attempted without the proper <code>#![feature(X)]</code> tag.
Each unstable lang feature is required to have a gate test.</li>
</ul>
<p><a name="error_annotations"></p>
<a class="header" href="print.html#error-annotations" id="error-annotations"><h2>Error annotations</h2></a>
<p>Error annotations specify the errors that the compiler is expected to
emit. They are &quot;attached&quot; to the line in source where the error is
located.</p>
<ul>
<li><code>~</code>: Associates the following error level and message with the
current line</li>
<li><code>~|</code>: Associates the following error level and message with the same
line as the previous comment</li>
<li><code>~^</code>: Associates the following error level and message with the
previous line. Each caret (<code>^</code>) that you add adds a line to this, so
<code>~^^^^^^^</code> is seven lines up.</li>
</ul>
<p>The error levels that you can have are:</p>
<ol>
<li><code>ERROR</code></li>
<li><code>WARNING</code></li>
<li><code>NOTE</code></li>
<li><code>HELP</code> and <code>SUGGESTION</code>*</li>
</ol>
<p>* <strong>Note</strong>: <code>SUGGESTION</code> must follow immediately after <code>HELP</code>.</p>
<a class="header" href="print.html#revisions" id="revisions"><h2>Revisions</h2></a>
<p>Certain classes of tests support &quot;revisions&quot; (as of the time of this
writing, this includes run-pass, compile-fail, run-fail, and
incremental, though incremental tests are somewhat
different). Revisions allow a single test file to be used for multiple
tests. This is done by adding a special header at the top of the file:</p>
<pre><code>// revisions: foo bar baz
</code></pre>
<p>This will result in the test being compiled (and tested) three times,
once with <code>--cfg foo</code>, once with <code>--cfg bar</code>, and once with <code>--cfg baz</code>. You can therefore use <code>#[cfg(foo)]</code> etc within the test to tweak
each of these results.</p>
<p>You can also customize headers and expected error messages to a particular
revision. To do this, add <code>[foo]</code> (or <code>bar</code>, <code>baz</code>, etc) after the <code>//</code>
comment, like so:</p>
<pre><code>// A flag to pass in only for cfg `foo`:
//[foo]compile-flags: -Z verbose

#[cfg(foo)]
fn test_foo() {
    let x: usize = 32_u32; //[foo]~ ERROR mismatched types
}
</code></pre>
<p>Note that not all headers have meaning when customized to a revision.
For example, the <code>ignore-test</code> header (and all &quot;ignore&quot; headers)
currently only apply to the test as a whole, not to particular
revisions. The only headers that are intended to really work when
customized to a revision are error patterns and compiler flags.</p>
<p><a name="ui"></p>
<a class="header" href="print.html#guide-to-the-ui-tests" id="guide-to-the-ui-tests"><h2>Guide to the UI tests</h2></a>
<p>The UI tests are intended to capture the compiler's complete output,
so that we can test all aspects of the presentation. They work by
compiling a file (e.g., <a href="https://github.com/rust-lang/rust/blob/master/src/test/ui/hello_world/main.rs"><code>ui/hello_world/main.rs</code></a>),
capturing the output, and then applying some normalization (see
below). This normalized result is then compared against reference
files named <code>ui/hello_world/main.stderr</code> and
<code>ui/hello_world/main.stdout</code>. If either of those files doesn't exist,
the output must be empty (that is actually the case for
<a href="https://github.com/rust-lang/rust/blob/master/src/test/ui/hello_world/">this particular test</a>). If the test run fails, we will print out
the current output, but it is also saved in
<code>build/&lt;target-triple&gt;/test/ui/hello_world/main.stdout</code> (this path is
printed as part of the test failure message), so you can run <code>diff</code>
and so forth.</p>
<a class="header" href="print.html#tests-that-do-not-result-in-compile-errors" id="tests-that-do-not-result-in-compile-errors"><h3>Tests that do not result in compile errors</h3></a>
<p>By default, a UI test is expected <strong>not to compile</strong> (in which case,
it should contain at least one <code>//~ ERROR</code> annotation). However, you
can also make UI tests where compilation is expected to succeed, and
you can even run the resulting program. Just add one of the following
<a href="print.html#header_commands">header commands</a>:</p>
<ul>
<li><code>// must-compile-successfully</code> -- compilation should succeed but do not run the resulting binary</li>
<li><code>// run-pass</code> -- compilation should succeed and we should run the resulting binary</li>
</ul>
<a class="header" href="print.html#editing-and-updating-the-reference-files" id="editing-and-updating-the-reference-files"><h3>Editing and updating the reference files</h3></a>
<p>If you have changed the compiler's output intentionally, or you are
making a new test, you can use the script <code>ui/update-references.sh</code> to
update the references. When you run the test framework, it will report
various errors: in those errors is a command you can use to run the
<code>ui/update-references.sh</code> script, which will then copy over the files
from the build directory and use them as the new reference. You can
also just run <code>ui/update-all-references.sh</code>. In both cases, you can run
the script with <code>--help</code> to get a help message.</p>
<a class="header" href="print.html#normalization" id="normalization"><h3>Normalization</h3></a>
<p>The normalization applied is aimed at eliminating output difference
between platforms, mainly about filenames:</p>
<ul>
<li>the test directory is replaced with <code>$DIR</code></li>
<li>all backslashes (<code>\</code>) are converted to forward slashes (<code>/</code>) (for Windows)</li>
<li>all CR LF newlines are converted to LF</li>
</ul>
<p>Sometimes these built-in normalizations are not enough. In such cases, you
may provide custom normalization rules using the header commands, e.g.</p>
<pre><code>// normalize-stdout-test: &quot;foo&quot; -&gt; &quot;bar&quot;
// normalize-stderr-32bit: &quot;fn\(\) \(32 bits\)&quot; -&gt; &quot;fn\(\) \($$PTR bits\)&quot;
// normalize-stderr-64bit: &quot;fn\(\) \(64 bits\)&quot; -&gt; &quot;fn\(\) \($$PTR bits\)&quot;
</code></pre>
<p>This tells the test, on 32-bit platforms, whenever the compiler writes
<code>fn() (32 bits)</code> to stderr, it should be normalized to read <code>fn() ($PTR bits)</code>
instead. Similar for 64-bit. The replacement is performed by regexes using
default regex flavor provided by <code>regex</code> crate.</p>
<p>The corresponding reference file will use the normalized output to test both
32-bit and 64-bit platforms:</p>
<pre><code>...
   |
   = note: source type: fn() ($PTR bits)
   = note: target type: u16 (16 bits)
...
</code></pre>
<p>Please see <a href="https://github.com/rust-lang/rust/blob/master/src/test/ui/transmute/main.rs"><code>ui/transmute/main.rs</code></a> and <a href="https://github.com/rust-lang/rust/blob/master/src/test/ui/transmute/main.stderr"><code>main.stderr</code></a> for a concrete usage example.</p>
<p>Besides <code>normalize-stderr-32bit</code> and <code>-64bit</code>, one may use any target
information or stage supported by <code>ignore-X</code> here as well (e.g.
<code>normalize-stderr-windows</code> or simply <code>normalize-stderr-test</code> for unconditional
replacement).</p>
<a class="header" href="print.html#compiletest" id="compiletest"><h1><code>compiletest</code></h1></a>
<a class="header" href="print.html#introduction" id="introduction"><h2>Introduction</h2></a>
<p><code>compiletest</code> is the main test harness of the Rust test suite.  It allows test authors to organize large numbers of tests (the
Rust compiler has many thousands), efficient test execution (parallel execution is supported), and allows the test author to
configure behavior and expected results of both individual and groups of tests.</p>
<p><code>compiletest</code> tests may check test code for success, for failure or in some cases, even failure to compile.  Tests are
typically organized as a Rust source file with annotations in comments before and/or within the test code, which serve to
direct <code>compiletest</code> on if or how to run the test, what behavior to expect, and more.  If you are unfamiliar with the compiler
testing framework, see <a href="./tests/intro.html"><code>this chapter</code></a> for additional background.</p>
<p>The tests themselves are typically (but not always) organized into &quot;suites&quot;--for example, <code>run-pass</code>, a folder
representing tests that should succeed, <code>run-fail</code>, a folder holding tests that should compile successfully, but return
a failure (non-zero status), <code>compile-fail</code>, a folder holding tests that should fail to compile, and many more.  The various
suites are defined in <a href="https://github.com/rust-lang/rust/tree/master/src/tools/compiletest/src/common.rs">src/tools/compiletest/src/common.rs</a> in the <code>pub struct Config</code> declaration.  And a very good
introduction to the different suites of compiler tests along with details about them can be found in <a href="./tests/adding.html"><code>Adding new tests</code></a>.</p>
<a class="header" href="print.html#adding-a-new-test-file" id="adding-a-new-test-file"><h2>Adding a new test file</h2></a>
<p>Briefly, simply create your new test in the appropriate location under <a href="https://github.com/rust-lang/rust/tree/master/src/test">src/test</a>.  No registration of test files is necessary as
<code>compiletest</code> will scan the <a href="https://github.com/rust-lang/rust/tree/master/src/test">src/test</a> subfolder recursively, and will execute any Rust source files it finds as tests.
See <a href="./tests/adding.html"><code>Adding new tests</code></a> for a complete guide on how to adding new tests.</p>
<a class="header" href="print.html#header-commands" id="header-commands"><h2>Header Commands</h2></a>
<p>Source file annotations which appear in comments near the top of the source file <em>before</em> any test code are known as header
commands.  These commands can instruct <code>compiletest</code> to ignore this test, set expectations on whether it is expected to
succeed at compiling, or what the test's return code is expected to be.  Header commands (and their inline counterparts,
Error Info commands) are described more fully <a href="./tests/adding.html#header-commands-configuring-rustc">here</a>.</p>
<a class="header" href="print.html#adding-a-new-header-command" id="adding-a-new-header-command"><h3>Adding a new header command</h3></a>
<p>Header commands are defined in the <code>TestProps</code> struct in <a href="https://github.com/rust-lang/rust/tree/master/src/tools/compiletest/src/header.rs">src/tools/compiletest/src/header.rs</a>.  At a high level, there are dozens of test properties defined here, all set to default values in the <code>TestProp</code> struct's <code>impl</code> block. Any test can override this
default value by specifying the property in question as header command as a comment (<code>//</code>) in the test source file, before any source code.</p>
<a class="header" href="print.html#using-a-header-command" id="using-a-header-command"><h4>Using a header command</h4></a>
<p>Here is an example, specifying the <code>must-compile-successfully</code> header command, which takes no arguments, followed by the
<code>failure-status</code> header command, which takes a single argument (which, in this case is a value of 1).  <code>failure-status</code> is
instructing <code>compiletest</code> to expect a failure status of 1 (rather than the current Rust default of 101 at the time of this
writing).  The header command and the argument list (if present) are typically separated by a colon:</p>
<pre><code>// Copyright 2018 The Rust Project Developers. See the COPYRIGHT
// file at the top-level directory of this distribution and at
// http://rust-lang.org/COPYRIGHT.
//
// Licensed under the Apache License, Version 2.0 &lt;LICENSE-APACHE or
// http://www.apache.org/licenses/LICENSE-2.0&gt; or the MIT license
// &lt;LICENSE-MIT or http://opensource.org/licenses/MIT&gt;, at your
// option. This file may not be copied, modified, or distributed
// except according to those terms.

// must-compile-successfully
// failure-status: 1

#![feature(termination_trait)]

use std::io::{Error, ErrorKind};

fn main() -&gt; Result&lt;(), Box&lt;Error&gt;&gt; {
    Err(Box::new(Error::new(ErrorKind::Other, &quot;returned Box&lt;Error&gt; from main()&quot;)))
}
</code></pre>
<a class="header" href="print.html#adding-a-new-header-command-property" id="adding-a-new-header-command-property"><h4>Adding a new header command property</h4></a>
<p>One would add a new header command if there is a need to define some test property or behavior on an individual, test-by-test
basis.  A header command property serves as the header command's backing store (holds the command's current value) at
runtime.</p>
<p>To add a new header command property:
1. Look for the <code>pub struct TestProps</code> declaration in <a href="https://github.com/rust-lang/rust/tree/master/src/tools/compiletest/src/header.rs">src/tools/compiletest/src/header.rs</a> and add
the new public property to the end of the declaration.
2. Look for the <code>impl TestProps</code> implementation block immediately following the struct declaration and initialize the new
property to its default value.</p>
<a class="header" href="print.html#adding-a-new-header-command-parser" id="adding-a-new-header-command-parser"><h4>Adding a new header command parser</h4></a>
<p>When <code>compiletest</code> encounters a test file, it parses the file a line at a time by calling every parser defined in the
<code>Config</code> struct's implementation block, also in <a href="https://github.com/rust-lang/rust/tree/master/src/tools/compiletest/src/header.rs">src/tools/compiletest/src/header.rs</a> (note the <code>Config</code> struct's declaration
block is found in <a href="https://github.com/rust-lang/rust/tree/master/src/tools/compiletest/src/common.rs">src/tools/compiletest/src/common.rs</a>.  <code>TestProps</code>'s <code>load_from()</code> method will try passing the current
line of text to each parser, which, in turn typically checks to see if the line begins with a particular commented (<code>//</code>)
header command such as <code>// must-compile-successfully</code> or <code>// failure-status</code>.  Whitespace after the comment marker is
optional.</p>
<p>Parsers will override a given header command property's default value merely by being specified in the test file as a header
command or by having a parameter value specified in the test file, depending on the header command.</p>
<p>Parsers defined in <code>impl Config</code> are typically named <code>parse_&lt;header_command&gt;</code> (note kebab-case <code>&lt;header-command&gt;</code> transformed
to snake-case <code>&lt;header_command&gt;</code>).  <code>impl Config</code> also defines several 'low-level' parsers which make it simple to parse
common patterns like simple presence or not (<code>parse_name_directive()</code>), header-command:parameter(s)
(<code>parse_name_value_directive()</code>), optional parsing only if a particular <code>cfg</code> attribute is defined (<code>has_cfg_prefix()</code>) and
many more.  The low-level parsers are found near the end of the <code>impl Config</code> block; be sure to look through them and their
associated parsers immediately above to see how they are used to avoid writing additional parsing code unneccessarily.</p>
<p>As a concrete example, here is the implementation for the <code>parse_failure_status()</code> parser, in
<a href="https://github.com/rust-lang/rust/tree/master/src/tools/compiletest/src/header.rs">src/tools/compiletest/src/header.rs</a>:</p>
<pre><code class="language-diff">@@ -232,6 +232,7 @@ pub struct TestProps {
     // customized normalization rules
     pub normalize_stdout: Vec&lt;(String, String)&gt;,
     pub normalize_stderr: Vec&lt;(String, String)&gt;,
+    pub failure_status: i32,
 }
 
 impl TestProps {
@@ -260,6 +261,7 @@ impl TestProps {
             run_pass: false,
             normalize_stdout: vec![],
             normalize_stderr: vec![],
+            failure_status: 101,
         }
     }
 
@@ -383,6 +385,10 @@ impl TestProps {
             if let Some(rule) = config.parse_custom_normalization(ln, &quot;normalize-stderr&quot;) {
                 self.normalize_stderr.push(rule);
             }
+
+            if let Some(code) = config.parse_failure_status(ln) {
+                self.failure_status = code;
+            }
         });
 
         for key in &amp;[&quot;RUST_TEST_NOCAPTURE&quot;, &quot;RUST_TEST_THREADS&quot;] {
@@ -488,6 +494,13 @@ impl Config {
         self.parse_name_directive(line, &quot;pretty-compare-only&quot;)
     }
 
+    fn parse_failure_status(&amp;self, line: &amp;str) -&gt; Option&lt;i32&gt; {
+        match self.parse_name_value_directive(line, &quot;failure-status&quot;) {
+            Some(code) =&gt; code.trim().parse::&lt;i32&gt;().ok(),
+            _ =&gt; None,
+        }
+    }
</code></pre>
<a class="header" href="print.html#implementing-the-behavior-change" id="implementing-the-behavior-change"><h2>Implementing the behavior change</h2></a>
<p>When a test invokes a particular header command, it is expected that some behavior will change as a result.  What behavior,
obviously, will depend on the purpose of the header command.  In the case of <code>failure-status</code>, the behavior that changes
is that <code>compiletest</code> expects the failure code defined by the header command invoked in the test, rather than the default
value.</p>
<p>Although specific to <code>failure-status</code> (as every header command will have a different implementation in order to invoke
behavior change) perhaps it is helpful to see the behavior change implementation of one case, simply as an example.  To implement <code>failure-status</code>, the <code>check_correct_failure_status()</code> function found in the <code>TestCx</code> implementation block,
located in <a href="https://github.com/rust-lang/rust/tree/master/src/tools/compiletest/src/runtest.rs">src/tools/compiletest/src/runtest.rs</a>, was modified as per below:</p>
<pre><code class="language-diff">@@ -295,11 +295,14 @@ impl&lt;'test&gt; TestCx&lt;'test&gt; {
     }
 
     fn check_correct_failure_status(&amp;self, proc_res: &amp;ProcRes) {
-        // The value the rust runtime returns on failure
-        const RUST_ERR: i32 = 101;
-        if proc_res.status.code() != Some(RUST_ERR) {
+        let expected_status = Some(self.props.failure_status);
+        let received_status = proc_res.status.code();
+
+        if expected_status != received_status {
             self.fatal_proc_rec(
-                &amp;format!(&quot;failure produced the wrong error: {}&quot;, proc_res.status),
+                &amp;format!(&quot;Error: expected failure status ({:?}) but received status {:?}.&quot;,
+                         expected_status,
+                         received_status),
                 proc_res,
             );
         }
@@ -320,7 +323,6 @@ impl&lt;'test&gt; TestCx&lt;'test&gt; {
         );
 
         let proc_res = self.exec_compiled_test();
-
         if !proc_res.status.success() {
             self.fatal_proc_rec(&quot;test run failed!&quot;, &amp;proc_res);
         }
@@ -499,7 +501,6 @@ impl&lt;'test&gt; TestCx&lt;'test&gt; {
                 expected,
                 actual
             );
-            panic!();
         }
     }    
</code></pre>
<p>Note the use of <code>self.props.failure_status</code> to access the header command property.  In tests which do not specify the failure
status header command, <code>self.props.failure_status</code> will evaluate to the default value of 101 at the time of this writing.
But for a test which specifies a header command of, for example, <code>// failure-status: 1</code>, <code>self.props.failure_status</code> will
evaluate to 1, as <code>parse_failure_status()</code> will have overridden the <code>TestProps</code> default value, for that test specifically.</p>
<a class="header" href="print.html#walkthrough-a-typical-contribution" id="walkthrough-a-typical-contribution"><h1>Walkthrough: a typical contribution</h1></a>
<a class="header" href="print.html#high-level-overview-of-the-compiler-source" id="high-level-overview-of-the-compiler-source"><h1>High-level overview of the compiler source</h1></a>
<a class="header" href="print.html#crate-structure" id="crate-structure"><h2>Crate structure</h2></a>
<p>The main Rust repository consists of a <code>src</code> directory, under which
there live many crates. These crates contain the sources for the
standard library and the compiler.  This document, of course, focuses
on the latter.</p>
<p>Rustc consists of a number of crates, including <code>syntax</code>,
<code>rustc</code>, <code>rustc_back</code>, <code>rustc_trans</code>, <code>rustc_driver</code>, and
many more. The source for each crate can be found in a directory
like <code>src/libXXX</code>, where <code>XXX</code> is the crate name.</p>
<p>(N.B. The names and divisions of these crates are not set in
stone and may change over time. For the time being, we tend towards a
finer-grained division to help with compilation time, though as incremental
compilation improves, that may change.)</p>
<p>The dependency structure of these crates is roughly a diamond:</p>
<pre><code>                  rustc_driver
                /      |       \
              /        |         \
            /          |           \
          /            v             \
rustc_trans    rustc_borrowck   ...  rustc_metadata
          \            |            /
            \          |          /
              \        |        /
                \      v      /
                    rustc
                       |
                       v
                    syntax
                    /    \
                  /       \
           syntax_pos  syntax_ext
</code></pre>
<p>The <code>rustc_driver</code> crate, at the top of this lattice, is effectively
the &quot;main&quot; function for the rust compiler. It doesn't have much &quot;real
code&quot;, but instead ties together all of the code defined in the other
crates and defines the overall flow of execution. (As we transition
more and more to the <a href="query.html">query model</a>, however, the
&quot;flow&quot; of compilation is becoming less centrally defined.)</p>
<p>At the other extreme, the <code>rustc</code> crate defines the common and
pervasive data structures that all the rest of the compiler uses
(e.g. how to represent types, traits, and the program itself). It
also contains some amount of the compiler itself, although that is
relatively limited.</p>
<p>Finally, all the crates in the bulge in the middle define the bulk of
the compiler – they all depend on <code>rustc</code>, so that they can make use
of the various types defined there, and they export public routines
that <code>rustc_driver</code> will invoke as needed (more and more, what these
crates export are &quot;query definitions&quot;, but those are covered later
on).</p>
<p>Below <code>rustc</code> lie various crates that make up the parser and error
reporting mechanism. For historical reasons, these crates do not have
the <code>rustc_</code> prefix, but they are really just as much an internal part
of the compiler and not intended to be stable (though they do wind up
getting used by some crates in the wild; a practice we hope to
gradually phase out).</p>
<p>Each crate has a <code>README.md</code> file that describes, at a high-level,
what it contains, and tries to give some kind of explanation (some
better than others).</p>
<a class="header" href="print.html#the-main-stages-of-compilation" id="the-main-stages-of-compilation"><h2>The main stages of compilation</h2></a>
<p>The Rust compiler is in a bit of transition right now. It used to be a
purely &quot;pass-based&quot; compiler, where we ran a number of passes over the
entire program, and each did a particular check of transformation. We
are gradually replacing this pass-based code with an alternative setup
based on on-demand <strong>queries</strong>. In the query-model, we work backwards,
executing a <em>query</em> that expresses our ultimate goal (e.g. &quot;compile
this crate&quot;). This query in turn may make other queries (e.g. &quot;get me
a list of all modules in the crate&quot;). Those queries make other queries
that ultimately bottom out in the base operations, like parsing the
input, running the type-checker, and so forth. This on-demand model
permits us to do exciting things like only do the minimal amount of
work needed to type-check a single function. It also helps with
incremental compilation. (For details on defining queries, check out
<code>src/librustc/ty/maps/README.md</code>.)</p>
<p>Regardless of the general setup, the basic operations that the
compiler must perform are the same. The only thing that changes is
whether these operations are invoked front-to-back, or on demand.  In
order to compile a Rust crate, these are the general steps that we
take:</p>
<ol>
<li><strong>Parsing input</strong>
<ul>
<li>this processes the <code>.rs</code> files and produces the AST (&quot;abstract syntax tree&quot;)</li>
<li>the AST is defined in <code>syntax/ast.rs</code>. It is intended to match the lexical
syntax of the Rust language quite closely.</li>
</ul>
</li>
<li><strong>Name resolution, macro expansion, and configuration</strong>
<ul>
<li>once parsing is complete, we process the AST recursively, resolving paths
and expanding macros. This same process also processes <code>#[cfg]</code> nodes, and hence
may strip things out of the AST as well.</li>
</ul>
</li>
<li><strong>Lowering to HIR</strong>
<ul>
<li>Once name resolution completes, we convert the AST into the HIR,
or &quot;high-level IR&quot;. The HIR is defined in <code>src/librustc/hir/</code>; that module also includes
the lowering code.</li>
<li>The HIR is a lightly desugared variant of the AST. It is more processed than the
AST and more suitable for the analyses that follow. It is <strong>not</strong> required to match
the syntax of the Rust language.</li>
<li>As a simple example, in the <strong>AST</strong>, we preserve the parentheses
that the user wrote, so <code>((1 + 2) + 3)</code> and <code>1 + 2 + 3</code> parse
into distinct trees, even though they are equivalent. In the
HIR, however, parentheses nodes are removed, and those two
expressions are represented in the same way.</li>
</ul>
</li>
<li><strong>Type-checking and subsequent analyses</strong>
<ul>
<li>An important step in processing the HIR is to perform type
checking. This process assigns types to every HIR expression,
for example, and also is responsible for resolving some
&quot;type-dependent&quot; paths, such as field accesses (<code>x.f</code> – we
can't know what field <code>f</code> is being accessed until we know the
type of <code>x</code>) and associated type references (<code>T::Item</code> – we
can't know what type <code>Item</code> is until we know what <code>T</code> is).</li>
<li>Type checking creates &quot;side-tables&quot; (<code>TypeckTables</code>) that include
the types of expressions, the way to resolve methods, and so forth.</li>
<li>After type-checking, we can do other analyses, such as privacy checking.</li>
</ul>
</li>
<li><strong>Lowering to MIR and post-processing</strong>
<ul>
<li>Once type-checking is done, we can lower the HIR into MIR (&quot;middle IR&quot;), which
is a <strong>very</strong> desugared version of Rust, well suited to the borrowck but also
certain high-level optimizations.</li>
</ul>
</li>
<li><strong>Translation to LLVM and LLVM optimizations</strong>
<ul>
<li>From MIR, we can produce LLVM IR.</li>
<li>LLVM then runs its various optimizations, which produces a number of <code>.o</code> files
(one for each &quot;codegen unit&quot;).</li>
</ul>
</li>
<li><strong>Linking</strong>
<ul>
<li>Finally, those <code>.o</code> files are linked together.</li>
</ul>
</li>
</ol>
<a class="header" href="print.html#queries-demand-driven-compilation" id="queries-demand-driven-compilation"><h1>Queries: demand-driven compilation</h1></a>
<p>As described in <a href="high-level-overview.html">the high-level overview of the compiler</a>, the
Rust compiler is current transitioning from a traditional &quot;pass-based&quot;
setup to a &quot;demand-driven&quot; system. <strong>The Compiler Query System is the
key to our new demand-driven organization.</strong> The idea is pretty
simple. You have various queries that compute things about the input
-- for example, there is a query called <code>type_of(def_id)</code> that, given
the def-id of some item, will compute the type of that item and return
it to you.</p>
<p>Query execution is <strong>memoized</strong> – so the first time you invoke a
query, it will go do the computation, but the next time, the result is
returned from a hashtable. Moreover, query execution fits nicely into
<strong>incremental computation</strong>; the idea is roughly that, when you do a
query, the result <strong>may</strong> be returned to you by loading stored data
from disk (but that's a separate topic we won't discuss further here).</p>
<p>The overall vision is that, eventually, the entire compiler
control-flow will be query driven. There will effectively be one
top-level query (&quot;compile&quot;) that will run compilation on a crate; this
will in turn demand information about that crate, starting from the
<em>end</em>.  For example:</p>
<ul>
<li>This &quot;compile&quot; query might demand to get a list of codegen-units
(i.e. modules that need to be compiled by LLVM).</li>
<li>But computing the list of codegen-units would invoke some subquery
that returns the list of all modules defined in the Rust source.</li>
<li>That query in turn would invoke something asking for the HIR.</li>
<li>This keeps going further and further back until we wind up doing the
actual parsing.</li>
</ul>
<p>However, that vision is not fully realized. Still, big chunks of the
compiler (for example, generating MIR) work exactly like this.</p>
<a class="header" href="print.html#invoking-queries" id="invoking-queries"><h3>Invoking queries</h3></a>
<p>To invoke a query is simple. The tcx (&quot;type context&quot;) offers a method
for each defined query. So, for example, to invoke the <code>type_of</code>
query, you would just do this:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let ty = tcx.type_of(some_def_id);
#}</code></pre></pre>
<a class="header" href="print.html#cycles-between-queries" id="cycles-between-queries"><h3>Cycles between queries</h3></a>
<p>Currently, cycles during query execution should always result in a
compilation error. Typically, they arise because of illegal programs
that contain cyclic references they shouldn't (though sometimes they
arise because of compiler bugs, in which case we need to factor our
queries in a more fine-grained fashion to avoid them).</p>
<p>However, it is nonetheless often useful to <em>recover</em> from a cycle
(after reporting an error, say) and try to soldier on, so as to give a
better user experience. In order to recover from a cycle, you don't
get to use the nice method-call-style syntax. Instead, you invoke
using the <code>try_get</code> method, which looks roughly like this:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
use ty::maps::queries;
...
match queries::type_of::try_get(tcx, DUMMY_SP, self.did) {
  Ok(result) =&gt; {
    // no cycle occurred! You can use `result`
  }
  Err(err) =&gt; {
    // A cycle occurred! The error value `err` is a `DiagnosticBuilder`,
    // meaning essentially an &quot;in-progress&quot;, not-yet-reported error message.
    // See below for more details on what to do here.
  }
}
#}</code></pre></pre>
<p>So, if you get back an <code>Err</code> from <code>try_get</code>, then a cycle <em>did</em> occur. This means that
you must ensure that a compiler error message is reported. You can do that in two ways:</p>
<p>The simplest is to invoke <code>err.emit()</code>. This will emit the cycle error to the user.</p>
<p>However, often cycles happen because of an illegal program, and you
know at that point that an error either already has been reported or
will be reported due to this cycle by some other bit of code. In that
case, you can invoke <code>err.cancel()</code> to not emit any error. It is
traditional to then invoke:</p>
<pre><code>tcx.sess.delay_span_bug(some_span, &quot;some message&quot;)
</code></pre>
<p><code>delay_span_bug()</code> is a helper that says: we expect a compilation
error to have happened or to happen in the future; so, if compilation
ultimately succeeds, make an ICE with the message <code>&quot;some message&quot;</code>. This is basically just a precaution in case you are wrong.</p>
<a class="header" href="print.html#how-the-compiler-executes-a-query" id="how-the-compiler-executes-a-query"><h3>How the compiler executes a query</h3></a>
<p>So you may be wondering what happens when you invoke a query
method. The answer is that, for each query, the compiler maintains a
cache – if your query has already been executed, then, the answer is
simple: we clone the return value out of the cache and return it
(therefore, you should try to ensure that the return types of queries
are cheaply cloneable; insert a <code>Rc</code> if necessary).</p>
<a class="header" href="print.html#providers" id="providers"><h4>Providers</h4></a>
<p>If, however, the query is <em>not</em> in the cache, then the compiler will
try to find a suitable <strong>provider</strong>. A provider is a function that has
been defined and linked into the compiler somewhere that contains the
code to compute the result of the query.</p>
<p><strong>Providers are defined per-crate.</strong> The compiler maintains,
internally, a table of providers for every crate, at least
conceptually. Right now, there are really two sets: the providers for
queries about the <strong>local crate</strong> (that is, the one being compiled)
and providers for queries about <strong>external crates</strong> (that is,
dependencies of the local crate). Note that what determines the crate
that a query is targeting is not the <em>kind</em> of query, but the <em>key</em>.
For example, when you invoke <code>tcx.type_of(def_id)</code>, that could be a
local query or an external query, depending on what crate the <code>def_id</code>
is referring to (see the <code>self::keys::Key</code> trait for more information
on how that works).</p>
<p>Providers always have the same signature:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn provider&lt;'cx, 'tcx&gt;(tcx: TyCtxt&lt;'cx, 'tcx, 'tcx&gt;,
                       key: QUERY_KEY)
                       -&gt; QUERY_RESULT
{
    ...
}
#}</code></pre></pre>
<p>Providers take two arguments: the <code>tcx</code> and the query key. Note also
that they take the <em>global</em> tcx (i.e. they use the <code>'tcx</code> lifetime
twice), rather than taking a tcx with some active inference context.
They return the result of the query.</p>
<a class="header" href="print.html#how-providers-are-setup" id="how-providers-are-setup"><h4>How providers are setup</h4></a>
<p>When the tcx is created, it is given the providers by its creator using
the <code>Providers</code> struct. This struct is generate by the macros here, but it
is basically a big list of function pointers:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
struct Providers {
    type_of: for&lt;'cx, 'tcx&gt; fn(TyCtxt&lt;'cx, 'tcx, 'tcx&gt;, DefId) -&gt; Ty&lt;'tcx&gt;,
    ...
}
#}</code></pre></pre>
<p>At present, we have one copy of the struct for local crates, and one
for external crates, though the plan is that we may eventually have
one per crate.</p>
<p>These <code>Provider</code> structs are ultimately created and populated by
<code>librustc_driver</code>, but it does this by distributing the work
throughout the other <code>rustc_*</code> crates. This is done by invoking
various <code>provide</code> functions. These functions tend to look something
like this:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn provide(providers: &amp;mut Providers) {
    *providers = Providers {
        type_of,
        ..*providers
    };
}
#}</code></pre></pre>
<p>That is, they take an <code>&amp;mut Providers</code> and mutate it in place. Usually
we use the formulation above just because it looks nice, but you could
as well do <code>providers.type_of = type_of</code>, which would be equivalent.
(Here, <code>type_of</code> would be a top-level function, defined as we saw
before.) So, if we want to add a provider for some other query,
let's call it <code>fubar</code>, into the crate above, we might modify the <code>provide()</code>
function like so:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn provide(providers: &amp;mut Providers) {
    *providers = Providers {
        type_of,
        fubar,
        ..*providers
    };
}

fn fubar&lt;'cx, 'tcx&gt;(tcx: TyCtxt&lt;'cx, 'tcx&gt;, key: DefId) -&gt; Fubar&lt;'tcx&gt; { .. }
#}</code></pre></pre>
<p>N.B. Most of the <code>rustc_*</code> crates only provide <strong>local
providers</strong>. Almost all <strong>extern providers</strong> wind up going through the
<a href="https://github.com/rust-lang/rust/tree/master/src/librustc_metadata"><code>rustc_metadata</code> crate</a>, which loads the information from the crate
metadata.  But in some cases there are crates that provide queries for
<em>both</em> local and external crates, in which case they define both a
<code>provide</code> and a <code>provide_extern</code> function that <code>rustc_driver</code> can
invoke.</p>
<a class="header" href="print.html#adding-a-new-kind-of-query" id="adding-a-new-kind-of-query"><h3>Adding a new kind of query</h3></a>
<p>So suppose you want to add a new kind of query, how do you do so?
Well, defining a query takes place in two steps:</p>
<ol>
<li>first, you have to specify the query name and arguments; and then,</li>
<li>you have to supply query providers where needed.</li>
</ol>
<p>To specify the query name and arguments, you simply add an entry to
the big macro invocation in
<a href="https://github.com/rust-lang/rust/blob/master/src/librustc/ty/maps/mod.rs"><code>src/librustc/ty/maps/mod.rs</code></a>. This will probably have
changed by the time you read this README, but at present it looks
something like:</p>
<pre><code>define_maps! { &lt;'tcx&gt;
    /// Records the type of every item.
    [] fn type_of: TypeOfItem(DefId) -&gt; Ty&lt;'tcx&gt;,

    ...
}
</code></pre>
<p>Each line of the macro defines one query. The name is broken up like this:</p>
<pre><code>[] fn type_of: TypeOfItem(DefId) -&gt; Ty&lt;'tcx&gt;,
^^    ^^^^^^^  ^^^^^^^^^^ ^^^^^     ^^^^^^^^
|     |        |          |         |
|     |        |          |         result type of query
|     |        |          query key type
|     |        dep-node constructor
|     name of query
query flags
</code></pre>
<p>Let's go over them one by one:</p>
<ul>
<li><strong>Query flags:</strong> these are largely unused right now, but the intention
is that we'll be able to customize various aspects of how the query is
processed.</li>
<li><strong>Name of query:</strong> the name of the query method
(<code>tcx.type_of(..)</code>). Also used as the name of a struct
(<code>ty::maps::queries::type_of</code>) that will be generated to represent
this query.</li>
<li><strong>Dep-node constructor:</strong> indicates the constructor function that
connects this query to incremental compilation. Typically, this is a
<code>DepNode</code> variant, which can be added by modifying the
<code>define_dep_nodes!</code> macro invocation in
<a href="https://github.com/rust-lang/rust/blob/master/src/librustc/dep_graph/dep_node.rs"><code>librustc/dep_graph/dep_node.rs</code></a>.
<ul>
<li>However, sometimes we use a custom function, in which case the
name will be in snake case and the function will be defined at the
bottom of the file. This is typically used when the query key is
not a def-id, or just not the type that the dep-node expects.</li>
</ul>
</li>
<li><strong>Query key type:</strong> the type of the argument to this query.
This type must implement the <code>ty::maps::keys::Key</code> trait, which
defines (for example) how to map it to a crate, and so forth.</li>
<li><strong>Result type of query:</strong> the type produced by this query. This type
should (a) not use <code>RefCell</code> or other interior mutability and (b) be
cheaply cloneable. Interning or using <code>Rc</code> or <code>Arc</code> is recommended for
non-trivial data types.
<ul>
<li>The one exception to those rules is the <code>ty::steal::Steal</code> type,
which is used to cheaply modify MIR in place. See the definition
of <code>Steal</code> for more details. New uses of <code>Steal</code> should <strong>not</strong> be
added without alerting <code>@rust-lang/compiler</code>.</li>
</ul>
</li>
</ul>
<p>So, to add a query:</p>
<ul>
<li>Add an entry to <code>define_maps!</code> using the format above.</li>
<li>Possibly add a corresponding entry to the dep-node macro.</li>
<li>Link the provider by modifying the appropriate <code>provide</code> method;
or add a new one if needed and ensure that <code>rustc_driver</code> is invoking it.</li>
</ul>
<a class="header" href="print.html#query-structs-and-descriptions" id="query-structs-and-descriptions"><h4>Query structs and descriptions</h4></a>
<p>For each kind, the <code>define_maps</code> macro will generate a &quot;query struct&quot;
named after the query. This struct is a kind of a place-holder
describing the query. Each such struct implements the
<code>self::config::QueryConfig</code> trait, which has associated types for the
key/value of that particular query. Basically the code generated looks something
like this:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
// Dummy struct representing a particular kind of query:
pub struct type_of&lt;'tcx&gt; { phantom: PhantomData&lt;&amp;'tcx ()&gt; }

impl&lt;'tcx&gt; QueryConfig for type_of&lt;'tcx&gt; {
  type Key = DefId;
  type Value = Ty&lt;'tcx&gt;;
}
#}</code></pre></pre>
<p>There is an additional trait that you may wish to implement called
<code>self::config::QueryDescription</code>. This trait is used during cycle
errors to give a &quot;human readable&quot; name for the query, so that we can
summarize what was happening when the cycle occurred. Implementing
this trait is optional if the query key is <code>DefId</code>, but if you <em>don't</em>
implement it, you get a pretty generic error (&quot;processing <code>foo</code>...&quot;).
You can put new impls into the <code>config</code> module. They look something like this:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl&lt;'tcx&gt; QueryDescription for queries::type_of&lt;'tcx&gt; {
    fn describe(tcx: TyCtxt, key: DefId) -&gt; String {
        format!(&quot;computing the type of `{}`&quot;, tcx.item_path_str(key))
    }
}
#}</code></pre></pre>
<a class="header" href="print.html#incremental-compilation" id="incremental-compilation"><h1>Incremental compilation</h1></a>
<p>The incremental compilation scheme is, in essence, a surprisingly
simple extension to the overall query system. We'll start by describing
a slightly simplified variant of the real thing – the &quot;basic algorithm&quot; – and then describe
some possible improvements.</p>
<a class="header" href="print.html#the-basic-algorithm" id="the-basic-algorithm"><h2>The basic algorithm</h2></a>
<p>The basic algorithm is
called the <strong>red-green</strong> algorithm<sup class="footnote-reference"><a href="print.html#salsa">1</a></sup>. The high-level idea is
that, after each run of the compiler, we will save the results of all
the queries that we do, as well as the <strong>query DAG</strong>. The
<strong>query DAG</strong> is a <a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph">DAG</a> that indexes which queries executed which
other queries. So, for example, there would be an edge from a query Q1
to another query Q2 if computing Q1 required computing Q2 (note that
because queries cannot depend on themselves, this results in a DAG and
not a general graph).</p>
<p>On the next run of the compiler, then, we can sometimes reuse these
query results to avoid re-executing a query. We do this by assigning
every query a <strong>color</strong>:</p>
<ul>
<li>If a query is colored <strong>red</strong>, that means that its result during
this compilation has <strong>changed</strong> from the previous compilation.</li>
<li>If a query is colored <strong>green</strong>, that means that its result is
the <strong>same</strong> as the previous compilation.</li>
</ul>
<p>There are two key insights here:</p>
<ul>
<li>First, if all the inputs to query Q are colored green, then the
query Q <strong>must</strong> result in the same value as last time and hence
need not be re-executed (or else the compiler is not deterministic).</li>
<li>Second, even if some inputs to a query changes, it may be that it
<strong>still</strong> produces the same result as the previous compilation. In
particular, the query may only use part of its input.
<ul>
<li>Therefore, after executing a query, we always check whether it
produced the same result as the previous time. <strong>If it did,</strong> we
can still mark the query as green, and hence avoid re-executing
dependent queries.</li>
</ul>
</li>
</ul>
<a class="header" href="print.html#the-try-mark-green-algorithm" id="the-try-mark-green-algorithm"><h3>The try-mark-green algorithm</h3></a>
<p>At the core of incremental compilation is an algorithm called
&quot;try-mark-green&quot;. It has the job of determining the color of a given
query Q (which must not have yet been executed). In cases where Q has
red inputs, determining Q's color may involve re-executing Q so that
we can compare its output, but if all of Q's inputs are green, then we
can conclude that Q must be green without re-executing it or inspecting
its value at all. In the compiler, this allows us to avoid
deserializing the result from disk when we don't need it, and in fact
enables us to sometimes skip <em>serializing</em> the result as well
(see the refinements section below).</p>
<p>Try-mark-green works as follows:</p>
<ul>
<li>First check if the query Q was executed during the previous compilation.
<ul>
<li>If not, we can just re-execute the query as normal, and assign it the
color of red.</li>
</ul>
</li>
<li>If yes, then load the 'dependent queries' of Q.</li>
<li>If there is a saved result, then we load the <code>reads(Q)</code> vector from the
query DAG. The &quot;reads&quot; is the set of queries that Q executed during
its execution.
<ul>
<li>For each query R in <code>reads(Q)</code>, we recursively demand the color
of R using try-mark-green.
<ul>
<li>Note: it is important that we visit each node in <code>reads(Q)</code> in same order
as they occurred in the original compilation. See <a href="print.html#dag">the section on the query DAG below</a>.</li>
<li>If <strong>any</strong> of the nodes in <code>reads(Q)</code> wind up colored <strong>red</strong>, then Q is dirty.
<ul>
<li>We re-execute Q and compare the hash of its result to the hash of the result
from the previous compilation.</li>
<li>If the hash has not changed, we can mark Q as <strong>green</strong> and return.</li>
</ul>
</li>
<li>Otherwise, <strong>all</strong> of the nodes in <code>reads(Q)</code> must be <strong>green</strong>. In that case,
we can color Q as <strong>green</strong> and return.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><a name="dag"></p>
<a class="header" href="print.html#the-query-dag" id="the-query-dag"><h3>The query DAG</h3></a>
<p>The query DAG code is stored in
<a href="https://github.com/rust-lang/rust/tree/master/src/librustc/dep_graph"><code>src/librustc/dep_graph</code></a>. Construction of the DAG is done
by instrumenting the query execution.</p>
<p>One key point is that the query DAG also tracks ordering; that is, for
each query Q, we not only track the queries that Q reads, we track the
<strong>order</strong> in which they were read.  This allows try-mark-green to walk
those queries back in the same order. This is important because once a subquery comes back as red,
we can no longer be sure that Q will continue along the same path as before.
That is, imagine a query like this:</p>
<pre><code class="language-rust ignore">fn main_query(tcx) {
    if tcx.subquery1() {
        tcx.subquery2()
    } else {
        tcx.subquery3()
    }
}
</code></pre>
<p>Now imagine that in the first compilation, <code>main_query</code> starts by
executing <code>subquery1</code>, and this returns true. In that case, the next
query <code>main_query</code> executes will be <code>subquery2</code>, and <code>subquery3</code> will
not be executed at all.</p>
<p>But now imagine that in the <strong>next</strong> compilation, the input has
changed such that <code>subquery1</code> returns <strong>false</strong>. In this case, <code>subquery2</code> would never
execute. If try-mark-green were to visit <code>reads(main_query)</code> out of order,
however, it might visit <code>subquery2</code> before <code>subquery1</code>, and hence execute it.
This can lead to ICEs and other problems in the compiler.</p>
<a class="header" href="print.html#improvements-to-the-basic-algorithm" id="improvements-to-the-basic-algorithm"><h2>Improvements to the basic algorithm</h2></a>
<p>In the description basic algorithm, we said that at the end of
compilation we would save the results of all the queries that were
performed.  In practice, this can be quite wasteful – many of those
results are very cheap to recompute, and serializing and deserializing
them is not a particular win. In practice, what we would do is to save
<strong>the hashes</strong> of all the subqueries that we performed. Then, in select cases,
we <strong>also</strong> save the results.</p>
<p>This is why the incremental algorithm separates computing the
<strong>color</strong> of a node, which often does not require its value, from
computing the <strong>result</strong> of a node. Computing the result is done via a simple algorithm
like so:</p>
<ul>
<li>Check if a saved result for Q is available. If so, compute the color of Q.
If Q is green, deserialize and return the saved result.</li>
<li>Otherwise, execute Q.
<ul>
<li>We can then compare the hash of the result and color Q as green if
it did not change.</li>
</ul>
</li>
</ul>
<a class="header" href="print.html#footnotes" id="footnotes"><h1>Footnotes</h1></a>
<div class="footnote-definition" id="salsa"><sup class="footnote-definition-label">1</sup>
<p>I have long wanted to rename it to the Salsa algorithm, but it never caught on. -@nikomatsakis</p>
</div>
<a class="header" href="print.html#the-parser" id="the-parser"><h1>The Parser</h1></a>
<p>The parser is responsible for converting raw Rust source code into a structured
form which is easier for the compiler to work with, usually called an <a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree"><em>Abstract
Syntax Tree</em></a>. An AST mirrors the structure of a Rust program in memory,
using a <code>Span</code> to link a particular AST node back to its source text.</p>
<p>The bulk of the parser lives in the <a href="https://github.com/rust-lang/rust/tree/master/src/libsyntax">libsyntax</a> crate.</p>
<p>Like most parsers, the parsing process is composed of two main steps,</p>
<ul>
<li>lexical analysis – turn a stream of characters into a stream of token trees</li>
<li>parsing – turn the token trees into an AST</li>
</ul>
<p>The <code>syntax</code> crate contains several main players,</p>
<ul>
<li>a <a href="https://github.com/rust-lang/rust/blob/master/src/libsyntax/codemap.rs"><code>CodeMap</code></a> for mapping AST nodes to their source code</li>
<li>the <a href="https://github.com/rust-lang/rust/blob/master/src/libsyntax/ast.rs">ast module</a> contains types corresponding to each AST node</li>
<li>a <a href="https://github.com/rust-lang/rust/blob/master/src/libsyntax/parse/lexer/mod.rs"><code>StringReader</code></a> for lexing source code into tokens</li>
<li>the <a href="https://github.com/rust-lang/rust/tree/master/src/libsyntax/parse">parser module</a> and <a href="https://github.com/rust-lang/rust/blob/master/src/libsyntax/parse/parser.rs"><code>Parser</code></a> struct are in charge of actually parsing
tokens into AST nodes,</li>
<li>and a <a href="https://github.com/rust-lang/rust/blob/master/src/libsyntax/visit.rs">visit module</a> for walking the AST and inspecting or mutating the AST
nodes.</li>
</ul>
<p>The main entrypoint to the parser is via the various <code>parse_*</code> functions
in the <a href="https://github.com/rust-lang/rust/tree/master/src/libsyntax/parse">parser module</a>. They let you do things like turn a filemap into a
token stream, create a parser from the token stream, and then execute the
parser to get a <code>Crate</code> (the root AST node).</p>
<p>To minimise the amount of copying that is done, both the <code>StringReader</code> and
<code>Parser</code> have lifetimes which bind them to the parent <code>ParseSess</code>. This contains
all the information needed while parsing, as well as the <code>CodeMap</code> itself.</p>
<a class="header" href="print.html#macro-expansion" id="macro-expansion"><h1>Macro expansion</h1></a>
<p>Macro expansion happens during parsing. <code>rustc</code> has two parsers, in fact: the
normal Rust parser, and the macro parser. During the parsing phase, the normal
Rust parser will set aside the contents of macros and their invokations. Later,
before name resolution, macros are expanded using these portions of the code.
The macro parser, in turn, may call the normal Rust parser when it needs to
bind a metavariable (e.g.  <code>$my_expr</code>) while parsing the contents of a macro
invocation. The code for macro expansion is in
<a href="https://github.com/rust-lang/rust/tree/master/src/libsyntax/ext/tt"><code>src/libsyntax/ext/tt/</code></a>. This chapter aims to explain how macro
expansion works.</p>
<a class="header" href="print.html#example" id="example"><h3>Example</h3></a>
<p>It's helpful to have an example to refer to. For the remainder of this chapter,
whenever we refer to the &quot;example <em>definition</em>&quot;, we mean the following:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
macro_rules! printer {
    (print $mvar:ident) =&gt; {
        println!(&quot;{}&quot;, $mvar);
    }
    (print twice $mvar:ident) =&gt; {
        println!(&quot;{}&quot;, $mvar);
        println!(&quot;{}&quot;, $mvar);
    }
}
#}</code></pre></pre>
<p><code>$mvar</code> is called a <em>metavariable</em>. Unlike normal variables, rather than
binding to a value in a computation, a metavariable binds <em>at compile time</em> to
a tree of <em>tokens</em>.  A <em>token</em> is a single &quot;unit&quot; of the grammar, such as an
identifier (e.g. <code>foo</code>) or punctuation (e.g. <code>=&gt;</code>). There are also other
special tokens, such as <code>EOF</code>, which indicates that there are no more tokens.
Token trees resulting from paired parentheses-like characters (<code>(</code>...<code>)</code>,
<code>[</code>...<code>]</code>, and <code>{</code>...<code>}</code>) – they include the open and close and all the tokens
in between (we do require that parentheses-like characters be balanced). Having
macro expansion operate on token streams rather than the raw bytes of a source
file abstracts away a lot of complexity. The macro expander (and much of the
rest of the compiler) doesn't really care that much about the exact line and
column of some syntactic construct in the code; it cares about what constructs
are used in the code. Using tokens allows us to care about <em>what</em> without
worrying about <em>where</em>. For more information about tokens, see the
<a href="./the-parser.html">Parsing</a> chapter of this book.</p>
<p>Whenever we refer to the &quot;example <em>invocation</em>&quot;, we mean the following snippet:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
printer!(print foo); // Assume `foo` is a variable defined somewhere else...
#}</code></pre></pre>
<p>The process of expanding the macro invocation into the syntax tree
<code>println!(&quot;{}&quot;, foo)</code> and then expanding that into a call to <code>Display::fmt</code> is
called <em>macro expansion</em>, and it is the topic of this chapter.</p>
<a class="header" href="print.html#the-macro-parser" id="the-macro-parser"><h3>The macro parser</h3></a>
<p>There are two parts to macro expansion: parsing the definition and parsing the
invocations. Interestingly, both are done by the macro parser.</p>
<p>Basically, the macro parser is like an NFA-based regex parser. It uses an
algorithm similar in spirit to the <a href="https://en.wikipedia.org/wiki/Earley_parser">Earley parsing
algorithm</a>. The macro parser is
defined in <a href="https://github.com/rust-lang/rust/tree/master/src/libsyntax/ext/tt/macro_parser.rs"><code>src/libsyntax/ext/tt/macro_parser.rs</code></a>.</p>
<p>The interface of the macro parser is as follows (this is slightly simplified):</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn parse(
    sess: ParserSession,
    tts: TokenStream,
    ms: &amp;[TokenTree]
) -&gt; NamedParseResult
#}</code></pre></pre>
<p>In this interface:</p>
<ul>
<li><code>sess</code> is a &quot;parsing session&quot;, which keeps track of some metadata. Most
notably, this is used to keep track of errors that are generated so they can
be reported to the user.</li>
<li><code>tts</code> is a stream of tokens. The macro parser's job is to consume the raw
stream of tokens and output a binding of metavariables to corresponding token
trees.</li>
<li><code>ms</code> a <em>matcher</em>. This is a sequence of token trees that we want to match
<code>tts</code> against.</li>
</ul>
<p>In the analogy of a regex parser, <code>tts</code> is the input and we are matching it
against the pattern <code>ms</code>. Using our examples, <code>tts</code> could be the stream of
tokens containing the inside of the example invocation <code>print foo</code>, while <code>ms</code>
might be the sequence of token (trees) <code>print $mvar:ident</code>.</p>
<p>The output of the parser is a <code>NamedParserResult</code>, which indicates which of
three cases has occured:</p>
<ul>
<li>Success: <code>tts</code> matches the given matcher <code>ms</code>, and we have produced a binding
from metavariables to the corresponding token trees.</li>
<li>Failure: <code>tts</code> does not match <code>ms</code>. This results in an error message such as
&quot;No rule expected token <em>blah</em>&quot;.</li>
<li>Error: some fatal error has occured <em>in the parser</em>. For example, this happens
if there are more than one pattern match, since that indicates the macro is
ambiguous.</li>
</ul>
<p>The full interface is defined <a href="https://github.com/rust-lang/rust/blob/a97cd17f5d71fb4ec362f4fbd79373a6e7ed7b82/src/libsyntax/ext/tt/macro_parser.rs#L421">here</a>.</p>
<p>The macro parser does pretty much exactly the same as a normal regex parser with
one exception: in order to parse different types of metavariables, such as
<code>ident</code>, <code>block</code>, <code>expr</code>, etc., the macro parser must sometimes call back to the
normal Rust parser.</p>
<p>As mentioned above, both definitions and invocations of macros are parsed using
the macro parser. This is extremely non-intuitive and self-referential. The code
to parse macro <em>definitions</em> is in
<a href="https://github.com/rust-lang/rust/tree/master/src/libsyntax/ext/tt/macro_rules.rs"><code>src/libsyntax/ext/tt/macro_rules.rs</code></a>. It defines the pattern for
matching for a macro definition as <code>$( $lhs:tt =&gt; $rhs:tt );+</code>. In other words,
a <code>macro_rules</code> defintion should have in its body at least one occurence of a
token tree followed by <code>=&gt;</code> followed by another token tree. When the compiler
comes to a <code>macro_rules</code> definition, it uses this pattern to match the two token
trees per rule in the definition of the macro <em>using the macro parser itself</em>.
In our example definition, the metavariable <code>$lhs</code> would match the patterns of
both arms: <code>(print $mvar:ident)</code> and <code>(print twice $mvar:ident)</code>.  And <code>$rhs</code>
would match the bodies of both arms: <code>{ println!(&quot;{}&quot;, $mvar); }</code> and <code>{ println!(&quot;{}&quot;, $mvar); println!(&quot;{}&quot;, $mvar); }</code>. The parser would keep this
knowledge around for when it needs to expand a macro invocation.</p>
<p>When the compiler comes to a macro invocation, it parses that invocation using
the same NFA-based macro parser that is described above. However, the matcher
used is the first token tree (<code>$lhs</code>) extracted from the arms of the macro
<em>definition</em>. Using our example, we would try to match the token stream <code>print foo</code> from the invocation against the matchers <code>print $mvar:ident</code> and <code>print twice $mvar:ident</code> that we previously extracted from the definition.  The
algorithm is exactly the same, but when the macro parser comes to a place in the
current matcher where it needs to match a <em>non-terminal</em> (e.g. <code>$mvar:ident</code>),
it calls back to the normal Rust parser to get the contents of that
non-terminal. In this case, the Rust parser would look for an <code>ident</code> token,
which it finds (<code>foo</code>) and returns to the macro parser. Then, the macro parser
proceeds in parsing as normal. Also, note that exactly one of the matchers from
the various arms should match the invocation; if there is more than one match,
the parse is ambiguous, while if there are no matches at all, there is a syntax
error.</p>
<p>For more information about the macro parser's implementation, see the comments
in <a href="https://github.com/rust-lang/rust/tree/master/src/libsyntax/ext/tt/macro_parser.rs"><code>src/libsyntax/ext/tt/macro_parser.rs</code></a>.</p>
<a class="header" href="print.html#hygiene" id="hygiene"><h3>Hygiene</h3></a>
<p>TODO</p>
<a class="header" href="print.html#procedural-macros" id="procedural-macros"><h3>Procedural Macros</h3></a>
<p>TODO</p>
<a class="header" href="print.html#custom-derive" id="custom-derive"><h3>Custom Derive</h3></a>
<p>TODO</p>
<a class="header" href="print.html#name-resolution" id="name-resolution"><h1>Name resolution</h1></a>
<p>The name resolution is a separate pass in the compiler. Its input is the syntax
tree, produced by parsing input files. It produces links from all the names in
the source to relevant places where the name was introduced. It also generates
helpful error messages, like typo suggestions or traits to import.</p>
<p>The name resolution lives in the <code>librustc_resolve</code> crate, with the meat in
<code>lib.rs</code> and some helpers or symbol-type specific logic in the other modules.</p>
<a class="header" href="print.html#namespaces" id="namespaces"><h2>Namespaces</h2></a>
<p>Different kind of symbols live in different namespaces ‒ eg. types don't
clash with variables. This usually doesn't happen, because variables start with
lower-case letter while types with upper case one, but this is only a
convention. This is legal Rust code that'll compile (with warnings):</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
type x = u32;
let x: x = 1;
let y: x = 2; // See? x is still a type here.
#}</code></pre></pre>
<p>To cope with this, and with slightly different scoping rules for these
namespaces, the resolver keeps them separated and builds separate structures for
them.</p>
<p>In other words, when the code talks about namespaces, it doesn't mean the module
hierarchy, it's types vs. values vs. macros.</p>
<a class="header" href="print.html#scopes-and-ribs" id="scopes-and-ribs"><h2>Scopes and ribs</h2></a>
<p>A name is visible only in certain area in the source code. This forms a
hierarchical structure, but not necessarily a simple one ‒ if one scope is part
of another, it doesn't mean the name visible in the outer one is also visible in
the inner one, or that it refers to the same thing.</p>
<p>To cope with that, the compiler introduces the concept of Ribs. This is
abstraction of a scope. Every time the set of visible names potentially changes,
a new rib is pushed onto a stack. The places where this can happen includes for
example:</p>
<ul>
<li>The obvious places ‒ curly braces enclosing a block, function boundaries,
modules.</li>
<li>Introducing a let binding ‒ this can shadow another binding with the same
name.</li>
<li>Macro expansion border ‒ to cope with macro hygiene.</li>
</ul>
<p>When searching for a name, the stack of ribs is traversed from the innermost
outwards. This helps to find the closest meaning of the name (the one not
shadowed by anything else). The transition to outer rib may also change the
rules what names are usable ‒ if there are nested functions (not closures), the
inner one can't access parameters and local bindings of the outer one, even
though they should be visible by ordinary scoping rules. An example:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn do_something&lt;T: Default&gt;(val: T) { // &lt;- New rib in both types and values (1)
    // `val` is accessible, as is the helper function
    // `T` is accessible
    let helper = || { // New rib on `helper` (2) and another on the block (3)
        // `val` is accessible here
    }; // End of (3)
    // `val` is accessible, `helper` variable shadows `helper` function
    fn helper() { // &lt;- New rib in both types and values (4)
        // `val` is not accessible here, (4) is not transparent for locals)
        // `T` is not accessible here
    } // End of (4)
    let val = T::default(); // New rib (5)
    // `val` is the variable, not the parameter here
} // End of (5), (2) and (1)
#}</code></pre></pre>
<p>Because the rules for different namespaces are a bit different, each namespace
has its own independent rib stack that is constructed in parallel to the others.</p>
<a class="header" href="print.html#overall-strategy" id="overall-strategy"><h2>Overall strategy</h2></a>
<p>To perform the name resolution of the whole crate, the syntax tree is traversed
top-down and every encountered name is resolved. This works for most kinds of
names, because at the point of use of a name it is already introduced in the Rib
hierarchy.</p>
<p>There are some exceptions to this. Items are bit tricky, because they can be
used even before encountered ‒ therefore every block needs to be first scanned
for items to fill in its Rib.</p>
<p>Other, even more problematic ones, are imports which need recursive fixed-point
resolution and macros, that need to be resolved and expanded before the rest of
the code can be processed.</p>
<p>Therefore, the resolution is performed in multiple stages.</p>
<a class="header" href="print.html#todo" id="todo"><h2>TODO:</h2></a>
<p>This is a result of the first pass of learning the code. It is definitely
incomplete and not detailed enough. It also might be inaccurate in places.
Still, it probably provides useful first guidepost to what happens in there.</p>
<ul>
<li>What exactly does it link to and how is that published and consumed by
following stages of compilation?</li>
<li>Who calls it and how it is actually used.</li>
<li>Is it a pass and then the result is only used, or can it be computed
incrementally (eg. for RLS)?</li>
<li>The overall strategy description is a bit vague.</li>
<li>Where does the name <code>Rib</code> come from?</li>
<li>Does this thing have its own tests, or is it tested only as part of some e2e
testing?</li>
</ul>
<a class="header" href="print.html#the-hir" id="the-hir"><h1>The HIR</h1></a>
<p>The HIR – &quot;High-level IR&quot; – is the primary IR used in most of rustc.
It is a desugared version of the &quot;abstract syntax tree&quot; (AST) that is generated
after parsing, macro expansion, and name resolution have completed. Many parts
of HIR resemble Rust surface syntax quite closely, with the exception that some
of Rust's expression forms have been desugared away (as an example, <code>for</code> loops
are converted into a <code>loop</code> and do not appear in the HIR).</p>
<p>This chapter covers the main concepts of the HIR.</p>
<p>You can view the HIR representation of your code by passing the
<code>-Zunpretty=hir-tree</code> flag to rustc:</p>
<pre><code>cargo rustc -- -Zunpretty=hir-tree
</code></pre>
<a class="header" href="print.html#out-of-band-storage-and-the-crate-type" id="out-of-band-storage-and-the-crate-type"><h3>Out-of-band storage and the <code>Crate</code> type</h3></a>
<p>The top-level data-structure in the HIR is the <code>Crate</code>, which stores
the contents of the crate currently being compiled (we only ever
construct HIR for the current crate). Whereas in the AST the crate
data structure basically just contains the root module, the HIR
<code>Crate</code> structure contains a number of maps and other things that
serve to organize the content of the crate for easier access.</p>
<p>For example, the contents of individual items (e.g. modules,
functions, traits, impls, etc) in the HIR are not immediately
accessible in the parents. So, for example, if there is a module item
<code>foo</code> containing a function <code>bar()</code>:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
mod foo {
    fn bar() { }
}
#}</code></pre></pre>
<p>then in the HIR the representation of module <code>foo</code> (the <code>Mod</code>
stuct) would only have the <strong><code>ItemId</code></strong> <code>I</code> of <code>bar()</code>. To get the
details of the function <code>bar()</code>, we would lookup <code>I</code> in the
<code>items</code> map.</p>
<p>One nice result from this representation is that one can iterate
over all items in the crate by iterating over the key-value pairs
in these maps (without the need to trawl through the whole HIR).
There are similar maps for things like trait items and impl items,
as well as &quot;bodies&quot; (explained below).</p>
<p>The other reason to set up the representation this way is for better
integration with incremental compilation. This way, if you gain access
to an <code>&amp;hir::Item</code> (e.g. for the mod <code>foo</code>), you do not immediately
gain access to the contents of the function <code>bar()</code>. Instead, you only
gain access to the <strong>id</strong> for <code>bar()</code>, and you must invoke some
function to lookup the contents of <code>bar()</code> given its id; this gives the
compiler a chance to observe that you accessed the data for <code>bar()</code>,
and then record the dependency.</p>
<a class="header" href="print.html#identifiers-in-the-hir" id="identifiers-in-the-hir"><h3>Identifiers in the HIR</h3></a>
<p>Most of the code that has to deal with things in HIR tends not to
carry around references into the HIR, but rather to carry around
<em>identifier numbers</em> (or just &quot;ids&quot;). Right now, you will find four
sorts of identifiers in active use:</p>
<ul>
<li><code>DefId</code> – primarily names &quot;definitions&quot; or top-level items.
<ul>
<li>You can think of a <code>DefId</code> as shorthand for a very explicit and complete
path, like <code>std::collections::HashMap</code>. However, these paths are able to
name things that are not nameable in normal Rust (e.g. <code>impl</code>s), and they
also include extra information about the crate (such as its version number,
since two versions of the same crate can co-exist).</li>
<li>A <code>DefId</code> really consists of two parts, a <code>CrateNum</code> (which identifies the
crate) and a <code>DefIndex</code> (which indexes into a list of items that is
maintained per crate).</li>
</ul>
</li>
<li><code>HirId</code> – combines the index of a particular item with an offset within
that item.
<ul>
<li>The key point of an <code>HirId</code> is that it is <em>relative</em> to some item (which is
named via a <code>DefId</code>).</li>
</ul>
</li>
<li><code>BodyId</code> – an absolute identifier that refers to a specific body (definition
of a function or constant) in the crate. It is currently effectively a
&quot;newtype'd&quot; <code>NodeId</code>.</li>
<li><code>NodeId</code> – an absolute ID that identifies a single node in the HIR tree.
<ul>
<li>While these are still in common use, <strong>they are being slowly phased out</strong>.</li>
<li>Since they are absolute within the crate, adding a new node anywhere in the
tree causes the <code>NodeId</code>s of all subsequent code in the crate to change.
This is terrible for incremental compilation, as you can perhaps imagine.</li>
</ul>
</li>
</ul>
<a class="header" href="print.html#the-hir-map" id="the-hir-map"><h3>The HIR Map</h3></a>
<p>Most of the time when you are working with the HIR, you will do so via
the <strong>HIR Map</strong>, accessible in the tcx via <code>tcx.hir</code> (and defined in
the <code>hir::map</code> module). The HIR map contains a number of methods to
convert between IDs of various kinds and to lookup data associated
with an HIR node.</p>
<p>For example, if you have a <code>DefId</code>, and you would like to convert it
to a <code>NodeId</code>, you can use <code>tcx.hir.as_local_node_id(def_id)</code>. This
returns an <code>Option&lt;NodeId&gt;</code> – this will be <code>None</code> if the def-id
refers to something outside of the current crate (since then it has no
HIR node), but otherwise returns <code>Some(n)</code> where <code>n</code> is the node-id of
the definition.</p>
<p>Similarly, you can use <code>tcx.hir.find(n)</code> to lookup the node for a
<code>NodeId</code>. This returns a <code>Option&lt;Node&lt;'tcx&gt;&gt;</code>, where <code>Node</code> is an enum
defined in the map; by matching on this you can find out what sort of
node the node-id referred to and also get a pointer to the data
itself. Often, you know what sort of node <code>n</code> is – e.g. if you know
that <code>n</code> must be some HIR expression, you can do
<code>tcx.hir.expect_expr(n)</code>, which will extract and return the
<code>&amp;hir::Expr</code>, panicking if <code>n</code> is not in fact an expression.</p>
<p>Finally, you can use the HIR map to find the parents of nodes, via
calls like <code>tcx.hir.get_parent_node(n)</code>.</p>
<a class="header" href="print.html#hir-bodies" id="hir-bodies"><h3>HIR Bodies</h3></a>
<p>A <strong>body</strong> represents some kind of executable code, such as the body
of a function/closure or the definition of a constant. Bodies are
associated with an <strong>owner</strong>, which is typically some kind of item
(e.g. an <code>fn()</code> or <code>const</code>), but could also be a closure expression
(e.g. <code>|x, y| x + y</code>). You can use the HIR map to find the body
associated with a given <code>DefId</code> (<code>maybe_body_owned_by()</code>) or to find
the owner of a body (<code>body_owner_def_id()</code>).</p>
<a class="header" href="print.html#the-ty-module-representing-types" id="the-ty-module-representing-types"><h1>The <code>ty</code> module: representing types</h1></a>
<p>The <code>ty</code> module defines how the Rust compiler represents types
internally. It also defines the <em>typing context</em> (<code>tcx</code> or <code>TyCtxt</code>),
which is the central data structure in the compiler.</p>
<a class="header" href="print.html#the-tcx-and-how-it-uses-lifetimes" id="the-tcx-and-how-it-uses-lifetimes"><h2>The tcx and how it uses lifetimes</h2></a>
<p>The <code>tcx</code> (&quot;typing context&quot;) is the central data structure in the
compiler. It is the context that you use to perform all manner of
queries. The struct <code>TyCtxt</code> defines a reference to this shared context:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
tcx: TyCtxt&lt;'a, 'gcx, 'tcx&gt;
//          --  ----  ----
//          |   |     |
//          |   |     innermost arena lifetime (if any)
//          |   &quot;global arena&quot; lifetime
//          lifetime of this reference
#}</code></pre></pre>
<p>As you can see, the <code>TyCtxt</code> type takes three lifetime parameters.
These lifetimes are perhaps the most complex thing to understand about
the tcx. During Rust compilation, we allocate most of our memory in
<strong>arenas</strong>, which are basically pools of memory that get freed all at
once. When you see a reference with a lifetime like <code>'tcx</code> or <code>'gcx</code>,
you know that it refers to arena-allocated data (or data that lives as
long as the arenas, anyhow).</p>
<p>We use two distinct levels of arenas. The outer level is the &quot;global
arena&quot;. This arena lasts for the entire compilation: so anything you
allocate in there is only freed once compilation is basically over
(actually, when we shift to executing LLVM).</p>
<p>To reduce peak memory usage, when we do type inference, we also use an
inner level of arena. These arenas get thrown away once type inference
is over. This is done because type inference generates a lot of
&quot;throw-away&quot; types that are not particularly interesting after type
inference completes, so keeping around those allocations would be
wasteful.</p>
<p>Often, we wish to write code that explicitly asserts that it is not
taking place during inference. In that case, there is no &quot;local&quot;
arena, and all the types that you can access are allocated in the
global arena.  To express this, the idea is to use the same lifetime
for the <code>'gcx</code> and <code>'tcx</code> parameters of <code>TyCtxt</code>. Just to be a touch
confusing, we tend to use the name <code>'tcx</code> in such contexts. Here is an
example:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn not_in_inference&lt;'a, 'tcx&gt;(tcx: TyCtxt&lt;'a, 'tcx, 'tcx&gt;, def_id: DefId) {
    //                                        ----  ----
    //                                        Using the same lifetime here asserts
    //                                        that the innermost arena accessible through
    //                                        this reference *is* the global arena.
}
#}</code></pre></pre>
<p>In contrast, if we want to code that can be usable during type inference, then you
need to declare a distinct <code>'gcx</code> and <code>'tcx</code> lifetime parameter:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn maybe_in_inference&lt;'a, 'gcx, 'tcx&gt;(tcx: TyCtxt&lt;'a, 'gcx, 'tcx&gt;, def_id: DefId) {
    //                                                ----  ----
    //                                        Using different lifetimes here means that
    //                                        the innermost arena *may* be distinct
    //                                        from the global arena (but doesn't have to be).
}
#}</code></pre></pre>
<a class="header" href="print.html#allocating-and-working-with-types" id="allocating-and-working-with-types"><h3>Allocating and working with types</h3></a>
<p>Rust types are represented using the <code>Ty&lt;'tcx&gt;</code> defined in the <code>ty</code>
module (not to be confused with the <code>Ty</code> struct from <a href="./hir.html">the HIR</a>). This
is in fact a simple type alias for a reference with <code>'tcx</code> lifetime:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub type Ty&lt;'tcx&gt; = &amp;'tcx TyS&lt;'tcx&gt;;
#}</code></pre></pre>
<p>You can basically ignore the <code>TyS</code> struct – you will basically never
access it explicitly. We always pass it by reference using the
<code>Ty&lt;'tcx&gt;</code> alias – the only exception I think is to define inherent
methods on types. Instances of <code>TyS</code> are only ever allocated in one of
the rustc arenas (never e.g. on the stack).</p>
<p>One common operation on types is to <strong>match</strong> and see what kinds of
types they are. This is done by doing <code>match ty.sty</code>, sort of like this:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn test_type&lt;'tcx&gt;(ty: Ty&lt;'tcx&gt;) {
    match ty.sty {
        ty::TyArray(elem_ty, len) =&gt; { ... }
        ...
    }
}
#}</code></pre></pre>
<p>The <code>sty</code> field (the origin of this name is unclear to me; perhaps
structural type?) is of type <code>TypeVariants&lt;'tcx&gt;</code>, which is an enum
defining all of the different kinds of types in the compiler.</p>
<blockquote>
<p>N.B. inspecting the <code>sty</code> field on types during type inference can be
risky, as there may be inference variables and other things to
consider, or sometimes types are not yet known that will become
known later.).</p>
</blockquote>
<p>To allocate a new type, you can use the various <code>mk_</code> methods defined
on the <code>tcx</code>. These have names that correpond mostly to the various kinds
of type variants. For example:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let array_ty = tcx.mk_array(elem_ty, len * 2);
#}</code></pre></pre>
<p>These methods all return a <code>Ty&lt;'tcx&gt;</code> – note that the lifetime you
get back is the lifetime of the innermost arena that this <code>tcx</code> has
access to. In fact, types are always canonicalized and interned (so we
never allocate exactly the same type twice) and are always allocated
in the outermost arena where they can be (so, if they do not contain
any inference variables or other &quot;temporary&quot; types, they will be
allocated in the global arena). However, the lifetime <code>'tcx</code> is always
a safe approximation, so that is what you get back.</p>
<blockquote>
<p>NB. Because types are interned, it is possible to compare them for
equality efficiently using <code>==</code> – however, this is almost never what
you want to do unless you happen to be hashing and looking for
duplicates. This is because often in Rust there are multiple ways to
represent the same type, particularly once inference is involved. If
you are going to be testing for type equality, you probably need to
start looking into the inference code to do it right.</p>
</blockquote>
<p>You can also find various common types in the <code>tcx</code> itself by accessing
<code>tcx.types.bool</code>, <code>tcx.types.char</code>, etc (see <code>CommonTypes</code> for more).</p>
<a class="header" href="print.html#beyond-types-other-kinds-of-arena-allocated-data-structures" id="beyond-types-other-kinds-of-arena-allocated-data-structures"><h3>Beyond types: other kinds of arena-allocated data structures</h3></a>
<p>In addition to types, there are a number of other arena-allocated data
structures that you can allocate, and which are found in this
module. Here are a few examples:</p>
<ul>
<li><code>Substs</code>, allocated with <code>mk_substs</code> – this will intern a slice of types, often used to
specify the values to be substituted for generics (e.g. <code>HashMap&lt;i32, u32&gt;</code>
would be represented as a slice <code>&amp;'tcx [tcx.types.i32, tcx.types.u32]</code>).</li>
<li><code>TraitRef</code>, typically passed by value – a <strong>trait reference</strong>
consists of a reference to a trait along with its various type
parameters (including <code>Self</code>), like <code>i32: Display</code> (here, the def-id
would reference the <code>Display</code> trait, and the substs would contain
<code>i32</code>).</li>
<li><code>Predicate</code> defines something the trait system has to prove (see <code>traits</code> module).</li>
</ul>
<a class="header" href="print.html#import-conventions" id="import-conventions"><h3>Import conventions</h3></a>
<p>Although there is no hard and fast rule, the <code>ty</code> module tends to be used like so:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
use ty::{self, Ty, TyCtxt};
#}</code></pre></pre>
<p>In particular, since they are so common, the <code>Ty</code> and <code>TyCtxt</code> types
are imported directly. Other types are often referenced with an
explicit <code>ty::</code> prefix (e.g. <code>ty::TraitRef&lt;'tcx&gt;</code>). But some modules
choose to import a larger or smaller set of names explicitly.</p>
<a class="header" href="print.html#type-inference" id="type-inference"><h1>Type inference</h1></a>
<p>The type inference is based on the standard Hindley-Milner (HM) type inference
algorithm, but extended in various way to accommodate subtyping, region
inference, and higher-ranked types.</p>
<a class="header" href="print.html#a-note-on-terminology" id="a-note-on-terminology"><h2>A note on terminology</h2></a>
<p>We use the notation <code>?T</code> to refer to inference variables, also called
existential variables.</p>
<p>We use the terms &quot;region&quot; and &quot;lifetime&quot; interchangeably. Both refer to
the <code>'a</code> in <code>&amp;'a T</code>.</p>
<p>The term &quot;bound region&quot; refers to a region that is bound in a function
signature, such as the <code>'a</code> in <code>for&lt;'a&gt; fn(&amp;'a u32)</code>. A region is
&quot;free&quot; if it is not bound.</p>
<a class="header" href="print.html#creating-an-inference-context" id="creating-an-inference-context"><h2>Creating an inference context</h2></a>
<p>You create and &quot;enter&quot; an inference context by doing something like
the following:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
tcx.infer_ctxt().enter(|infcx| {
    // Use the inference context `infcx` here.
})
#}</code></pre></pre>
<p>Each inference context creates a short-lived type arena to store the
fresh types and things that it will create, as described in the
<a href="ty.html">chapter on the <code>ty</code> module</a>. This arena is created by the <code>enter</code>
function and disposed of after it returns.</p>
<p>Within the closure, <code>infcx</code> has the type <code>InferCtxt&lt;'cx, 'gcx, 'tcx&gt;</code>
for some fresh <code>'cx</code> and <code>'tcx</code> – the latter corresponds to the lifetime of
this temporary arena, and the <code>'cx</code> is the lifetime of the <code>InferCtxt</code> itself.
(Again, see the <a href="ty.html"><code>ty</code> chapter</a> for more details on this setup.)</p>
<p>The <code>tcx.infer_ctxt</code> method actually returns a build, which means
there are some kinds of configuration you can do before the <code>infcx</code> is
created. See <code>InferCtxtBuilder</code> for more information.</p>
<a class="header" href="print.html#inference-variables" id="inference-variables"><h2>Inference variables</h2></a>
<p>The main purpose of the inference context is to house a bunch of
<strong>inference variables</strong> – these represent types or regions whose precise
value is not yet known, but will be uncovered as we perform type-checking.</p>
<p>If you're familiar with the basic ideas of unification from H-M type
systems, or logic languages like Prolog, this is the same concept. If
you're not, you might want to read a tutorial on how H-M type
inference works, or perhaps this blog post on
<a href="http://smallcultfollowing.com/babysteps/blog/2017/03/25/unification-in-chalk-part-1/">unification in the Chalk project</a>.</p>
<p>All said, the inference context stores four kinds of inference variables as of
writing:</p>
<ul>
<li>Type variables, which come in three varieties:
<ul>
<li>General type variables (the most common). These can be unified with any type.</li>
<li>Integral type variables, which can only be unified with an integral type, and
arise from an integer literal expression like <code>22</code>.</li>
<li>Float type variables, which can only be unified with a float type, and
arise from a float literal expression like <code>22.0</code>.</li>
</ul>
</li>
<li>Region variables, which represent lifetimes, and arise all over the place.</li>
</ul>
<p>All the type variables work in much the same way: you can create a new
type variable, and what you get is <code>Ty&lt;'tcx&gt;</code> representing an
unresolved type <code>?T</code>. Then later you can apply the various operations
that the inferencer supports, such as equality or subtyping, and it
will possibly <strong>instantiate</strong> (or <strong>bind</strong>) that <code>?T</code> to a specific
value as a result.</p>
<p>The region variables work somewhat differently, and are described
below in a separate section.</p>
<a class="header" href="print.html#enforcing-equality--subtyping" id="enforcing-equality--subtyping"><h2>Enforcing equality / subtyping</h2></a>
<p>The most basic operations you can perform in the type inferencer is
<strong>equality</strong>, which forces two types <code>T</code> and <code>U</code> to be the same. The
recommended way to add an equality constraint is using the <code>at</code>
method, roughly like so:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
infcx.at(...).eq(t, u);
#}</code></pre></pre>
<p>The first <code>at()</code> call provides a bit of context, i.e. why you are
doing this unification, and in what environment, and the <code>eq</code> method
performs the actual equality constraint.</p>
<p>When you equate things, you force them to be precisely equal. Equating
returns an <code>InferResult</code> – if it returns <code>Err(err)</code>, then equating
failed, and the enclosing <code>TypeError</code> will tell you what went wrong.</p>
<p>The success case is perhaps more interesting. The &quot;primary&quot; return
type of <code>eq</code> is <code>()</code> – that is, when it succeeds, it doesn't return a
value of any particular interest. Rather, it is executed for its
side-effects of constraining type variables and so forth. However, the
actual return type is not <code>()</code>, but rather <code>InferOk&lt;()&gt;</code>. The
<code>InferOk</code> type is used to carry extra trait obligations – your job is
to ensure that these are fulfilled (typically by enrolling them in a
fulfillment context). See the <a href="trait-resolution.html">trait chapter</a> for more background on that.</p>
<p>You can similarly enforce subtyping through <code>infcx.at(..).sub(..)</code>. The same
basic concepts as above apply.</p>
<a class="header" href="print.html#trying-equality" id="trying-equality"><h2>&quot;Trying&quot; equality</h2></a>
<p>Sometimes you would like to know if it is <em>possible</em> to equate two
types without error.  You can test that with <code>infcx.can_eq</code> (or
<code>infcx.can_sub</code> for subtyping). If this returns <code>Ok</code>, then equality
is possible – but in all cases, any side-effects are reversed.</p>
<p>Be aware, though, that the success or failure of these methods is always
<strong>modulo regions</strong>. That is, two types <code>&amp;'a u32</code> and <code>&amp;'b u32</code> will
return <code>Ok</code> for <code>can_eq</code>, even if <code>'a != 'b</code>.  This falls out from the
&quot;two-phase&quot; nature of how we solve region constraints.</p>
<a class="header" href="print.html#snapshots" id="snapshots"><h2>Snapshots</h2></a>
<p>As described in the previous section on <code>can_eq</code>, often it is useful
to be able to do a series of operations and then roll back their
side-effects. This is done for various reasons: one of them is to be
able to backtrack, trying out multiple possibilities before settling
on which path to take. Another is in order to ensure that a series of
smaller changes take place atomically or not at all.</p>
<p>To allow for this, the inference context supports a <code>snapshot</code> method.
When you call it, it will start recording changes that occur from the
operations you perform. When you are done, you can either invoke
<code>rollback_to</code>, which will undo those changes, or else <code>confirm</code>, which
will make the permanent. Snapshots can be nested as long as you follow
a stack-like discipline.</p>
<p>Rather than use snapshots directly, it is often helpful to use the
methods like <code>commit_if_ok</code> or <code>probe</code> that encapsulate higher-level
patterns.</p>
<a class="header" href="print.html#subtyping-obligations" id="subtyping-obligations"><h2>Subtyping obligations</h2></a>
<p>One thing worth discussing is subtyping obligations. When you force
two types to be a subtype, like <code>?T &lt;: i32</code>, we can often convert those
into equality constraints. This follows from Rust's rather limited notion
of subtyping: so, in the above case, <code>?T &lt;: i32</code> is equivalent to <code>?T = i32</code>.</p>
<p>However, in some cases we have to be more careful. For example, when
regions are involved. So if you have <code>?T &lt;: &amp;'a i32</code>, what we would do
is to first &quot;generalize&quot; <code>&amp;'a i32</code> into a type with a region variable:
<code>&amp;'?b i32</code>, and then unify <code>?T</code> with that (<code>?T = &amp;'?b i32</code>). We then
relate this new variable with the original bound:</p>
<pre><code>&amp;'?b i32 &lt;: &amp;'a i32
</code></pre>
<p>This will result in a region constraint (see below) of <code>'?b: 'a</code>.</p>
<p>One final interesting case is relating two unbound type variables,
like <code>?T &lt;: ?U</code>.  In that case, we can't make progress, so we enqueue
an obligation <code>Subtype(?T, ?U)</code> and return it via the <code>InferOk</code>
mechanism. You'll have to try again when more details about <code>?T</code> or
<code>?U</code> are known.</p>
<a class="header" href="print.html#region-constraints" id="region-constraints"><h2>Region constraints</h2></a>
<p>Regions are inferred somewhat differently from types. Rather than
eagerly unifying things, we simply collect constraints as we go, but
make (almost) no attempt to solve regions. These constraints have the
form of an &quot;outlives&quot; constraint:</p>
<pre><code>'a: 'b
</code></pre>
<p>Actually, the code tends to view them as a subregion relation, but it's the same
idea:</p>
<pre><code>'b &lt;= 'a
</code></pre>
<p>(There are various other kinds of constriants, such as &quot;verifys&quot;; see
the <code>region_constraints</code> module for details.)</p>
<p>There is one case where we do some amount of eager unification. If you have an equality constraint
between two regions</p>
<pre><code>'a = 'b
</code></pre>
<p>we will record that fact in a unification table. You can then use
<code>opportunistic_resolve_var</code> to convert <code>'b</code> to <code>'a</code> (or vice
versa). This is sometimes needed to ensure termination of fixed-point
algorithms.</p>
<a class="header" href="print.html#extracting-region-constraints" id="extracting-region-constraints"><h2>Extracting region constraints</h2></a>
<p>Ultimately, region constraints are only solved at the very end of
type-checking, once all other constraints are known. There are two
ways to solve region constraints right now: lexical and
non-lexical. Eventually there will only be one.</p>
<p>To solve <strong>lexical</strong> region constraints, you invoke
<code>resolve_regions_and_report_errors</code>.  This &quot;closes&quot; the region
constraint process and invoke the <code>lexical_region_resolve</code> code. Once
this is done, any further attempt to equate or create a subtyping
relationship will yield an ICE.</p>
<p>Non-lexical region constraints are not handled within the inference
context. Instead, the NLL solver (actually, the MIR type-checker)
invokes <code>take_and_reset_region_constraints</code> periodically. This
extracts all of the outlives constraints from the region solver, but
leaves the set of variables intact. This is used to get <em>just</em> the
region constraints that resulted from some particular point in the
program, since the NLL solver needs to know not just <em>what</em> regions
were subregions but <em>where</em>. Finally, the NLL solver invokes
<code>take_region_var_origins</code>, which &quot;closes&quot; the region constraint
process in the same way as normal solving.</p>
<a class="header" href="print.html#lexical-region-resolution" id="lexical-region-resolution"><h2>Lexical region resolution</h2></a>
<p>Lexical region resolution is done by initially assigning each region
variable to an empty value. We then process each outlives constraint
repeatedly, growing region variables until a fixed-point is reached.
Region variables can be grown using a least-upper-bound relation on
the region lattice in a fairly straightforward fashion.</p>
<a class="header" href="print.html#trait-resolution" id="trait-resolution"><h1>Trait resolution</h1></a>
<p>This chapter describes the general process of <em>trait resolution</em> and points out
some non-obvious things.</p>
<a class="header" href="print.html#major-concepts" id="major-concepts"><h2>Major concepts</h2></a>
<p>Trait resolution is the process of pairing up an impl with each
reference to a trait. So, for example, if there is a generic function like:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn clone_slice&lt;T:Clone&gt;(x: &amp;[T]) -&gt; Vec&lt;T&gt; { /*...*/ }
#}</code></pre></pre>
<p>and then a call to that function:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let v: Vec&lt;isize&gt; = clone_slice(&amp;[1, 2, 3])
#}</code></pre></pre>
<p>it is the job of trait resolution to figure out whether there exists an impl of
(in this case) <code>isize : Clone</code>.</p>
<p>Note that in some cases, like generic functions, we may not be able to
find a specific impl, but we can figure out that the caller must
provide an impl. For example, consider the body of <code>clone_slice</code>:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn clone_slice&lt;T:Clone&gt;(x: &amp;[T]) -&gt; Vec&lt;T&gt; {
    let mut v = Vec::new();
    for e in &amp;x {
        v.push((*e).clone()); // (*)
    }
}
#}</code></pre></pre>
<p>The line marked <code>(*)</code> is only legal if <code>T</code> (the type of <code>*e</code>)
implements the <code>Clone</code> trait. Naturally, since we don't know what <code>T</code>
is, we can't find the specific impl; but based on the bound <code>T:Clone</code>,
we can say that there exists an impl which the caller must provide.</p>
<p>We use the term <em>obligation</em> to refer to a trait reference in need of
an impl. Basically, the trait resolution system resolves an obligation
by proving that an appropriate impl does exist.</p>
<p>During type checking, we do not store the results of trait selection.
We simply wish to verify that trait selection will succeed. Then
later, at trans time, when we have all concrete types available, we
can repeat the trait selection to choose an actual implementation, which
will then be generated in the output binary.</p>
<a class="header" href="print.html#overview" id="overview"><h2>Overview</h2></a>
<p>Trait resolution consists of three major parts:</p>
<ul>
<li>
<p><strong>Selection</strong> is deciding how to resolve a specific obligation. For
example, selection might decide that a specific obligation can be
resolved by employing an impl which matches the <code>Self</code> type, or by
using a parameter bound (e.g. <code>T: Trait</code>). In the case of an impl, selecting one
obligation can create <em>nested obligations</em> because of where clauses
on the impl itself. It may also require evaluating those nested
obligations to resolve ambiguities.</p>
</li>
<li>
<p><strong>Fulfillment</strong> is keeping track of which obligations
are completely fulfilled. Basically, it is a worklist of obligations
to be selected: once selection is successful, the obligation is
removed from the worklist and any nested obligations are enqueued.</p>
</li>
<li>
<p><strong>Coherence</strong> checks are intended to ensure that there
are never overlapping impls, where two impls could be used with
equal precedence.</p>
</li>
</ul>
<a class="header" href="print.html#selection" id="selection"><h2>Selection</h2></a>
<p>Selection is the process of deciding whether an obligation can be
resolved and, if so, how it is to be resolved (via impl, where clause, etc).
The main interface is the <code>select()</code> function, which takes an obligation
and returns a <code>SelectionResult</code>. There are three possible outcomes:</p>
<ul>
<li>
<p><code>Ok(Some(selection))</code> – yes, the obligation can be resolved, and
<code>selection</code> indicates how. If the impl was resolved via an impl,
then <code>selection</code> may also indicate nested obligations that are required
by the impl.</p>
</li>
<li>
<p><code>Ok(None)</code> – we are not yet sure whether the obligation can be
resolved or not. This happens most commonly when the obligation
contains unbound type variables.</p>
</li>
<li>
<p><code>Err(err)</code> – the obligation definitely cannot be resolved due to a
type error or because there are no impls that could possibly apply.</p>
</li>
</ul>
<p>The basic algorithm for selection is broken into two big phases:
candidate assembly and confirmation.</p>
<p>Note that because of how lifetime inference works, it is not possible to
give back immediate feedback as to whether a unification or subtype
relationship between lifetimes holds or not. Therefore, lifetime
matching is <em>not</em> considered during selection. This is reflected in
the fact that subregion assignment is infallible. This may yield
lifetime constraints that will later be found to be in error (in
contrast, the non-lifetime-constraints have already been checked
during selection and can never cause an error, though naturally they
may lead to other errors downstream).</p>
<a class="header" href="print.html#candidate-assembly" id="candidate-assembly"><h3>Candidate assembly</h3></a>
<p>Searches for impls/where-clauses/etc that might
possibly be used to satisfy the obligation. Each of those is called
a candidate. To avoid ambiguity, we want to find exactly one
candidate that is definitively applicable. In some cases, we may not
know whether an impl/where-clause applies or not – this occurs when
the obligation contains unbound inference variables.</p>
<p>The subroutines that decide whether a particular impl/where-clause/etc
applies to a particular obligation are collectively refered to as the
process of <em>matching</em>. At the moment, this amounts to
unifying the <code>Self</code> types, but in the future we may also recursively
consider some of the nested obligations, in the case of an impl.</p>
<p><strong>TODO</strong>: what does &quot;unifying the <code>Self</code> types&quot; mean? The <code>Self</code> of the
obligation with that of an impl?</p>
<p>The basic idea for candidate assembly is to do a first pass in which
we identify all possible candidates. During this pass, all that we do
is try and unify the type parameters. (In particular, we ignore any
nested where clauses.) Presuming that this unification succeeds, the
impl is added as a candidate.</p>
<p>Once this first pass is done, we can examine the set of candidates. If
it is a singleton set, then we are done: this is the only impl in
scope that could possibly apply. Otherwise, we can winnow down the set
of candidates by using where clauses and other conditions. If this
reduced set yields a single, unambiguous entry, we're good to go,
otherwise the result is considered ambiguous.</p>
<a class="header" href="print.html#the-basic-process-inferring-based-on-the-impls-we-see" id="the-basic-process-inferring-based-on-the-impls-we-see"><h4>The basic process: Inferring based on the impls we see</h4></a>
<p>This process is easier if we work through some examples. Consider
the following trait:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
trait Convert&lt;Target&gt; {
    fn convert(&amp;self) -&gt; Target;
}
#}</code></pre></pre>
<p>This trait just has one method. It's about as simple as it gets. It
converts from the (implicit) <code>Self</code> type to the <code>Target</code> type. If we
wanted to permit conversion between <code>isize</code> and <code>usize</code>, we might
implement <code>Convert</code> like so:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl Convert&lt;usize&gt; for isize { /*...*/ } // isize -&gt; usize
impl Convert&lt;isize&gt; for usize { /*...*/ } // usize -&gt; isize
#}</code></pre></pre>
<p>Now imagine there is some code like the following:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let x: isize = ...;
let y = x.convert();
#}</code></pre></pre>
<p>The call to convert will generate a trait reference <code>Convert&lt;$Y&gt; for isize</code>, where <code>$Y</code> is the type variable representing the type of
<code>y</code>. Of the two impls we can see, the only one that matches is
<code>Convert&lt;usize&gt; for isize</code>. Therefore, we can
select this impl, which will cause the type of <code>$Y</code> to be unified to
<code>usize</code>. (Note that while assembling candidates, we do the initial
unifications in a transaction, so that they don't affect one another.)</p>
<p><strong>TODO</strong>: The example says we can &quot;select&quot; the impl, but this section is talking specifically about candidate assembly. Does this mean we can sometimes skip confirmation? Or is this poor wording?
<strong>TODO</strong>: Is the unification of <code>$Y</code> part of trait resolution or type inference? Or is this not the same type of &quot;inference variable&quot; as in type inference?</p>
<a class="header" href="print.html#winnowing-resolving-ambiguities" id="winnowing-resolving-ambiguities"><h4>Winnowing: Resolving ambiguities</h4></a>
<p>But what happens if there are multiple impls where all the types
unify? Consider this example:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
trait Get {
    fn get(&amp;self) -&gt; Self;
}

impl&lt;T:Copy&gt; Get for T {
    fn get(&amp;self) -&gt; T { *self }
}

impl&lt;T:Get&gt; Get for Box&lt;T&gt; {
    fn get(&amp;self) -&gt; Box&lt;T&gt; { Box::new(get_it(&amp;**self)) }
}
#}</code></pre></pre>
<p>What happens when we invoke <code>get_it(&amp;Box::new(1_u16))</code>, for example? In this
case, the <code>Self</code> type is <code>Box&lt;u16&gt;</code> – that unifies with both impls,
because the first applies to all types, and the second to all
boxes. In order for this to be unambiguous, the compiler does a <em>winnowing</em>
pass that considers <code>where</code> clauses
and attempts to remove candidates. In this case, the first impl only
applies if <code>Box&lt;u16&gt; : Copy</code>, which doesn't hold. After winnowing,
then, we are left with just one candidate, so we can proceed.</p>
<a class="header" href="print.html#where-clauses" id="where-clauses"><h4><code>where</code> clauses</h4></a>
<p>Besides an impl, the other major way to resolve an obligation is via a
where clause. The selection process is always given a <a href="./param_env.html">parameter
environment</a> which contains a list of where clauses, which are
basically obligations that we can assume are satisfiable. We will iterate
over that list and check whether our current obligation can be found
in that list. If so, it is considered satisfied. More precisely, we
want to check whether there is a where-clause obligation that is for
the same trait (or some subtrait) and which can match against the obligation.</p>
<p>Consider this simple example:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
trait A1 {
    fn do_a1(&amp;self);
}
trait A2 : A1 { /*...*/ }

trait B {
    fn do_b(&amp;self);
}

fn foo&lt;X:A2+B&gt;(x: X) {
    x.do_a1(); // (*)
    x.do_b();  // (#)
}
#}</code></pre></pre>
<p>In the body of <code>foo</code>, clearly we can use methods of <code>A1</code>, <code>A2</code>, or <code>B</code>
on variable <code>x</code>. The line marked <code>(*)</code> will incur an obligation <code>X: A1</code>,
which the line marked <code>(#)</code> will incur an obligation <code>X: B</code>. Meanwhile,
the parameter environment will contain two where-clauses: <code>X : A2</code> and <code>X : B</code>.
For each obligation, then, we search this list of where-clauses. The
obligation <code>X: B</code> trivially matches against the where-clause <code>X: B</code>.
To resolve an obligation <code>X:A1</code>, we would note that <code>X:A2</code> implies that <code>X:A1</code>.</p>
<a class="header" href="print.html#confirmation" id="confirmation"><h3>Confirmation</h3></a>
<p><em>Confirmation</em> unifies the output type parameters of the trait with the
values found in the obligation, possibly yielding a type error.</p>
<p>Suppose we have the following variation of the <code>Convert</code> example in the
previous section:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
trait Convert&lt;Target&gt; {
    fn convert(&amp;self) -&gt; Target;
}

impl Convert&lt;usize&gt; for isize { /*...*/ } // isize -&gt; usize
impl Convert&lt;isize&gt; for usize { /*...*/ } // usize -&gt; isize

let x: isize = ...;
let y: char = x.convert(); // NOTE: `y: char` now!
#}</code></pre></pre>
<p>Confirmation is where an error would be reported because the impl specified
that <code>Target</code> would be <code>usize</code>, but the obligation reported <code>char</code>. Hence the
result of selection would be an error.</p>
<p>Note that the candidate impl is chosen base on the <code>Self</code> type, but
confirmation is done based on (in this case) the <code>Target</code> type parameter.</p>
<a class="header" href="print.html#selection-during-translation" id="selection-during-translation"><h3>Selection during translation</h3></a>
<p>As mentioned above, during type checking, we do not store the results of trait
selection. At trans time, repeat the trait selection to choose a particular
impl for each method call. In this second selection, we do not consider any
where-clauses to be in scope because we know that each resolution will resolve
to a particular impl.</p>
<p>One interesting twist has to do with nested obligations. In general, in trans,
we only need to do a &quot;shallow&quot; selection for an obligation. That is, we wish to
identify which impl applies, but we do not (yet) need to decide how to select
any nested obligations. Nonetheless, we <em>do</em> currently do a complete
resolution, and that is because it can sometimes inform the results of type
inference. That is, we do not have the full substitutions for the type
variables of the impl available to us, so we must run trait selection to figure
everything out.</p>
<p><strong>TODO</strong>: is this still talking about trans?</p>
<p>Here is an example:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
trait Foo { /*...*/ }
impl&lt;U,T:Bar&lt;U&gt;&gt; Foo for Vec&lt;T&gt; { /*...*/ }

impl Bar&lt;usize&gt; for isize { /*...*/ }
#}</code></pre></pre>
<p>After one shallow round of selection for an obligation like <code>Vec&lt;isize&gt; : Foo</code>, we would know which impl we want, and we would know that
<code>T=isize</code>, but we do not know the type of <code>U</code>.  We must select the
nested obligation <code>isize : Bar&lt;U&gt;</code> to find out that <code>U=usize</code>.</p>
<p>It would be good to only do <em>just as much</em> nested resolution as
necessary. Currently, though, we just do a full resolution.</p>
<a class="header" href="print.html#higher-ranked-trait-bounds" id="higher-ranked-trait-bounds"><h1>Higher-ranked trait bounds</h1></a>
<p>One of the more subtle concepts in trait resolution is <em>higher-ranked trait
bounds</em>. An example of such a bound is <code>for&lt;'a&gt; MyTrait&lt;&amp;'a isize&gt;</code>.
Let's walk through how selection on higher-ranked trait references
works.</p>
<a class="header" href="print.html#basic-matching-and-skolemization-leaks" id="basic-matching-and-skolemization-leaks"><h2>Basic matching and skolemization leaks</h2></a>
<p>Suppose we have a trait <code>Foo</code>:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
trait Foo&lt;X&gt; {
    fn foo(&amp;self, x: X) { }
}
#}</code></pre></pre>
<p>Let's say we have a function <code>want_hrtb</code> that wants a type which
implements <code>Foo&lt;&amp;'a isize&gt;</code> for any <code>'a</code>:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn want_hrtb&lt;T&gt;() where T : for&lt;'a&gt; Foo&lt;&amp;'a isize&gt; { ... }
#}</code></pre></pre>
<p>Now we have a struct <code>AnyInt</code> that implements <code>Foo&lt;&amp;'a isize&gt;</code> for any
<code>'a</code>:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
struct AnyInt;
impl&lt;'a&gt; Foo&lt;&amp;'a isize&gt; for AnyInt { }
#}</code></pre></pre>
<p>And the question is, does <code>AnyInt : for&lt;'a&gt; Foo&lt;&amp;'a isize&gt;</code>? We want the
answer to be yes. The algorithm for figuring it out is closely related
to the subtyping for higher-ranked types (which is described in <a href="https://github.com/rust-lang/rust/tree/master/src/librustc/infer/higher_ranked/README.md">here</a>
and also in a <a href="http://research.microsoft.com/en-us/um/people/simonpj/papers/higher-rank/">paper by SPJ</a>. If you wish to understand higher-ranked
subtyping, we recommend you read the paper). There are a few parts:</p>
<p><strong>TODO</strong>: We should define <em>skolemize</em>.</p>
<ol>
<li><em>Skolemize</em> the obligation.</li>
<li>Match the impl against the skolemized obligation.</li>
<li>Check for <em>skolemization leaks</em>.</li>
</ol>
<p>So let's work through our example.</p>
<ol>
<li>
<p>The first thing we would do is to
skolemize the obligation, yielding <code>AnyInt : Foo&lt;&amp;'0 isize&gt;</code> (here <code>'0</code>
represents skolemized region #0). Note that we now have no quantifiers;
in terms of the compiler type, this changes from a <code>ty::PolyTraitRef</code>
to a <code>TraitRef</code>. We would then create the <code>TraitRef</code> from the impl,
using fresh variables for it's bound regions (and thus getting
<code>Foo&lt;&amp;'$a isize&gt;</code>, where <code>'$a</code> is the inference variable for <code>'a</code>).</p>
</li>
<li>
<p>Next
we relate the two trait refs, yielding a graph with the constraint
that <code>'0 == '$a</code>.</p>
</li>
<li>
<p>Finally, we check for skolemization &quot;leaks&quot; – a
leak is basically any attempt to relate a skolemized region to another
skolemized region, or to any region that pre-existed the impl match.
The leak check is done by searching from the skolemized region to find
the set of regions that it is related to in any way. This is called
the &quot;taint&quot; set. To pass the check, that set must consist <em>solely</em> of
itself and region variables from the impl. If the taint set includes
any other region, then the match is a failure. In this case, the taint
set for <code>'0</code> is <code>{'0, '$a}</code>, and hence the check will succeed.</p>
</li>
</ol>
<p>Let's consider a failure case. Imagine we also have a struct</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
struct StaticInt;
impl Foo&lt;&amp;'static isize&gt; for StaticInt;
#}</code></pre></pre>
<p>We want the obligation <code>StaticInt : for&lt;'a&gt; Foo&lt;&amp;'a isize&gt;</code> to be
considered unsatisfied. The check begins just as before. <code>'a</code> is
skolemized to <code>'0</code> and the impl trait reference is instantiated to
<code>Foo&lt;&amp;'static isize&gt;</code>. When we relate those two, we get a constraint
like <code>'static == '0</code>. This means that the taint set for <code>'0</code> is <code>{'0, 'static}</code>, which fails the leak check.</p>
<p><strong>TODO</strong>: This is because <code>'static</code> is not a region variable but is in the taint set, right?</p>
<a class="header" href="print.html#higher-ranked-trait-obligations" id="higher-ranked-trait-obligations"><h2>Higher-ranked trait obligations</h2></a>
<p>Once the basic matching is done, we get to another interesting topic:
how to deal with impl obligations. I'll work through a simple example
here. Imagine we have the traits <code>Foo</code> and <code>Bar</code> and an associated impl:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
trait Foo&lt;X&gt; {
    fn foo(&amp;self, x: X) { }
}

trait Bar&lt;X&gt; {
    fn bar(&amp;self, x: X) { }
}

impl&lt;X,F&gt; Foo&lt;X&gt; for F
    where F : Bar&lt;X&gt;
{
}
#}</code></pre></pre>
<p>Now let's say we have a obligation <code>Baz: for&lt;'a&gt; Foo&lt;&amp;'a isize&gt;</code> and we match
this impl. What obligation is generated as a result? We want to get
<code>Baz: for&lt;'a&gt; Bar&lt;&amp;'a isize&gt;</code>, but how does that happen?</p>
<p>After the matching, we are in a position where we have a skolemized
substitution like <code>X =&gt; &amp;'0 isize</code>. If we apply this substitution to the
impl obligations, we get <code>F : Bar&lt;&amp;'0 isize&gt;</code>. Obviously this is not
directly usable because the skolemized region <code>'0</code> cannot leak out of
our computation.</p>
<p>What we do is to create an inverse mapping from the taint set of <code>'0</code>
back to the original bound region (<code>'a</code>, here) that <code>'0</code> resulted
from. (This is done in <code>higher_ranked::plug_leaks</code>). We know that the
leak check passed, so this taint set consists solely of the skolemized
region itself plus various intermediate region variables. We then walk
the trait-reference and convert every region in that taint set back to
a late-bound region, so in this case we'd wind up with <code>Baz: for&lt;'a&gt; Bar&lt;&amp;'a isize&gt;</code>.</p>
<a class="header" href="print.html#caching-and-subtle-considerations-therewith" id="caching-and-subtle-considerations-therewith"><h1>Caching and subtle considerations therewith</h1></a>
<p>In general, we attempt to cache the results of trait selection.  This
is a somewhat complex process. Part of the reason for this is that we
want to be able to cache results even when all the types in the trait
reference are not fully known. In that case, it may happen that the
trait selection process is also influencing type variables, so we have
to be able to not only cache the <em>result</em> of the selection process,
but <em>replay</em> its effects on the type variables.</p>
<a class="header" href="print.html#an-example" id="an-example"><h2>An example</h2></a>
<p>The high-level idea of how the cache works is that we first replace
all unbound inference variables with skolemized versions. Therefore,
if we had a trait reference <code>usize : Foo&lt;$t&gt;</code>, where <code>$t</code> is an unbound
inference variable, we might replace it with <code>usize : Foo&lt;$0&gt;</code>, where
<code>$0</code> is a skolemized type. We would then look this up in the cache.</p>
<p>If we found a hit, the hit would tell us the immediate next step to
take in the selection process (e.g. apply impl #22, or apply where
clause <code>X : Foo&lt;Y&gt;</code>).</p>
<p>On the other hand, if there is no hit, we need to go through the <a href="./trait-resolution.html#selection">selection
process</a> from scratch. Suppose, we come to the conclusion that the only
possible impl is this one, with def-id 22:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl Foo&lt;isize&gt; for usize { ... } // Impl #22
#}</code></pre></pre>
<p>We would then record in the cache <code>usize : Foo&lt;$0&gt; =&gt; ImplCandidate(22)</code>. Next
we would <a href="./trait-resolution.html#confirmation">confirm</a> <code>ImplCandidate(22)</code>, which would (as a side-effect) unify
<code>$t</code> with <code>isize</code>.</p>
<p>Now, at some later time, we might come along and see a <code>usize : Foo&lt;$u&gt;</code>. When skolemized, this would yield <code>usize : Foo&lt;$0&gt;</code>, just as
before, and hence the cache lookup would succeed, yielding
<code>ImplCandidate(22)</code>. We would confirm <code>ImplCandidate(22)</code> which would
(as a side-effect) unify <code>$u</code> with <code>isize</code>.</p>
<a class="header" href="print.html#where-clauses-and-the-local-vs-global-cache" id="where-clauses-and-the-local-vs-global-cache"><h2>Where clauses and the local vs global cache</h2></a>
<p>One subtle interaction is that the results of trait lookup will vary
depending on what where clauses are in scope. Therefore, we actually
have <em>two</em> caches, a local and a global cache. The local cache is
attached to the <a href="./param_env.html"><code>ParamEnv</code></a>, and the global cache attached to the
<a href="./ty.html"><code>tcx</code></a>. We use the local cache whenever the result might depend on the
where clauses that are in scope. The determination of which cache to
use is done by the method <code>pick_candidate_cache</code> in <code>select.rs</code>. At
the moment, we use a very simple, conservative rule: if there are any
where-clauses in scope, then we use the local cache.  We used to try
and draw finer-grained distinctions, but that led to a serious of
annoying and weird bugs like #22019 and #18290. This simple rule seems
to be pretty clearly safe and also still retains a very high hit rate
(~95% when compiling rustc).</p>
<p><strong>TODO</strong>: it looks like <code>pick_candidate_cache</code> no longer exists. In
general, is this section still accurate at all?</p>
<a class="header" href="print.html#specialization" id="specialization"><h1>Specialization</h1></a>
<p><strong>TODO</strong>: where does Chalk fit in? Should we mention/discuss it here?</p>
<p>Defined in the <code>specialize</code> module.</p>
<p>The basic strategy is to build up a <em>specialization graph</em> during
coherence checking (recall that coherence checking looks for overlapping
impls). Insertion into the graph locates the right place
to put an impl in the specialization hierarchy; if there is no right
place (due to partial overlap but no containment), you get an overlap
error. Specialization is consulted when selecting an impl (of course),
and the graph is consulted when propagating defaults down the
specialization hierarchy.</p>
<p>You might expect that the specialization graph would be used during
selection – i.e. when actually performing specialization. This is
not done for two reasons:</p>
<ul>
<li>
<p>It's merely an optimization: given a set of candidates that apply,
we can determine the most specialized one by comparing them directly
for specialization, rather than consulting the graph. Given that we
also cache the results of selection, the benefit of this
optimization is questionable.</p>
</li>
<li>
<p>To build the specialization graph in the first place, we need to use
selection (because we need to determine whether one impl specializes
another). Dealing with this reentrancy would require some additional
mode switch for selection. Given that there seems to be no strong
reason to use the graph anyway, we stick with a simpler approach in
selection, and use the graph only for propagating default
implementations.</p>
</li>
</ul>
<p>Trait impl selection can succeed even when multiple impls can apply,
as long as they are part of the same specialization family. In that
case, it returns a <em>single</em> impl on success – this is the most
specialized impl <em>known</em> to apply. However, if there are any inference
variables in play, the returned impl may not be the actual impl we
will use at trans time. Thus, we take special care to avoid projecting
associated types unless either (1) the associated type does not use
<code>default</code> and thus cannot be overridden or (2) all input types are
known concretely.</p>
<a class="header" href="print.html#type-checking" id="type-checking"><h1>Type checking</h1></a>
<a class="header" href="print.html#the-mir-mid-level-ir" id="the-mir-mid-level-ir"><h1>The MIR (Mid-level IR)</h1></a>
<p>MIR is Rust's <em>Mid-level Intermediate Representation</em>. It is
constructed from <a href="./hir.html">HIR</a>. MIR was introduced in
<a href="http://rust-lang.github.io/rfcs/1211-mir.html">RFC 1211</a>. It is a radically simplified form of Rust that is used for
certain flow-sensitive safety checks -- notably the borrow checker! --
and also for optimization and code generation.</p>
<p>If you'd like a very high-level introduction to MIR, as well as some
of the compiler concepts that it relies on (such as control-flow
graphs and desugaring), you may enjoy the
<a href="https://blog.rust-lang.org/2016/04/19/MIR.html">rust-lang blog post that introduced MIR</a>.</p>
<a class="header" href="print.html#introduction-to-mir" id="introduction-to-mir"><h2>Introduction to MIR</h2></a>
<p>MIR is defined in the <a href="https://github.com/rust-lang/rust/tree/master/src/librustc/mir"><code>src/librustc/mir/</code></a> module, but much of the code
that manipulates it is found in <a href="https://github.com/rust-lang/rust/tree/master/src/librustc_mir"><code>src/librustc_mir</code></a>.</p>
<p>Some of the key characteristics of MIR are:</p>
<ul>
<li>It is based on a <a href="./background.html#cfg">control-flow graph</a>.</li>
<li>It does not have nested expressions.</li>
<li>All types in MIR are fully explicit.</li>
</ul>
<a class="header" href="print.html#key-mir-vocabulary" id="key-mir-vocabulary"><h2>Key MIR vocabulary</h2></a>
<p>This section introduces the key concepts of MIR, summarized here:</p>
<ul>
<li><strong>Basic blocks</strong>: units of the control-flow graph, consisting of:
<ul>
<li><strong>statements:</strong> actions with one successor</li>
<li><strong>terminators:</strong> actions with potentially multiple successors; always at the end of a block</li>
<li>(if you're not familiar with the term <em>basic block</em>, see the <a href="./background.html#cfg">background chapter</a>)</li>
</ul>
</li>
<li><strong>Locals:</strong> Memory locations alloated on the stack (conceptually, at
least), such as function arguments, local variables, and
temporaries. These are identified by an index, written with a
leading underscore, like <code>_1</code>. There is also a special &quot;local&quot;
(<code>_0</code>) allocated to store the return value.</li>
<li><strong>Places:</strong> expressions that identify a location in memory, like <code>_1</code> or <code>_1.f</code>.</li>
<li><strong>Rvalues:</strong> expressions that produce a value. The &quot;R&quot; stands for
the fact that these are the &quot;right-hand side&quot; of an assignment.
<ul>
<li><strong>Operands:</strong> the arguments to an rvalue, which can either be a
constant (like <code>22</code>) or a place (like <code>_1</code>).</li>
</ul>
</li>
</ul>
<p>You can get a feeling for how MIR is structed by translating simple
programs into MIR and reading the pretty printed output. In fact, the
playground makes this easy, since it supplies a MIR button that will
show you the MIR for your program. Try putting this program into play
(or <a href="https://play.rust-lang.org/?gist=30074856e62e74e91f06abd19bd72ece&amp;version=stable">clicking on this link</a>), and then clicking the &quot;MIR&quot;
button on the top:</p>
<pre><pre class="playpen"><code class="language-rust">fn main() {
    let mut vec = Vec::new();
    vec.push(1);
    vec.push(2);
}
</code></pre></pre>
<p>You should see something like:</p>
<pre><code>// WARNING: This output format is intended for human consumers only
// and is subject to change without notice. Knock yourself out.
fn main() -&gt; () {
    ...
}    
</code></pre>
<p>This is the MIR format for the <code>main</code> function.</p>
<p><strong>Variable declarations.</strong> If we drill in a bit, we'll see it begins
with a bunch of variable declarations. They look like this:</p>
<pre><code>let mut _0: ();                      // return place
scope 1 {
    let mut _1: std::vec::Vec&lt;i32&gt;;  // &quot;vec&quot; in scope 1 at src/main.rs:2:9: 2:16
}
scope 2 {
}
let mut _2: ();
let mut _3: &amp;mut std::vec::Vec&lt;i32&gt;;
let mut _4: ();
let mut _5: &amp;mut std::vec::Vec&lt;i32&gt;;
</code></pre>
<p>You can see that variables in MIR don't have names, they have indices,
like <code>_0</code> or <code>_1</code>.  We also intermingle the user's variables (e.g.,
<code>_1</code>) with temporary values (e.g., <code>_2</code> or <code>_3</code>). You can tell the
difference between user-defined variables have a comment that gives
you their original name (<code>// &quot;vec&quot; in scope 1...</code>). The &quot;scope&quot; blocks
(e.g., <code>scope 1 { .. }</code>) describe the lexical structure of the source
program (which names were in scope when).</p>
<p><strong>Basic blocks.</strong> Reading further, we see our first <strong>basic block</strong> (naturally it may look
slightly different when you view it, and I am ignoring some of the comments):</p>
<pre><code>bb0: {                              
    StorageLive(_1);
    _1 = const &lt;std::vec::Vec&lt;T&gt;&gt;::new() -&gt; bb2;
}
</code></pre>
<p>A basic block is defined by a series of <strong>statements</strong> and a final <strong>terminator</strong>.
In this case, there is one statement:</p>
<pre><code>StorageLive(_1);
</code></pre>
<p>This statement indicates that the variable <code>_1</code> is &quot;live&quot;, meaning
that it may be used later -- this will persist until we encounter a
<code>StorageDead(_1)</code> statement, which indicates that the variable <code>_1</code> is
done being used. These &quot;storage statements&quot; are used by LLVM to
allocate stack space.</p>
<p>The <strong>terminator</strong> of the block <code>bb0</code> is the call to <code>Vec::new</code>:</p>
<pre><code>_1 = const &lt;std::vec::Vec&lt;T&gt;&gt;::new() -&gt; bb2;
</code></pre>
<p>Terminators are different from statements because they can have more
than one successor -- that is, control may flow to different
places. Function calls like the call to <code>Vec::new</code> are always
terminators because of the possibility of unwinding, although in the
case of <code>Vec::new</code> we are able to see that indeed unwinding is not
possible, and hence we list only one succssor block, <code>bb2</code>.</p>
<p>If we look ahead to <code>bb2</code>, we will see it looks like this:</p>
<pre><code>bb2: {                              
    StorageLive(_3);
    _3 = &amp;mut _1;
    _2 = const &lt;std::vec::Vec&lt;T&gt;&gt;::push(move _3, const 1i32) -&gt; [return: bb3, unwind: bb4];
}
</code></pre>
<p>Here there are two statements: another <code>StorageLive</code>, introducing the <code>_3</code> temporary,
and then an assignment:</p>
<pre><code>_3 = &amp;mut _1;
</code></pre>
<p>Assignments in general have the form:</p>
<pre><code>&lt;Place&gt; = &lt;Rvalue&gt;
</code></pre>
<p>A place is an expression like <code>_3</code>, <code>_3.f</code> or <code>*_3</code> -- it denotes a
location in memory.  An <strong>Rvalue</strong> is an expression that creates a
value: in this case, the rvalue is a mutable borrow expression, which
looks like <code>&amp;mut &lt;Place&gt;</code>. So we can kind of define a grammar for
rvalues like so:</p>
<pre><code>&lt;Rvalue&gt;  = &amp; (mut)? &lt;Place&gt;
          | &lt;Operand&gt; + &lt;Operand&gt;
          | &lt;Operand&gt; - &lt;Operand&gt;
          | ...

&lt;Operand&gt; = Constant
          | copy Place
          | move Place
</code></pre>
<p>As you can see from this grammar, rvalues cannot be nested -- they can
only reference places and constants. Moreover, when you use a place,
we indicate whether we are <strong>copying it</strong> (which requires that the
place have a type <code>T</code> where <code>T: Copy</code>) or <strong>moving it</strong> (which works
for a place of any type). So, for example, if we had the expression <code>x = a + b + c</code> in Rust, that would get compile to two statements and a
temporary:</p>
<pre><code>TMP1 = a + b
x = TMP1 + c
</code></pre>
<p>(<a href="https://play.rust-lang.org/?gist=1751196d63b2a71f8208119e59d8a5b6&amp;version=stable">Try it and see, though you may want to do release mode to skip over the overflow checks.</a>)</p>
<a class="header" href="print.html#mir-data-types" id="mir-data-types"><h2>MIR data types</h2></a>
<p>The MIR data types are defined in the <a href="https://github.com/rust-lang/rust/tree/master/src/librustc/mir"><code>src/librustc/mir/</code></a>
module.  Each of the key concepts mentioned in the previous section
maps in a fairly straightforward way to a Rust type.</p>
<p>The main MIR data type is <code>Mir</code>. It contains the data for a single
function (along with sub-instances of Mir for &quot;promoted constants&quot;,
but <a href="print.html#promoted">you can read about those below</a>).</p>
<ul>
<li><strong>Basic blocks</strong>: The basic blocks are stored in the field
<code>basic_blocks</code>; this is a vector of <code>BasicBlockData</code>
structures. Nobody ever references a basic block directly: instead,
we pass around <code>BasicBlock</code> values, which are
<a href="glossary.html">newtype'd</a> indices into this vector.</li>
<li><strong>Statements</strong> are represented by the type <code>Statement</code>.</li>
<li><strong>Terminators</strong> are represented by the <code>Terminator</code>.</li>
<li><strong>Locals</strong> are represented by a <a href="glossary.html">newtype'd</a> index type <code>Local</code>. The
data for a local variable is found in the <code>Mir</code> (the <code>local_decls</code>
vector). There is also a special constant <code>RETURN_PLACE</code> identifying
the special &quot;local&quot; representing the return value.</li>
<li><strong>Places</strong> are identified by the enum <code>Place</code>. There are a few variants:
<ul>
<li>Local variables like <code>_1</code></li>
<li>Static variables <code>FOO</code></li>
<li><strong>Projections</strong>, which are fields or other things that &quot;project
out&quot; from a base place. So e.g. the place <code>_1.f</code> is a projection,
with <code>f</code> being the &quot;projection element and <code>_1</code> being the base
path. <code>*_1</code> is also a projection, with the <code>*</code> being represented
by the <code>ProjectionElem::Deref</code> element.</li>
</ul>
</li>
<li><strong>Rvalues</strong> are represented by the enum <code>Rvalue</code>.</li>
<li><strong>Operands</strong> are represented by the enum <code>Operand</code>.</li>
</ul>
<a class="header" href="print.html#representing-constants" id="representing-constants"><h2>Representing constants</h2></a>
<p><em>to be written</em></p>
<p><a name=promoted></p>
<a class="header" href="print.html#promoted-constants" id="promoted-constants"><h3>Promoted constants</h3></a>
<p><em>to be written</em></p>
<a class="header" href="print.html#mir-construction" id="mir-construction"><h1>MIR construction</h1></a>
<a class="header" href="print.html#mir-visitor" id="mir-visitor"><h1>MIR visitor</h1></a>
<p>The MIR visitor is a convenient tool for traversing the MIR and either
looking for things or making changes to it. The visitor traits are
defined in <a href="https://github.com/rust-lang/rust/tree/master/src/librustc/mir/visit.rs">the <code>rustc::mir::visit</code> module</a> -- there are two of
them, generated via a single macro: <code>Visitor</code> (which operates on a
<code>&amp;Mir</code> and gives back shared references) and <code>MutVisitor</code> (which
operates on a <code>&amp;mut Mir</code> and gives back mutable references).</p>
<p>To implement a visitor, you have to create a type that represents
your visitor. Typically, this type wants to &quot;hang on&quot; to whatever
state you will need while processing MIR:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
struct MyVisitor&lt;...&gt; {
    tcx: TyCtxt&lt;'cx, 'tcx, 'tcx&gt;,
    ...
}
#}</code></pre></pre>
<p>and you then implement the <code>Visitor</code> or <code>MutVisitor</code> trait for that type:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl&lt;'tcx&gt; MutVisitor&lt;'tcx&gt; for NoLandingPads {
    fn visit_foo(&amp;mut self, ...) {
        // ...
        self.super_foo(...);
    }
}
#}</code></pre></pre>
<p>As shown above, within the impl, you can override any of the
<code>visit_foo</code> methods (e.g., <code>visit_terminator</code>) in order to write some
code that will execute whenever a <code>foo</code> is found. If you want to
recursively walk the contents of the <code>foo</code>, you then invoke the
<code>super_foo</code> method. (NB. You never want to override <code>super_foo</code>.)</p>
<p>A very simple example of a visitor can be found in <a href="https://github.com/rust-lang/rust/tree/master/src/librustc_mir/transform/no_landing_pads.rs"><code>NoLandingPads</code></a>.
That visitor doesn't even require any state: it just visits all
terminators and removes their <code>unwind</code> successors.</p>
<a class="header" href="print.html#traversal" id="traversal"><h2>Traversal</h2></a>
<p>In addition the visitor, <a href="https://github.com/rust-lang/rust/tree/master/src/librustc/mir/traversal.rs">the <code>rustc::mir::traversal</code> module</a>
contains useful functions for walking the MIR CFG in
<a href="https://en.wikipedia.org/wiki/Tree_traversal">different standard orders</a> (e.g. pre-order, reverse
post-order, and so forth).</p>
<a class="header" href="print.html#mir-passes" id="mir-passes"><h1>MIR passes</h1></a>
<p>If you would like to get the MIR for a function (or constant, etc),
you can use the <code>optimized_mir(def_id)</code> query. This will give you back
the final, optimized MIR. For foreign def-ids, we simply read the MIR
from the other crate's metadata. But for local def-ids, the query will
construct the MIR and then iteratively optimize it by applying a
series of passes. This section describes how those passes work and how
you can extend them.</p>
<p>To produce the <code>optimized_mir(D)</code> for a given def-id <code>D</code>, the MIR
passes through several suites of optimizations, each represented by a
query. Each suite consists of multiple optimizations and
transformations. These suites represent useful intermediate points
where we want to access the MIR for type checking or other purposes:</p>
<ul>
<li><code>mir_build(D)</code> – not a query, but this constructs the initial MIR</li>
<li><code>mir_const(D)</code> – applies some simple transformations to make MIR ready for constant evaluation;</li>
<li><code>mir_validated(D)</code> – applies some more transformations, making MIR ready for borrow checking;</li>
<li><code>optimized_mir(D)</code> – the final state, after all optimizations have been performed.</li>
</ul>
<a class="header" href="print.html#seeing-how-the-mir-changes-as-the-compiler-executes" id="seeing-how-the-mir-changes-as-the-compiler-executes"><h3>Seeing how the MIR changes as the compiler executes</h3></a>
<p><code>-Zdump-mir=F</code> is a handy compiler options that will let you view the MIR
for each function at each stage of compilation. <code>-Zdump-mir</code> takes a <strong>filter</strong>
<code>F</code> which allows you to control which functions and which passes you are interesting
in. For example:</p>
<pre><code class="language-bash">&gt; rustc -Zdump-mir=foo ...
</code></pre>
<p>This will dump the MIR for any function whose name contains <code>foo</code>; it
will dump the MIR both before and after every pass. Those files will
be created in the <code>mir_dump</code> directory. There will likely be quite a
lot of them!</p>
<pre><code class="language-bash">&gt; cat &gt; foo.rs
fn main() {
    println!(&quot;Hello, world!&quot;);
}
^D
&gt; rustc -Zdump-mir=main foo.rs
&gt; ls mir_dump/* | wc -l
     161
</code></pre>
<p>The files have names like <code>rustc.main.000-000.CleanEndRegions.after.mir</code>. These
names have a number of parts:</p>
<pre><code>rustc.main.000-000.CleanEndRegions.after.mir
      ---- --- --- --------------- ----- either before or after
      |    |   |   name of the pass
      |    |   index of dump within the pass (usually 0, but some passes dump intermediate states)
      |    index of the pass
      def-path to the function etc being dumped    
</code></pre>
<p>You can also make more selective filters. For example, <code>main &amp; CleanEndRegions</code> will select
for things that reference <em>both</em> <code>main</code> and the pass <code>CleanEndRegions</code>:</p>
<pre><code class="language-bash">&gt; rustc -Zdump-mir='main &amp; CleanEndRegions' foo.rs
&gt; ls mir_dump
rustc.main.000-000.CleanEndRegions.after.mir	rustc.main.000-000.CleanEndRegions.before.mir
</code></pre>
<p>Filters can also have <code>|</code> parts to combine multiple sets of
<code>&amp;</code>-filters. For example <code>main &amp; CleanEndRegions | main &amp; NoLandingPads</code> will select <em>either</em> <code>main</code> and <code>CleanEndRegions</code> <em>or</em>
<code>main</code> and <code>NoLandingPads</code>:</p>
<pre><code class="language-bash">&gt; rustc -Zdump-mir='main &amp; CleanEndRegions | main &amp; NoLandingPads' foo.rs
&gt; ls mir_dump
rustc.main-promoted[0].002-000.NoLandingPads.after.mir
rustc.main-promoted[0].002-000.NoLandingPads.before.mir
rustc.main-promoted[0].002-006.NoLandingPads.after.mir
rustc.main-promoted[0].002-006.NoLandingPads.before.mir
rustc.main-promoted[1].002-000.NoLandingPads.after.mir
rustc.main-promoted[1].002-000.NoLandingPads.before.mir
rustc.main-promoted[1].002-006.NoLandingPads.after.mir
rustc.main-promoted[1].002-006.NoLandingPads.before.mir
rustc.main.000-000.CleanEndRegions.after.mir
rustc.main.000-000.CleanEndRegions.before.mir
rustc.main.002-000.NoLandingPads.after.mir
rustc.main.002-000.NoLandingPads.before.mir
rustc.main.002-006.NoLandingPads.after.mir
rustc.main.002-006.NoLandingPads.before.mir
</code></pre>
<p>(Here, the <code>main-promoted[0]</code> files refer to the MIR for &quot;promoted constants&quot;
that appeared within the <code>main</code> function.)</p>
<a class="header" href="print.html#implementing-and-registering-a-pass" id="implementing-and-registering-a-pass"><h3>Implementing and registering a pass</h3></a>
<p>A <code>MirPass</code> is some bit of code that processes the MIR, typically --
but not always -- transforming it along the way somehow. For example,
it might perform an optimization. The <code>MirPass</code> trait itself is found
in in <a href="https://github.com/rust-lang/rust/tree/master/src/librustc_mir/transform/mod.rs">the <code>rustc_mir::transform</code> module</a>, and it
basically consists of one method, <code>run_pass</code>, that simply gets an
<code>&amp;mut Mir</code> (along with the tcx and some information about where it
came from). The MIR is therefore modified in place (which helps to
keep things efficient).</p>
<p>A good example of a basic MIR pass is <a href="https://github.com/rust-lang/rust/tree/master/src/librustc_mir/transform/no_landing_pads.rs"><code>NoLandingPads</code></a>, which walks
the MIR and removes all edges that are due to unwinding -- this is
used when configured with <code>panic=abort</code>, which never unwinds. As you
can see from its source, a MIR pass is defined by first defining a
dummy type, a struct with no fields, something like:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
struct MyPass;
#}</code></pre></pre>
<p>for which you then implement the <code>MirPass</code> trait. You can then insert
this pass into the appropriate list of passes found in a query like
<code>optimized_mir</code>, <code>mir_validated</code>, etc. (If this is an optimization, it
should go into the <code>optimized_mir</code> list.)</p>
<p>If you are writing a pass, there's a good chance that you are going to
want to use a <a href="mir-visitor.html">MIR visitor</a>. MIR visitors are a handy way to walk all
the parts of the MIR, either to search for something or to make small
edits.</p>
<a class="header" href="print.html#stealing" id="stealing"><h3>Stealing</h3></a>
<p>The intermediate queries <code>mir_const()</code> and <code>mir_validated()</code> yield up
a <code>&amp;'tcx Steal&lt;Mir&lt;'tcx&gt;&gt;</code>, allocated using
<code>tcx.alloc_steal_mir()</code>. This indicates that the result may be
<strong>stolen</strong> by the next suite of optimizations – this is an
optimization to avoid cloning the MIR. Attempting to use a stolen
result will cause a panic in the compiler. Therefore, it is important
that you do not read directly from these intermediate queries except as
part of the MIR processing pipeline.</p>
<p>Because of this stealing mechanism, some care must also be taken to
ensure that, before the MIR at a particular phase in the processing
pipeline is stolen, anyone who may want to read from it has already
done so. Concretely, this means that if you have some query <code>foo(D)</code>
that wants to access the result of <code>mir_const(D)</code> or
<code>mir_validated(D)</code>, you need to have the successor pass &quot;force&quot;
<code>foo(D)</code> using <code>ty::queries::foo::force(...)</code>. This will force a query
to execute even though you don't directly require its result.</p>
<p>As an example, consider MIR const qualification. It wants to read the
result produced by the <code>mir_const()</code> suite. However, that result will
be <strong>stolen</strong> by the <code>mir_validated()</code> suite. If nothing was done,
then <code>mir_const_qualif(D)</code> would succeed if it came before
<code>mir_validated(D)</code>, but fail otherwise. Therefore, <code>mir_validated(D)</code>
will <strong>force</strong> <code>mir_const_qualif</code> before it actually steals, thus
ensuring that the reads have already happened (remember that
<a href="./query.html">queries are memoized</a>, so executing a query twice
simply loads from a cache the second time):</p>
<pre><code>mir_const(D) --read-by--&gt; mir_const_qualif(D)
     |                       ^
  stolen-by                  |
     |                    (forces)
     v                       |
mir_validated(D) ------------+
</code></pre>
<p>This mechanism is a bit dodgy. There is a discussion of more elegant
alternatives in <a href="https://github.com/rust-lang/rust/issues/41710">rust-lang/rust#41710</a>.</p>
<a class="header" href="print.html#mir-borrow-check" id="mir-borrow-check"><h1>MIR borrow check</h1></a>
<p>The borrow check is Rust's &quot;secret sauce&quot; -- it is tasked with
enforcing a number of properties:</p>
<ul>
<li>That all variables are initialized before they are used.</li>
<li>That you can't move the same value twice.</li>
<li>That you can't move a value while it is borrowed.</li>
<li>That you can't access a place while it is mutably borrowed (except through the reference).</li>
<li>That you can't mutate a place while it is shared borrowed.</li>
<li>etc</li>
</ul>
<p>At the time of this writing, the code is in a state of transition. The
&quot;main&quot; borrow checker still works by processing <a href="hir.html">the HIR</a>,
but that is being phased out in favor of the MIR-based borrow checker.
Doing borrow checking on MIR has two key advantages:</p>
<ul>
<li>The MIR is <em>far</em> less complex than the HIR; the radical desugaring
helps prevent bugs in the borrow checker. (If you're curious, you
can see
<a href="https://github.com/rust-lang/rust/issues/47366">a list of bugs that the MIR-based borrow checker fixes here</a>.)</li>
<li>Even more importantly, using the MIR enables <a href="http://rust-lang.github.io/rfcs/2094-nll.html">&quot;non-lexical lifetimes&quot;</a>,
which are regions derived from the control-flow graph.</li>
</ul>
<a class="header" href="print.html#major-phases-of-the-borrow-checker" id="major-phases-of-the-borrow-checker"><h3>Major phases of the borrow checker</h3></a>
<p>The borrow checker source is found in
<a href="https://github.com/rust-lang/rust/tree/master/src/librustc_mir/borrow_check">the <code>rustc_mir::borrow_check</code> module</a>. The main entry point is
the <code>mir_borrowck</code> query. At the time of this writing, MIR borrowck can operate
in several modes, but this text will describe only the mode when NLL is enabled
(what you get with <code>#![feature(nll)]</code>).</p>
<p>The overall flow of the borrow checker is as follows:</p>
<ul>
<li>We first create a <strong>local copy</strong> C of the MIR. In the coming steps,
we will modify this copy in place to modify the types and things to
include references to the new regions that we are computing.</li>
<li>We then invoke <code>nll::replace_regions_in_mir</code> to modify this copy C.
Among other things, this function will replace all of the regions in
the MIR with fresh <a href="glossary.html">inference variables</a>.
<ul>
<li>(More details can be found in <a href="./mir-regionck.html">the regionck section</a>.)</li>
</ul>
</li>
<li>Next, we perform a number of <a href="./background.html#dataflow">dataflow analyses</a>
that compute what data is moved and when. The results of these analyses
are needed to do both borrow checking and region inference.</li>
<li>Using the move data, we can then compute the values of all the regions in the MIR.
<ul>
<li>(More details can be found in <a href="./mir-regionck.html">the NLL section</a>.)</li>
</ul>
</li>
<li>Finally, the borrow checker itself runs, taking as input (a) the
results of move analysis and (b) the regions computed by the region
checker. This allows us to figure out which loans are still in scope
at any particular point.</li>
</ul>
<a class="header" href="print.html#mir-based-region-checking-nll" id="mir-based-region-checking-nll"><h1>MIR-based region checking (NLL)</h1></a>
<p>The MIR-based region checking code is located in
<a href="https://github.com/rust-lang/rust/tree/master/src/librustc_mir/borrow_check/nll">the <code>rustc_mir::borrow_check::nll</code> module</a>. (NLL, of course,
stands for &quot;non-lexical lifetimes&quot;, a term that will hopefully be
deprecated once they become the standard kind of lifetime.)</p>
<p>The MIR-based region analysis consists of two major functions:</p>
<ul>
<li><code>replace_regions_in_mir</code>, invoked first, has two jobs:
<ul>
<li>First, it finds the set of regions that appear within the
signature of the function (e.g., <code>'a</code> in <code>fn foo&lt;'a&gt;(&amp;'a u32) { ... }</code>). These are called the &quot;universal&quot; or &quot;free&quot; regions -- in
particular, they are the regions that <a href="background.html#free-vs-bound">appear free</a> in the
function body.</li>
<li>Second, it replaces all the regions from the function body with
fresh inference variables. This is because (presently) those
regions are the results of lexical region inference and hence are
not of much interest. The intention is that -- eventually -- they
will be &quot;erased regions&quot; (i.e., no information at all), since we
won't be doing lexical region inference at all.</li>
</ul>
</li>
<li><code>compute_regions</code>, invoked second: this is given as argument the
results of move analysis. It has the job of computing values for all
the inference variabes that <code>replace_regions_in_mir</code> introduced.
<ul>
<li>To do that, it first runs the <a href="print.html#mirtypeck">MIR type checker</a>. This
is basically a normal type-checker but specialized to MIR, which
is much simpler than full Rust of course. Running the MIR type
checker will however create <strong>outlives constraints</strong> between
region variables (e.g., that one variable must outlive another
one) to reflect the subtyping relationships that arise.</li>
<li>It also adds <strong>liveness constraints</strong> that arise from where variables
are used.</li>
<li>More details to come, though the <a href="http://rust-lang.github.io/rfcs/2094-nll.html">NLL RFC</a> also includes fairly thorough
(and hopefully readable) coverage.</li>
</ul>
</li>
</ul>
<a class="header" href="print.html#universal-regions" id="universal-regions"><h2>Universal regions</h2></a>
<p><em>to be written</em> -- explain the <code>UniversalRegions</code> type</p>
<a class="header" href="print.html#region-variables-and-constraints" id="region-variables-and-constraints"><h2>Region variables and constraints</h2></a>
<p><em>to be written</em> -- describe the <code>RegionInferenceContext</code> and
the role of <code>liveness_constraints</code> vs other <code>constraints</code>, plus</p>
<a class="header" href="print.html#closures" id="closures"><h2>Closures</h2></a>
<p><em>to be written</em></p>
<p><a name=mirtypeck></p>
<a class="header" href="print.html#the-mir-type-check" id="the-mir-type-check"><h2>The MIR type-check</h2></a>
<a class="header" href="print.html#representing-the-values-of-a-region-variable" id="representing-the-values-of-a-region-variable"><h2>Representing the &quot;values&quot; of a region variable</h2></a>
<p>The value of a region can be thought of as a <strong>set</strong>; we call the
domain of this set a <code>RegionElement</code>. In the code, the value for all
regions is maintained in
<a href="https://github.com/rust-lang/rust/tree/master/src/librustc_mir/borrow_check/nll/region_infer/">the <code>rustc_mir::borrow_check::nll::region_infer</code> module</a>. For
each region we maintain a set storing what elements are present in its
value (to make this efficient, we give each kind of element an index,
the <code>RegionElementIndex</code>, and use sparse bitsets).</p>
<p>The kinds of region elements are as follows:</p>
<ul>
<li>Each <strong>location</strong> in the MIR control-flow graph: a location is just
the pair of a basic block and an index. This identifies the point
<strong>on entry</strong> to the statement with that index (or the terminator, if
the index is equal to <code>statements.len()</code>).</li>
<li>There is an element <code>end('a)</code> for each universal region <code>'a</code>,
corresponding to some portion of the caller's (or caller's caller,
etc) control-flow graph.</li>
<li>Similarly, there is an element denoted <code>end('static)</code> corresponding
to the remainder of program execution after this function returns.</li>
<li>There is an element <code>!1</code> for each skolemized region <code>!1</code>. This
corresponds (intuitively) to some unknown set of other elements --
for details on skolemization, see the section
<a href="print.html#skol">skolemization and universes</a>.</li>
</ul>
<a class="header" href="print.html#causal-tracking" id="causal-tracking"><h2>Causal tracking</h2></a>
<p><em>to be written</em> -- describe how we can extend the values of a variable
with causal tracking etc</p>
<p><a name=skol></p>
<a class="header" href="print.html#skolemization-and-universes" id="skolemization-and-universes"><h2>Skolemization and universes</h2></a>
<p>(This section describes ongoing work that hasn't landed yet.)</p>
<p>From time to time we have to reason about regions that we can't
concretely know. For example, consider this program:</p>
<pre><pre class="playpen"><code class="language-rust">// A function that needs a static reference
fn foo(x: &amp;'static u32) { }

fn bar(f: for&lt;'a&gt; fn(&amp;'a u32)) {
       // ^^^^^^^^^^^^^^^^^^^ a function that can accept **any** reference
    let x = 22;
    f(&amp;x);
}

fn main() {
    bar(foo);
}
</code></pre></pre>
<p>This program ought not to type-check: <code>foo</code> needs a static reference
for its argument, and <code>bar</code> wants to be given a function that that
accepts <strong>any</strong> reference (so it can call it with something on its
stack, for example). But <em>how</em> do we reject it and <em>why</em>?</p>
<a class="header" href="print.html#subtyping-and-skolemization" id="subtyping-and-skolemization"><h3>Subtyping and skolemization</h3></a>
<p>When we type-check <code>main</code>, and in particular the call <code>bar(foo)</code>, we
are going to wind up with a subtyping relationship like this one:</p>
<pre><code>fn(&amp;'static u32) &lt;: for&lt;'a&gt; fn(&amp;'a u32)
----------------    -------------------
the type of `foo`   the type `bar` expects
</code></pre>
<p>We handle this sort of subtyping by taking the variables that are
bound in the supertype and <strong>skolemizing</strong> them: this means that we
replace them with
<a href="background.html#quantified">universally quantified</a>
representatives, written like <code>!1</code>. We call these regions &quot;skolemized
regions&quot; -- they represent, basically, &quot;some unknown region&quot;.</p>
<p>Once we've done that replacement, we have the following relation:</p>
<pre><code>fn(&amp;'static u32) &lt;: fn(&amp;'!1 u32)
</code></pre>
<p>The key idea here is that this unknown region <code>'!1</code> is not related to
any other regions. So if we can prove that the subtyping relationship
is true for <code>'!1</code>, then it ought to be true for any region, which is
what we wanted.</p>
<p>So let's work through what happens next. To check if two functions are
subtypes, we check if their arguments have the desired relationship
(fn arguments are <a href="./background.html#variance">contravariant</a>, so
we swap the left and right here):</p>
<pre><code>&amp;'!1 u32 &lt;: &amp;'static u32
</code></pre>
<p>According to the basic subtyping rules for a reference, this will be
true if <code>'!1: 'static</code>. That is -- if &quot;some unknown region <code>!1</code>&quot; lives
outlives <code>'static</code>. Now, this <em>might</em> be true -- after all, <code>'!1</code>
could be <code>'static</code> -- but we don't <em>know</em> that it's true. So this
should yield up an error (eventually).</p>
<a class="header" href="print.html#what-is-a-universe" id="what-is-a-universe"><h3>What is a universe</h3></a>
<p>In the previous section, we introduced the idea of a skolemized
region, and we denoted it <code>!1</code>. We call this number <code>1</code> the <strong>universe
index</strong>. The idea of a &quot;universe&quot; is that it is a set of names that
are in scope within some type or at some point. Universes are formed
into a tree, where each child extends its parents with some new names.
So the <strong>root universe</strong> conceptually contains global names, such as
the the lifetime <code>'static</code> or the type <code>i32</code>. In the compiler, we also
put generic type parameters into this root universe (in this sense,
there is not just one root universe, but one per item). So consider
this function <code>bar</code>:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
struct Foo { }

fn bar&lt;'a, T&gt;(t: &amp;'a T) {
    ...
}
#}</code></pre></pre>
<p>Here, the root universe would consist of the lifetimes <code>'static</code> and
<code>'a</code>.  In fact, although we're focused on lifetimes here, we can apply
the same concept to types, in which case the types <code>Foo</code> and <code>T</code> would
be in the root universe (along with other global types, like <code>i32</code>).
Basically, the root universe contains all the names that
<a href="./background.html#free-vs-bound">appear free</a> in the body of <code>bar</code>.</p>
<p>Now let's extend <code>bar</code> a bit by adding a variable <code>x</code>:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn bar&lt;'a, T&gt;(t: &amp;'a T) {
    let x: for&lt;'b&gt; fn(&amp;'b u32) = ...;
}
#}</code></pre></pre>
<p>Here, the name <code>'b</code> is not part of the root universe. Instead, when we
&quot;enter&quot; into this <code>for&lt;'b&gt;</code> (e.g., by skolemizing it), we will create
a child universe of the root, let's call it U1:</p>
<pre><code>U0 (root universe)
│
└─ U1 (child universe)
</code></pre>
<p>The idea is that this child universe U1 extends the root universe U0
with a new name, which we are identifying by its universe number:
<code>!1</code>.</p>
<p>Now let's extend <code>bar</code> a bit by adding one more variable, <code>y</code>:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn bar&lt;'a, T&gt;(t: &amp;'a T) {
    let x: for&lt;'b&gt; fn(&amp;'b u32) = ...;
    let y: for&lt;'c&gt; fn(&amp;'b u32) = ...;
}
#}</code></pre></pre>
<p>When we enter <em>this</em> type, we will again create a new universe, which
we'll call <code>U2</code>. Its parent will be the root universe, and U1 will be
its sibling:</p>
<pre><code>U0 (root universe)
│
├─ U1 (child universe)
│
└─ U2 (child universe)
</code></pre>
<p>This implies that, while in U2, we can name things from U0 or U2, but
not U1.</p>
<p><strong>Giving existential variables a universe.</strong> Now that we have this
notion of universes, we can use it to extend our type-checker and
things to prevent illegal names from leaking out. The idea is that we
give each inference (existential) variable -- whether it be a type or
a lifetime -- a universe. That variable's value can then only
reference names visible from that universe. So for example is a
lifetime variable is created in U0, then it cannot be assigned a value
of <code>!1</code> or <code>!2</code>, because those names are not visible from the universe
U0.</p>
<p><strong>Representing universes with just a counter.</strong> You might be surprised
to see that the compiler doesn't keep track of a full tree of
universes. Instead, it just keeps a counter -- and, to determine if
one universe can see another one, it just checks if the index is
greater. For example, U2 can see U0 because 2 &gt;= 0. But U0 cannot see
U2, because 0 &gt;= 2 is false.</p>
<p>How can we get away with this? Doesn't this mean that we would allow
U2 to also see U1? The answer is that, yes, we would, <strong>if that
question ever arose</strong>.  But because of the structure of our type
checker etc, there is no way for that to happen. In order for
something happening in the universe U1 to &quot;communicate&quot; with something
happening in U2, they would have to have a shared inference variable X
in common. And because everything in U1 is scoped to just U1 and its
children, that inference variable X would have to be in U0. And since
X is in U0, it cannot name anything from U1 (or U2). This is perhaps easiest
to see by using a kind of generic &quot;logic&quot; example:</p>
<pre><code>exists&lt;X&gt; {
   forall&lt;Y&gt; { ... /* Y is in U1 ... */ }
   forall&lt;Z&gt; { ... /* Z is in U2 ... */ }
}   
</code></pre>
<p>Here, the only way for the two foralls to interact would be through X,
but neither Y nor Z are in scope when X is declared, so its value
cannot reference either of them.</p>
<a class="header" href="print.html#universes-and-skolemized-region-elements" id="universes-and-skolemized-region-elements"><h3>Universes and skolemized region elements</h3></a>
<p>But where does that error come from?  The way it happens is like this.
When we are constructing the region inference context, we can tell
from the type inference context how many skolemized variables exist
(the <code>InferCtxt</code> has an internal counter). For each of those, we
create a corresponding universal region variable <code>!n</code> and a &quot;region
element&quot; <code>skol(n)</code>. This corresponds to &quot;some unknown set of other
elements&quot;. The value of <code>!n</code> is <code>{skol(n)}</code>.</p>
<p>At the same time, we also give each existential variable a
<strong>universe</strong> (also taken from the <code>InferCtxt</code>). This universe
determines which skolemized elements may appear in its value: For
example, a variable in universe U3 may name <code>skol(1)</code>, <code>skol(2)</code>, and
<code>skol(3)</code>, but not <code>skol(4)</code>. Note that the universe of an inference
variable controls what region elements <strong>can</strong> appear in its value; it
does not say region elements <strong>will</strong> appear.</p>
<a class="header" href="print.html#skolemization-and-outlives-constraints" id="skolemization-and-outlives-constraints"><h3>Skolemization and outlives constraints</h3></a>
<p>In the region inference engine, outlives constraints have the form:</p>
<pre><code>V1: V2 @ P
</code></pre>
<p>where <code>V1</code> and <code>V2</code> are region indices, and hence map to some region
variable (which may be universally or existentially quantified). The
<code>P</code> here is a &quot;point&quot; in the control-flow graph; it's not important
for this section. This variable will have a universe, so let's call
those universes <code>U(V1)</code> and <code>U(V2)</code> respectively. (Actually, the only
one we are going to care about is <code>U(V1)</code>.)</p>
<p>When we encounter this constraint, the ordinary procedure is to start
a DFS from <code>P</code>. We keep walking so long as the nodes we are walking
are present in <code>value(V2)</code> and we add those nodes to <code>value(V1)</code>. If
we reach a return point, we add in any <code>end(X)</code> elements. That part
remains unchanged.</p>
<p>But then <em>after that</em> we want to iterate over the skolemized <code>skol(x)</code>
elements in V2 (each of those must be visible to <code>U(V2)</code>, but we
should be able to just assume that is true, we don't have to check
it). We have to ensure that <code>value(V1)</code> outlives each of those
skolemized elements.</p>
<p>Now there are two ways that could happen. First, if <code>U(V1)</code> can see
the universe <code>x</code> (i.e., <code>x &lt;= U(V1)</code>), then we can just add <code>skol(x)</code>
to <code>value(V1)</code> and be done. But if not, then we have to approximate:
we may not know what set of elements <code>skol(x)</code> represents, but we
should be able to compute some sort of <strong>upper bound</strong> B for it --
some region B that outlives <code>skol(x)</code>. For now, we'll just use
<code>'static</code> for that (since it outlives everything) -- in the future, we
can sometimes be smarter here (and in fact we have code for doing this
already in other contexts). Moreover, since <code>'static</code> is in the root
universe U0, we know that all variables can see it -- so basically if
we find that <code>value(V2)</code> contains <code>skol(x)</code> for some universe <code>x</code>
that <code>V1</code> can't see, then we force <code>V1</code> to <code>'static</code>.</p>
<a class="header" href="print.html#extending-the-universal-regions-check" id="extending-the-universal-regions-check"><h3>Extending the &quot;universal regions&quot; check</h3></a>
<p>After all constraints have been propagated, the NLL region inference
has one final check, where it goes over the values that wound up being
computed for each universal region and checks that they did not get
'too large'. In our case, we will go through each skolemized region
and check that it contains <em>only</em> the <code>skol(u)</code> element it is known to
outlive. (Later, we might be able to know that there are relationships
between two skolemized regions and take those into account, as we do
for universal regions from the fn signature.)</p>
<p>Put another way, the &quot;universal regions&quot; check can be considered to be
checking constraints like:</p>
<pre><code>{skol(1)}: V1
</code></pre>
<p>where <code>{skol(1)}</code> is like a constant set, and V1 is the variable we
made to represent the <code>!1</code> region.</p>
<a class="header" href="print.html#back-to-our-example" id="back-to-our-example"><h2>Back to our example</h2></a>
<p>OK, so far so good. Now let's walk through what would happen with our
first example:</p>
<pre><code>fn(&amp;'static u32) &lt;: fn(&amp;'!1 u32) @ P  // this point P is not imp't here
</code></pre>
<p>The region inference engine will create a region element domain like this:</p>
<pre><code>{ CFG; end('static); skol(1) }
  ---  ------------  ------- from the universe `!1`
  |    'static is always in scope
  all points in the CFG; not especially relevant here 
</code></pre>
<p>It will always create two universal variables, one representing
<code>'static</code> and one representing <code>'!1</code>. Let's call them Vs and V1. They
will have initial values like so:</p>
<pre><code>Vs = { CFG; end('static) } // it is in U0, so can't name anything else
V1 = { skol(1) }
</code></pre>
<p>From the subtyping constraint above, we would have an outlives constraint like</p>
<pre><code>'!1: 'static @ P
</code></pre>
<p>To process this, we would grow the value of V1 to include all of Vs:</p>
<pre><code>Vs = { CFG; end('static) }
V1 = { CFG; end('static), skol(1) }
</code></pre>
<p>At that point, constraint propagation is complete, because all the
outlives relationships are satisfied. Then we would go to the &quot;check
universal regions&quot; portion of the code, which would test that no
universal region grew too large.</p>
<p>In this case, <code>V1</code> <em>did</em> grow too large -- it is not known to outlive
<code>end('static)</code>, nor any of the CFG -- so we would report an error.</p>
<a class="header" href="print.html#another-example" id="another-example"><h2>Another example</h2></a>
<p>What about this subtyping relationship?</p>
<pre><code>for&lt;'a&gt; fn(&amp;'a u32, &amp;'a u32)
    &lt;:
for&lt;'b, 'c&gt; fn(&amp;'b u32, &amp;'c u32)
</code></pre>
<p>Here we would skolemize the supertype, as before, yielding:</p>
<pre><code>for&lt;'a&gt; fn(&amp;'a u32, &amp;'a u32)
    &lt;:
fn(&amp;'!1 u32, &amp;'!2 u32)
</code></pre>
<p>then we instantiate the variable on the left-hand side with an
existential in universe U2, yielding the following (<code>?n</code> is a notation
for an existential variable):</p>
<pre><code>fn(&amp;'?3 u32, &amp;'?3 u32) 
    &lt;: 
fn(&amp;'!1 u32, &amp;'!2 u32)
</code></pre>
<p>Then we break this down further:</p>
<pre><code>&amp;'!1 u32 &lt;: &amp;'?3 u32
&amp;'!2 u32 &lt;: &amp;'?3 u32
</code></pre>
<p>and even further, yield up our region constraints:</p>
<pre><code>'!1: '?3
'!2: '?3
</code></pre>
<p>Note that, in this case, both <code>'!1</code> and <code>'!2</code> have to outlive the
variable <code>'?3</code>, but the variable <code>'?3</code> is not forced to outlive
anything else. Therefore, it simply starts and ends as the empty set
of elements, and hence the type-check succeeds here.</p>
<p>(This should surprise you a little. It surprised me when I first
realized it. We are saying that if we are a fn that <strong>needs both of
its arguments to have the same region</strong>, we can accept being called
with <strong>arguments with two distinct regions</strong>. That seems intuitively
unsound. But in fact, it's fine, as I
<a href="https://github.com/rust-lang/rust/issues/32330#issuecomment-202536977">tried to explain in this issue on the Rust issue tracker long ago</a>.
The reason is that even if we get called with arguments of two
distinct lifetimes, those two lifetimes have some intersection (the
call itself), and that intersection can be our value of <code>'a</code> that we
use as the common lifetime of our arguments. -nmatsakis)</p>
<a class="header" href="print.html#final-example" id="final-example"><h2>Final example</h2></a>
<p>Let's look at one last example. We'll extend the previous one to have
a return type:</p>
<pre><code>for&lt;'a&gt; fn(&amp;'a u32, &amp;'a u32) -&gt; &amp;'a u32
    &lt;:
for&lt;'b, 'c&gt; fn(&amp;'b u32, &amp;'c u32) -&gt; &amp;'b u32
</code></pre>
<p>Despite seeming very similar to the previous example, this case is
going to get an error. That's good: the problem is that we've gone
from a fn that promises to return one of its two arguments, to a fn
that is promising to return the first one. That is unsound. Let's see how it plays out.</p>
<p>First, we skolemize the supertype:</p>
<pre><code>for&lt;'a&gt; fn(&amp;'a u32, &amp;'a u32) -&gt; &amp;'a u32
    &lt;:
fn(&amp;'!1 u32, &amp;'!2 u32) -&gt; &amp;'!1 u32
</code></pre>
<p>Then we instantiate the subtype with existentials (in U2):</p>
<pre><code>fn(&amp;'?3 u32, &amp;'?3 u32) -&gt; &amp;'?3 u32
    &lt;:
fn(&amp;'!1 u32, &amp;'!2 u32) -&gt; &amp;'!1 u32
</code></pre>
<p>And now we create the subtyping relationships:</p>
<pre><code>&amp;'!1 u32 &lt;: &amp;'?3 u32 // arg 1
&amp;'!2 u32 &lt;: &amp;'?3 u32 // arg 2
&amp;'?3 u32 &lt;: &amp;'!1 u32 // return type
</code></pre>
<p>And finally the outlives relationships. Here, let V1, V2, and V3 be the variables
we assign to <code>!1</code>, <code>!2</code>, and <code>?3</code> respectively:</p>
<pre><code>V1: V3
V2: V3
V3: V1
</code></pre>
<p>Those variables will have these initial values:</p>
<pre><code>V1 in U1 = {skol(1)}
V2 in U2 = {skol(2)}
V3 in U2 = {}
</code></pre>
<p>Now because of the <code>V3: V1</code> constraint, we have to add <code>skol(1)</code> into <code>V3</code> (and indeed
it is visible from <code>V3</code>), so we get:</p>
<pre><code>V3 in U2 = {skol(1)}
</code></pre>
<p>then we have this constraint <code>V2: V3</code>, so we wind up having to enlarge
<code>V2</code> to include <code>skol(1)</code> (which it can also see):</p>
<pre><code>V2 in U2 = {skol(1), skol(2)}
</code></pre>
<p>Now contraint propagation is done, but when we check the outlives
relationships, we find that <code>V2</code> includes this new element <code>skol(1)</code>,
so we report an error.</p>
<a class="header" href="print.html#mir-optimizations" id="mir-optimizations"><h1>MIR optimizations</h1></a>
<a class="header" href="print.html#constant-evaluation" id="constant-evaluation"><h1>Constant Evaluation</h1></a>
<p>Constant evaluation is the process of computing values at compile time. For a
specific item (constant/static/array length) this happens after the MIR for the
item is borrow-checked and optimized. In many cases trying to const evaluate an
item will trigger the computation of its MIR for the first time.</p>
<p>Prominent examples are</p>
<ul>
<li>The initializer of a <code>static</code></li>
<li>Array length
<ul>
<li>needs to be known to reserve stack or heap space</li>
</ul>
</li>
<li>Enum variant discriminants
<ul>
<li>needs to be known to prevent two variants from having the same discriminant</li>
</ul>
</li>
<li>Patterns
<ul>
<li>need to be known to check for overlapping patterns</li>
</ul>
</li>
</ul>
<p>Additionally constant evaluation can be used to reduce the workload or binary
size at runtime by precomputing complex operations at compiletime and only
storing the result.</p>
<p>Constant evaluation can be done by calling the <code>const_eval</code> query of <code>TyCtxt</code>.</p>
<p>The <code>const_eval</code> query takes a <a href="./param_env.html"><code>ParamEnv</code></a> of environment in
which the constant is evaluated (e.g. the function within which the constant is
used) and a <code>GlobalId</code>. The <code>GlobalId</code> is made up of an
<code>Instance</code> referring to a constant or static or of an
<code>Instance</code> of a function and an index into the function's <code>Promoted</code> table.</p>
<p>Constant evaluation returns a <code>Result</code> with either the error, or the simplest
representation of the constant. &quot;simplest&quot; meaning if it is representable as an
integer or fat pointer, it will directly yield the value (via <code>Value::ByVal</code> or
<code>Value::ByValPair</code>), instead of referring to the <a href="./miri.html"><code>miri</code></a> virtual
memory allocation (via <code>Value::ByRef</code>). This means that the <code>const_eval</code>
function cannot be used to create miri-pointers to the evaluated constant or
static. If you need that, you need to directly work with the functions in
<a href="https://github.com/rust-lang/rust/blob/master/src/librustc_mir/interpret/const_eval.rs">src/librustc_mir/interpret/const_eval.rs</a>.</p>
<a class="header" href="print.html#miri" id="miri"><h1>Miri</h1></a>
<p>Miri (<strong>MIR</strong> <strong>I</strong>nterpreter) is a virtual machine for executing MIR without
compiling to machine code. It is usually invoked via <code>tcx.const_eval</code>.</p>
<p>If you start out with a constant</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
const FOO: usize = 1 &lt;&lt; 12;
#}</code></pre></pre>
<p>rustc doesn't actually invoke anything until the constant is either used or
placed into metadata.</p>
<p>Once you have a use-site like</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
type Foo = [u8; FOO - 42];
#}</code></pre></pre>
<p>The compiler needs to figure out the length of the array before being able to
create items that use the type (locals, constants, function arguments, ...).</p>
<p>To obtain the (in this case empty) parameter environment, one can call
<code>let param_env = tcx.param_env(length_def_id);</code>. The <code>GlobalId</code> needed is</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let gid = GlobalId {
    promoted: None,
    instance: Instance::mono(length_def_id),
};
#}</code></pre></pre>
<p>Invoking <code>tcx.const_eval(param_env.and(gid))</code> will now trigger the creation of
the MIR of the array length expression. The MIR will look something like this:</p>
<pre><code class="language-mir">const Foo::{{initializer}}: usize = {
    let mut _0: usize;                   // return pointer
    let mut _1: (usize, bool);

    bb0: {
        _1 = CheckedSub(const Unevaluated(FOO, Slice([])), const 42usize);
        assert(!(_1.1: bool), &quot;attempt to subtract with overflow&quot;) -&gt; bb1;
    }

    bb1: {
        _0 = (_1.0: usize);
        return;
    }
}
</code></pre>
<p>Before the evaluation, a virtual memory location (in this case essentially a
<code>vec![u8; 4]</code> or <code>vec![u8; 8]</code>) is created for storing the evaluation result.</p>
<p>At the start of the evaluation, <code>_0</code> and <code>_1</code> are
<code>Value::ByVal(PrimVal::Undef)</code>. When the initialization of <code>_1</code> is invoked, the
value of the <code>FOO</code> constant is required, and triggers another call to
<code>tcx.const_eval</code>, which will not be shown here. If the evaluation of FOO is
successful, 42 will be subtracted by its value <code>4096</code> and the result stored in
<code>_1</code> as <code>Value::ByValPair(PrimVal::Bytes(4054), PrimVal::Bytes(0))</code>. The first
part of the pair is the computed value, the second part is a bool that's true if
an overflow happened.</p>
<p>The next statement asserts that said boolean is <code>0</code>. In case the assertion
fails, its error message is used for reporting a compile-time error.</p>
<p>Since it does not fail, <code>Value::ByVal(PrimVal::Bytes(4054))</code> is stored in the
virtual memory was allocated before the evaluation. <code>_0</code> always refers to that
location directly.</p>
<p>After the evaluation is done, the virtual memory allocation is interned into the
<code>TyCtxt</code>. Future evaluations of the same constants will not actually invoke
miri, but just extract the value from the interned allocation.</p>
<p>The <code>tcx.const_eval</code> function has one additional feature: it will not return a
<code>ByRef(interned_allocation_id)</code>, but a <code>ByVal(computed_value)</code> if possible. This
makes using the result much more convenient, as no further queries need to be
executed in order to get at something as simple as a <code>usize</code>.</p>
<a class="header" href="print.html#datastructures" id="datastructures"><h2>Datastructures</h2></a>
<p>Miri's core datastructures can be found in
<a href="https://github.com/rust-lang/rust/blob/master/src/librustc/mir/interpret">librustc/mir/interpret</a>.
This is mainly the error enum and the <code>Value</code> and <code>PrimVal</code> types. A <code>Value</code> can
be either <code>ByVal</code> (a single <code>PrimVal</code>), <code>ByValPair</code> (two <code>PrimVal</code>s, usually fat
pointers or two element tuples) or <code>ByRef</code>, which is used for anything else and
refers to a virtual allocation. These allocations can be accessed via the
methods on <code>tcx.interpret_interner</code>.</p>
<p>If you are expecting a numeric result, you can use <code>unwrap_u64</code> (panics on
anything that can't be representad as a <code>u64</code>) or <code>to_raw_bits</code> which results
in an <code>Option&lt;u128&gt;</code> yielding the <code>ByVal</code> if possible.</p>
<a class="header" href="print.html#allocations" id="allocations"><h2>Allocations</h2></a>
<p>A miri allocation is either a byte sequence of the memory or an <code>Instance</code> in
the case of function pointers. Byte sequences can additionally contain
relocations that mark a group of bytes as a pointer to another allocation. The
actual bytes at the relocation refer to the offset inside the other allocation.</p>
<p>These allocations exist so that references and raw pointers have something to
point to. There is no global linear heap in which things are allocated, but each
allocation (be it for a local variable, a static or a (future) heap allocation)
gets its own little memory with exactly the required size. So if you have a
pointer to an allocation for a local variable <code>a</code>, there is no possible (no
matter how unsafe) operation that you can do that would ever change said pointer
to a pointer to <code>b</code>.</p>
<a class="header" href="print.html#interpretation" id="interpretation"><h2>Interpretation</h2></a>
<p>Although the main entry point to constant evaluation is the <code>tcx.const_eval</code>
query, there are additional functions in
<a href="https://github.com/rust-lang/rust/blob/master/src/librustc_mir/interpret/const_eval.rs">librustc_mir/interpret/const_eval.rs</a>
that allow accessing the fields of a <code>Value</code> (<code>ByRef</code> or otherwise). You should
never have to access an <code>Allocation</code> directly except for translating it to the
compilation target (at the moment just LLVM).</p>
<p>Miri starts by creating a virtual stack frame for the current constant that is
being evaluated. There's essentially no difference between a constant and a
function with no arguments, except that constants do not allow local (named)
variables at the time of writing this guide.</p>
<p>A stack frame is defined by the <code>Frame</code> type in
<a href="https://github.com/rust-lang/rust/blob/master/src/librustc_mir/interpret/eval_context.rs">librustc_mir/interpret/eval_context.rs</a>
and contains all the local
variables memory (<code>None</code> at the start of evaluation). Each frame refers to the
evaluation of either the root constant or subsequent calls to <code>const fn</code>. The
evaluation of another constant simply calls <code>tcx.const_eval</code>, which produces an
entirely new and independent stack frame.</p>
<p>The frames are just a <code>Vec&lt;Frame&gt;</code>, there's no way to actually refer to a
<code>Frame</code>'s memory even if horrible shenigans are done via unsafe code. The only
memory that can be referred to are <code>Allocation</code>s.</p>
<p>Miri now calls the <code>step</code> method (in
<a href="https://github.com/rust-lang/rust/blob/master/src/librustc_mir/interpret/step.rs">librustc_mir/interpret/step.rs</a>
) until it either returns an error or has no further statements to execute. Each
statement will now initialize or modify the locals or the virtual memory
referred to by a local. This might require evaluating other constants or
statics, which just recursively invokes <code>tcx.const_eval</code>.</p>
<a class="header" href="print.html#parameter-environment" id="parameter-environment"><h1>Parameter Environment</h1></a>
<p>When working with associated and/or or generic items (types, constants,
functions/methods) it is often relevant to have more information about the
<code>Self</code> or generic parameters. Trait bounds and similar information is encoded in
the <code>ParamEnv</code>. Often this is not enough information to obtain things like the
type's <code>Layout</code>, but you can do all kinds of other checks on it (e.g. whether a
type implements <code>Copy</code>) or you can evaluate an associated constant whose value
does not depend on anything from the parameter environment.</p>
<p>For example if you have a function</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn foo&lt;T: Copy&gt;(t: T) {
}
#}</code></pre></pre>
<p>the parameter environment for that function is <code>[T: Copy]</code>. This means any
evaluation within this function will, when accessing the type <code>T</code>, know about
its <code>Copy</code> bound via the parameter environment.</p>
<p>Although you can obtain a valid <code>ParamEnv</code> for any item via
<code>tcx.param_env(def_id)</code>, this <code>ParamEnv</code> can be too generic for your use case.
Using the <code>ParamEnv</code> from the surrounding context can allow you to evaluate more
things.</p>
<p>Another great thing about <code>ParamEnv</code> is that you can use it to bundle the thing
depending on generic parameters (e.g. a <code>Ty</code>) by calling <code>param_env.and(ty)</code>.
This will produce a <code>ParamEnvAnd&lt;Ty&gt;</code>, making clear that you should probably not
be using the inner value without taking care to also use the <code>ParamEnv</code>.</p>
<a class="header" href="print.html#generating-llvm-ir" id="generating-llvm-ir"><h1>Generating LLVM IR</h1></a>
<a class="header" href="print.html#background-topics" id="background-topics"><h1>Background topics</h1></a>
<p>This section covers a numbers of common compiler terms that arise in
this guide. We try to give the general definition while providing some
Rust-specific context.</p>
<p><a name=cfg></p>
<a class="header" href="print.html#what-is-a-control-flow-graph" id="what-is-a-control-flow-graph"><h2>What is a control-flow graph?</h2></a>
<p>A control-flow graph is a common term from compilers. If you've ever
used a flow-chart, then the concept of a control-flow graph will be
pretty familiar to you. It's a representation of your program that
exposes the underlying control flow in a very clear way.</p>
<p>A control-flow graph is structured as a set of <strong>basic blocks</strong>
connected by edges. The key idea of a basic block is that it is a set
of statements that execute &quot;together&quot; -- that is, whenever you branch
to a basic block, you start at the first statement and then execute
all the remainder. Only at the end of the block is there the
possibility of branching to more than one place (in MIR, we call that
final statement the <strong>terminator</strong>):</p>
<pre><code>bb0: {
    statement0;
    statement1;
    statement2;
    ...
    terminator;
}
</code></pre>
<p>Many expressions that you are used to in Rust compile down to multiple
basic blocks. For example, consider an if statement:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
a = 1;
if some_variable {
    b = 1;
} else {
    c = 1;
}
d = 1;
#}</code></pre></pre>
<p>This would compile into four basic blocks:</p>
<pre><code>BB0: {
    a = 1;
    if some_variable { goto BB1 } else { goto BB2 }
}

BB1: {
    b = 1;
    goto BB3;
}

BB2: {
    c = 1;
    goto BB3;
}

BB3: {
    d = 1;
    ...;
}
</code></pre>
<p>When using a control-flow graph, a loop simply appears as a cycle in
the graph, and the <code>break</code> keyword translates into a path out of that
cycle.</p>
<p><a name=dataflow></p>
<a class="header" href="print.html#what-is-a-dataflow-analysis" id="what-is-a-dataflow-analysis"><h2>What is a dataflow analysis?</h2></a>
<p><em>to be written</em></p>
<p><a name=quantified></p>
<a class="header" href="print.html#what-is-universally-quantified-what-about-existentially-quantified" id="what-is-universally-quantified-what-about-existentially-quantified"><h2>What is &quot;universally quantified&quot;? What about &quot;existentially quantified&quot;?</h2></a>
<p><em>to be written</em></p>
<p><a name=variance></p>
<a class="header" href="print.html#what-is-co--and-contra-variance" id="what-is-co--and-contra-variance"><h2>What is co- and contra-variance?</h2></a>
<p>Check out the subtyping chapter from the
<a href="https://doc.rust-lang.org/nomicon/subtyping.html">Rust Nomicon</a>.</p>
<p><a name=free-vs-bound></p>
<a class="header" href="print.html#what-is-a-free-region-or-a-free-variable-what-about-bound-region" id="what-is-a-free-region-or-a-free-variable-what-about-bound-region"><h2>What is a &quot;free region&quot; or a &quot;free variable&quot;? What about &quot;bound region&quot;?</h2></a>
<p>Let's describe the concepts of free vs bound in terms of program
variables, since that's the thing we're most familiar with.</p>
<ul>
<li>Consider this expression, which creates a closure: <code>|a, b| a + b</code>. Here, the <code>a</code> and <code>b</code> in <code>a + b</code> refer to the arguments
that the closure will be given when it is called. We say that the
<code>a</code> and <code>b</code> there are <strong>bound</strong> to the closure, and that the closure
signature <code>|a, b|</code> is a <strong>binder</strong> for the names <code>a</code> and <code>b</code>
(because any references to <code>a</code> or <code>b</code> within refer to the variables
that it introduces).</li>
<li>Consider this expression: <code>a + b</code>. In this expression, <code>a</code> and <code>b</code>
refer to local variables that are defined <em>outside</em> of the
expression. We say that those variables <strong>appear free</strong> in the
expression (i.e., they are <strong>free</strong>, not <strong>bound</strong> (tied up)).</li>
</ul>
<p>So there you have it: a variable &quot;appears free&quot; in some
expression/statement/whatever if it refers to something defined
outside of that expressions/statement/whatever. Equivalently, we can
then refer to the &quot;free variables&quot; of an expression -- which is just
the set of variables that &quot;appear free&quot;.</p>
<p>So what does this have to do with regions? Well, we can apply the
analogous concept to type and regions. For example, in the type <code>&amp;'a u32</code>, <code>'a</code> appears free.  But in the type <code>for&lt;'a&gt; fn(&amp;'a u32)</code>, it
does not.</p>
<a class="header" href="print.html#glossary" id="glossary"><h2>Glossary</h2></a>
<p>The compiler uses a number of...idiosyncratic abbreviations and things. This glossary attempts to list them and give you a few pointers for understanding them better.</p>
<table><thead><tr><th>Term                    </th><th> Meaning</th></tr></thead><tbody>
<tr><td>AST                     </td><td>  the abstract syntax tree produced by the syntax crate; reflects user syntax very closely.</td></tr>
<tr><td>binder                  </td><td>  a &quot;binder&quot; is a place where a variable or type is declared; for example, the <code>&lt;T&gt;</code> is a binder for the generic type parameter <code>T</code> in <code>fn foo&lt;T&gt;(..)</code>, and |<code>a</code>|<code>...</code> is a binder for the parameter <code>a</code>. See <a href="./background.html#free-vs-bound">the background chapter for more</a></td></tr>
<tr><td>bound variable          </td><td>  a &quot;bound variable&quot; is one that is declared within an expression/term. For example, the variable <code>a</code> is bound within the closure expession |<code>a</code>|<code>a * 2</code>. See <a href="./background.html#free-vs-bound">the background chapter for more</a></td></tr>
<tr><td>codegen unit            </td><td>  when we produce LLVM IR, we group the Rust code into a number of codegen units. Each of these units is processed by LLVM independently from one another, enabling parallelism. They are also the unit of incremental re-use.</td></tr>
<tr><td>completeness            </td><td>  completeness is a technical term in type theory. Completeness means that every type-safe program also type-checks. Having both soundness and completeness is very hard, and usually soundness is more important. (see &quot;soundness&quot;).</td></tr>
<tr><td>control-flow graph      </td><td>  a representation of the control-flow of a program; see <a href="./background.html#cfg">the background chapter for more</a></td></tr>
<tr><td>cx                      </td><td>  we tend to use &quot;cx&quot; as an abbrevation for context. See also <code>tcx</code>, <code>infcx</code>, etc.</td></tr>
<tr><td>DAG                     </td><td>  a directed acyclic graph is used during compilation to keep track of dependencies between queries. (<a href="incremental-compilation.html">see more</a>)</td></tr>
<tr><td>data-flow analysis      </td><td>  a static analysis that figures out what properties are true at each point in the control-flow of a program; see <a href="./background.html#dataflow">the background chapter for more</a></td></tr>
<tr><td>DefId                   </td><td>  an index identifying a definition (see <code>librustc/hir/def_id.rs</code>). Uniquely identifies a <code>DefPath</code>.</td></tr>
<tr><td>free variable           </td><td>  a &quot;free variable&quot; is one that is not bound within an expression or term; see <a href="./background.html#free-vs-bound">the background chapter for more</a></td></tr>
<tr><td>'gcx                    </td><td>  the lifetime of the global arena (<a href="ty.html">see more</a>)</td></tr>
<tr><td>generics                </td><td>  the set of generic type parameters defined on a type or item</td></tr>
<tr><td>HIR                     </td><td>  the High-level IR, created by lowering and desugaring the AST (<a href="hir.html">see more</a>)</td></tr>
<tr><td>HirId                   </td><td>  identifies a particular node in the HIR by combining a def-id with an &quot;intra-definition offset&quot;.</td></tr>
<tr><td>HIR Map                 </td><td>  The HIR map, accessible via tcx.hir, allows you to quickly navigate the HIR and convert between various forms of identifiers.</td></tr>
<tr><td>ICE                     </td><td>  internal compiler error. When the compiler crashes.</td></tr>
<tr><td>ICH                     </td><td>  incremental compilation hash. ICHs are used as fingerprints for things such as HIR and crate metadata, to check if changes have been made. This is useful in incremental compilation to see if part of a crate has changed and should be recompiled.</td></tr>
<tr><td>inference variable      </td><td>  when doing type or region inference, an &quot;inference variable&quot; is a kind of special type/region that represents what you are trying to infer. Think of X in algebra. For example, if we are trying to infer the type of a variable in a program, we create an inference variable to represent that unknown type.</td></tr>
<tr><td>infcx                   </td><td>  the inference context (see <code>librustc/infer</code>)</td></tr>
<tr><td>IR                      </td><td>  Intermediate Representation. A general term in compilers. During compilation, the code is transformed from raw source (ASCII text) to various IRs. In Rust, these are primarily HIR, MIR, and LLVM IR. Each IR is well-suited for some set of computations. For example, MIR is well-suited for the borrow checker, and LLVM IR is well-suited for codegen because LLVM accepts it.</td></tr>
<tr><td>local crate             </td><td>  the crate currently being compiled.</td></tr>
<tr><td>LTO                     </td><td>  Link-Time Optimizations. A set of optimizations offered by LLVM that occur just before the final binary is linked. These include optmizations like removing functions that are never used in the final program, for example. <em>ThinLTO</em> is a variant of LTO that aims to be a bit more scalable and efficient, but possibly sacrifices some optimizations. You may also read issues in the Rust repo about &quot;FatLTO&quot;, which is the loving nickname given to non-Thin LTO. LLVM documentation: <a href="https://llvm.org/docs/LinkTimeOptimization.html">here</a> and <a href="https://clang.llvm.org/docs/ThinLTO.html">here</a></td></tr>
<tr><td><a href="https://llvm.org/">LLVM</a>                  </td><td>  (actually not an acronym :P) an open-source compiler backend. It accepts LLVM IR and outputs native binaries. Various languages (e.g. Rust) can then implement a compiler front-end that output LLVM IR and use LLVM to compile to all the platforms LLVM supports.</td></tr>
<tr><td>MIR                     </td><td>  the Mid-level IR that is created after type-checking for use by borrowck and trans (<a href="./mir.html">see more</a>)</td></tr>
<tr><td>miri                    </td><td>  an interpreter for MIR used for constant evaluation (<a href="./miri.html">see more</a>)</td></tr>
<tr><td>newtype                 </td><td>  a &quot;newtype&quot; is a wrapper around some other type (e.g., <code>struct Foo(T)</code> is a &quot;newtype&quot; for <code>T</code>). This is commonly used in Rust to give a stronger type for indices.</td></tr>
<tr><td>NLL                     </td><td> <a href="./mir-regionck.html">non-lexical lifetimes</a>, an extension to Rust's borrowing system to make it be based on the control-flow graph.</td></tr>
<tr><td>node-id or NodeId       </td><td>  an index identifying a particular node in the AST or HIR; gradually being phased out and replaced with <code>HirId</code>.</td></tr>
<tr><td>obligation              </td><td>  something that must be proven by the trait system (<a href="trait-resolution.html">see more</a>)</td></tr>
<tr><td>promoted constants      </td><td>  constants extracted from a function and lifted to static scope; see <a href="./mir.html#promoted">this section</a> for more details.</td></tr>
<tr><td>provider                </td><td>  the function that executes a query (<a href="query.html">see more</a>)</td></tr>
<tr><td>quantified              </td><td>  in math or logic, existential and universal quantification are used to ask questions like &quot;is there any type T for which is true?&quot; or &quot;is this true for all types T?&quot;; see <a href="./background.html#quantified">the background chapter for more</a></td></tr>
<tr><td>query                   </td><td>  perhaps some sub-computation during compilation (<a href="query.html">see more</a>)</td></tr>
<tr><td>region                  </td><td>  another term for &quot;lifetime&quot; often used in the literature and in the borrow checker.</td></tr>
<tr><td>sess                    </td><td>  the compiler session, which stores global data used throughout compilation</td></tr>
<tr><td>side tables             </td><td>  because the AST and HIR are immutable once created, we often carry extra information about them in the form of hashtables, indexed by the id of a particular node.</td></tr>
<tr><td>sigil                   </td><td>  like a keyword but composed entirely of non-alphanumeric tokens. For example, <code>&amp;</code> is a sigil for references.</td></tr>
<tr><td>skolemization           </td><td>  a way of handling subtyping around &quot;for-all&quot; types (e.g., <code>for&lt;'a&gt; fn(&amp;'a u32)</code>) as well as solving higher-ranked trait bounds (e.g., <code>for&lt;'a&gt; T: Trait&lt;'a&gt;</code>). See <a href="./mir-regionck.html#skol">the chapter on skolemization and universes</a> for more details.</td></tr>
<tr><td>soundness               </td><td>  soundness is a technical term in type theory. Roughly, if a type system is sound, then if a program type-checks, it is type-safe; i.e. I can never (in safe rust) force a value into a variable of the wrong type. (see &quot;completeness&quot;).</td></tr>
<tr><td>span                    </td><td>  a location in the user's source code, used for error reporting primarily. These are like a file-name/line-number/column tuple on steroids: they carry a start/end point, and also track macro expansions and compiler desugaring. All while being packed into a few bytes (really, it's an index into a table). See the Span datatype for more.</td></tr>
<tr><td>substs                  </td><td>  the substitutions for a given generic type or item (e.g. the <code>i32</code>, <code>u32</code> in <code>HashMap&lt;i32, u32&gt;</code>)</td></tr>
<tr><td>tcx                     </td><td>  the &quot;typing context&quot;, main data structure of the compiler (<a href="ty.html">see more</a>)</td></tr>
<tr><td>'tcx                    </td><td>  the lifetime of the currently active inference context (<a href="ty.html">see more</a>)</td></tr>
<tr><td>token                   </td><td>  the smallest unit of parsing. Tokens are produced after lexing (<a href="the-parser.html">see more</a>).</td></tr>
<tr><td><a href="https://llvm.org/docs/LangRef.html#thread-local-storage-models">TLS</a>                   </td><td>  Thread-Local Storage. Variables may be defined so that each thread has its own copy (rather than all threads sharing the variable). This has some interactions with LLVM. Not all platforms support TLS.</td></tr>
<tr><td>trans                   </td><td>  the code to translate MIR into LLVM IR.</td></tr>
<tr><td>trait reference         </td><td>  a trait and values for its type parameters (<a href="ty.html">see more</a>).</td></tr>
<tr><td>ty                      </td><td>  the internal representation of a type (<a href="ty.html">see more</a>).</td></tr>
<tr><td>variance                </td><td>  variance determines how changes to a generic type/lifetime parameter affect subtyping; for example, if <code>T</code> is a subtype of <code>U</code>, then <code>Vec&lt;T&gt;</code> is a subtype <code>Vec&lt;U&gt;</code> because <code>Vec</code> is <em>covariant</em> in its generic parameter. See <a href="./background.html#variance">the background chapter for more</a>.</td></tr>
</tbody></table>
<a class="header" href="print.html#code-index" id="code-index"><h1>Code Index</h1></a>
<p>rustc has a lot of important data structures. This is an attempt to give some
guidance on where to learn more about some of the key data structures of the
compiler.</p>
<table><thead><tr><th>Item            </th><th>  Kind    </th><th> Short description           </th><th> Chapter            </th><th> Declaration</th></tr></thead><tbody>
<tr><td><code>TyCtxt&lt;'cx, 'tcx, 'tcx&gt;</code> </td><td> type </td><td> The &quot;typing context&quot;. This is the central data structure in the compiler. It is the context that you use to perform all manner of queries. </td><td> <a href="ty.html">The <code>ty</code> modules</a> </td><td> <a href="https://github.com/rust-lang/rust/blob/master/src/librustc/ty/context.rs">src/librustc/ty/context.rs</a></td></tr>
<tr><td><code>ParseSess</code> </td><td> struct </td><td> This struct contains information about a parsing session </td><td> <a href="the-parser.html">The parser</a> </td><td> <a href="https://github.com/rust-lang/rust/blob/master/src/libsyntax/parse/mod.rs">src/libsyntax/parse/mod.rs</a></td></tr>
</tbody></table>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>


        <!-- Local fallback for Font Awesome -->
        <script>
            if (getComputedStyle(document.querySelector(".fa")).fontFamily !== "FontAwesome") {
                var link = document.createElement('link');
                link.rel = 'stylesheet';
                link.type = 'text/css';
                link.href = '_FontAwesome/css/font-awesome.css';
                document.head.insertBefore(link, document.head.firstChild)
            }
        </script>

        

        

        

        
        <script>
            document.addEventListener('DOMContentLoaded', function() {
                window.print();
            })
        </script>
        

        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS script -->
        

    </body>
</html>
